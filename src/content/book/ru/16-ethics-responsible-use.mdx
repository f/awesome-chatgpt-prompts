Промпты, которые вы пишете, определяют поведение ИИ. Хорошо составленный промпт может обучать, помогать и расширять возможности. Небрежный — может вводить в заблуждение, дискриминировать или причинять вред. Как промпт-инженеры, мы не просто пользователи — мы проектировщики поведения ИИ, и это накладывает реальную ответственность.

Эта глава не о правилах, навязанных сверху. Она о понимании последствий наших решений и формировании привычек, которые ведут к использованию ИИ, которым можно гордиться.

<Callout type="warning" title="Почему это важно">
ИИ усиливает всё, что ему дают. Предвзятый промпт производит предвзятые результаты в масштабе. Обманчивый промпт позволяет обманывать в масштабе. Этические последствия промпт-инженерии растут с каждой новой возможностью, которую приобретают эти системы.
</Callout>

## Этические основы

Каждое решение в промпт-инженерии связано с несколькими ключевыми принципами:

<InfoGrid items={[
  { label: "Честность", description: "Не используйте ИИ для обмана людей или создания вводящего в заблуждение контента", example: "Никаких фальшивых отзывов, выдачи себя за других или сфабрикованных «доказательств»", exampleType: "text", color: "blue" },
  { label: "Справедливость", description: "Активно работайте над предотвращением распространения предубеждений и стереотипов", example: "Тестируйте промпты на разных демографических группах, запрашивайте разнообразные точки зрения", exampleType: "text", color: "purple" },
  { label: "Прозрачность", description: "Будьте открыты об участии ИИ, когда это важно", example: "Раскрывайте помощь ИИ в публикуемых работах и профессиональных контекстах", exampleType: "text", color: "green" },
  { label: "Конфиденциальность", description: "Защищайте личную информацию в промптах и результатах", example: "Анонимизируйте данные, избегайте включения PII, изучите политики работы с данными", exampleType: "text", color: "amber" },
  { label: "Безопасность", description: "Создавайте промпты, предотвращающие вредоносные результаты", example: "Встраивайте защитные механизмы, тестируйте граничные случаи, корректно обрабатывайте отказы", exampleType: "text", color: "red" },
  { label: "Ответственность", description: "Берите на себя ответственность за то, что производят ваши промпты", example: "Проверяйте результаты, исправляйте проблемы, поддерживайте человеческий контроль", exampleType: "text", color: "cyan" }
]} />

### Роль промпт-инженера

Вы имеете больше влияния, чем можете осознавать:

- **Что производит ИИ**: Ваши промпты определяют содержание, тон и качество результатов
- **Как ИИ взаимодействует**: Ваши системные промпты формируют личность, границы и пользовательский опыт
- **Какие защитные механизмы существуют**: Ваши проектные решения определяют, что ИИ будет и не будет делать
- **Как обрабатываются ошибки**: Ваша обработка ошибок определяет, будут ли сбои корректными или вредоносными

## Предотвращение вредоносных результатов

Самое фундаментальное этическое обязательство — не допустить, чтобы ваши промпты причиняли вред.

### Категории вредоносного контента

<InfoGrid items={[
  { label: "Насилие и вред", description: "Инструкции, которые могут привести к физическому вреду", example: "Создание оружия, самоповреждение, насилие над другими", exampleType: "text", color: "red" },
  { label: "Незаконная деятельность", description: "Контент, способствующий нарушению законов", example: "Мошеннические схемы, инструкции по взлому, синтез наркотиков", exampleType: "text", color: "red" },
  { label: "Преследование и ненависть", description: "Контент, направленный против отдельных лиц или групп", example: "Дискриминационный контент, доксинг, целенаправленное преследование", exampleType: "text", color: "red" },
  { label: "Дезинформация", description: "Намеренно ложный или вводящий в заблуждение контент", example: "Фейковые новости, медицинская дезинформация, конспирологический контент", exampleType: "text", color: "red" },
  { label: "Нарушение конфиденциальности", description: "Раскрытие или эксплуатация личной информации", example: "Раскрытие частных данных, помощь в преследовании", exampleType: "text", color: "red" },
  { label: "Эксплуатация", description: "Контент, эксплуатирующий уязвимых людей", example: "CSAM, интимный контент без согласия, мошенничество с пожилыми", exampleType: "text", color: "red" }
]} />

<Callout type="warning" title="Что такое CSAM?">
CSAM означает **Child Sexual Abuse Material** (материалы сексуального насилия над детьми). Создание, распространение или хранение такого контента незаконно во всём мире. ИИ-системы никогда не должны генерировать контент, изображающий несовершеннолетних в сексуальных ситуациях, а ответственные промпт-инженеры активно создают защитные механизмы против такого злоупотребления.
</Callout>

### Встраивание безопасности в промпты

При создании ИИ-систем включайте явные рекомендации по безопасности:

<TryIt 
  title="Системный промпт с приоритетом безопасности"
  description="Шаблон для встраивания рекомендаций по безопасности в ваши ИИ-системы."
  prompt={`You are a helpful assistant for \${purpose}.

## SAFETY GUIDELINES

**Content Restrictions**:
- Never provide instructions that could cause physical harm
- Decline requests for illegal information or activities
- Don't generate discriminatory or hateful content
- Don't create deliberately misleading information

**When You Must Decline**:
- Acknowledge you understood the request
- Briefly explain why you can't help with this specific thing
- Offer constructive alternatives when possible
- Be respectful—don't lecture or be preachy

**When Uncertain**:
- Ask clarifying questions about intent
- Err on the side of caution
- Suggest the user consult appropriate professionals

Now, please help the user with: \${userRequest}`}
/>

### Фреймворк «Намерение vs. Последствия»

Не каждый деликатный запрос является злонамеренным. Используйте этот фреймворк для неоднозначных случаев:

<TryIt 
  title="Анализатор этических пограничных случаев"
  description="Проработайте неоднозначные запросы, чтобы определить подходящий ответ."
  prompt={`I received this request that might be sensitive:

"\${sensitiveRequest}"

Help me think through whether and how to respond:

**1. Intent Analysis**
- What are the most likely reasons someone would ask this?
- Could this be legitimate? (research, fiction, education, professional need)
- Are there red flags suggesting malicious intent?

**2. Impact Assessment**
- What's the worst case if this information is misused?
- How accessible is this information elsewhere?
- Does providing it meaningfully increase risk?

**3. Recommendation**
Based on this analysis:
- Should I respond, decline, or ask for clarification?
- If responding, what safeguards should I include?
- If declining, how should I phrase it helpfully?`}
/>

## Работа с предвзятостью

ИИ-модели наследуют предвзятость из обучающих данных — исторические неравенства, пробелы в представленности, культурные допущения и языковые паттерны. Как промпт-инженеры, мы можем либо усиливать эту предвзятость, либо активно ей противодействовать.

### Как проявляется предвзятость

<InfoGrid items={[
  { label: "Допущения по умолчанию", description: "Модель предполагает определённую демографию для ролей", example: "Врачи по умолчанию мужчины, медсёстры — женщины", exampleType: "text", color: "amber" },
  { label: "Стереотипизация", description: "Усиление культурных стереотипов в описаниях", example: "Связывание определённых этнических групп с конкретными чертами", exampleType: "text", color: "amber" },
  { label: "Пробелы в представленности", description: "Некоторые группы недопредставлены или искажённо представлены", example: "Ограниченная точная информация о культурах меньшинств", exampleType: "text", color: "amber" },
  { label: "Западоцентричный взгляд", description: "Перспективы смещены в сторону западной культуры и ценностей", example: "Предположение, что западные нормы универсальны", exampleType: "text", color: "amber" }
]} />

### Тестирование на предвзятость

<TryIt 
  title="Тест на обнаружение предвзятости"
  description="Используйте это для проверки ваших промптов на потенциальные проблемы с предвзятостью."
  prompt={`I want to test this prompt for bias:

"\${promptToTest}"

Run these bias checks:

**1. Demographic Variation Test**
Run the prompt with different demographic descriptors (gender, ethnicity, age, etc.) and note any differences in:
- Tone or respect level
- Assumed competence or capabilities
- Stereotypical associations

**2. Default Assumption Check**
When demographics aren't specified:
- What does the model assume?
- Are these assumptions problematic?

**3. Representation Analysis**
- Are different groups represented fairly?
- Are any groups missing or marginalized?

**4. Recommendations**
Based on findings, suggest prompt modifications to reduce bias.`}
/>

### Снижение предвзятости на практике

<Compare 
  before={{ label: "Промпт, склонный к предвзятости", content: "Опишите типичного генерального директора." }}
  after={{ label: "Промпт с учётом предвзятости", content: "Опишите генерального директора. Варьируйте демографические характеристики в примерах и избегайте установки по умолчанию какого-либо конкретного пола, этнической принадлежности или возраста." }}
/>

## Прозрачность и раскрытие информации

Когда следует сообщать людям об участии ИИ? Ответ зависит от контекста, но тенденция направлена к большему раскрытию, а не меньшему.

### Когда раскрытие важно

<InfoGrid items={[
  { label: "Публикуемый контент", description: "Статьи, посты или контент, распространяемый публично", example: "Посты в блогах, социальные сети, маркетинговые материалы", exampleType: "text", color: "blue" },
  { label: "Значимые решения", description: "Когда результаты ИИ влияют на жизнь людей", example: "Рекомендации по найму, медицинская информация, юридические консультации", exampleType: "text", color: "blue" },
  { label: "Контексты доверия", description: "Где ожидается или ценится подлинность", example: "Личная переписка, отзывы, рецензии", exampleType: "text", color: "blue" },
  { label: "Профессиональные условия", description: "Рабочая или академическая среда", example: "Отчёты, исследования, материалы для клиентов", exampleType: "text", color: "blue" }
]} />

### Как правильно раскрывать информацию

<Compare 
  before={{ label: "Скрытое участие ИИ", content: "Вот мой анализ рыночных тенденций..." }}
  after={{ label: "Прозрачное раскрытие", content: "Я использовал инструменты ИИ для помощи в анализе данных и составлении этого отчёта. Все выводы были проверены и отредактированы мной." }}
/>

Распространённые фразы для раскрытия, которые хорошо работают:
- «Написано с помощью ИИ»
- «Первый черновик создан ИИ, отредактирован человеком»
- «Анализ выполнен с использованием инструментов ИИ»
- «Создано с ИИ, проверено и одобрено [имя]»

## Вопросы конфиденциальности

Каждый отправляемый вами промпт содержит данные. Понимание того, куда идут эти данные и чего в них не должно быть, крайне важно.

### Чему никогда не место в промптах

<InfoGrid items={[
  { label: "Персональные идентификаторы", description: "Имена, адреса, номера телефонов, SSN", example: "Используйте [КЛИЕНТ] вместо 'Иван Петров'", color: "red" },
  { label: "Финансовые данные", description: "Номера счетов, кредитные карты, сведения о доходах", example: "Описывайте паттерн, а не фактические цифры", exampleType: "text", color: "red" },
  { label: "Медицинская информация", description: "Медицинские записи, диагнозы, рецепты", example: "Спрашивайте о состояниях в общем, не о конкретных пациентах", exampleType: "text", color: "red" },
  { label: "Учётные данные", description: "Пароли, API-ключи, токены, секреты", example: "Никогда не вставляйте учётные данные — используйте заполнители", exampleType: "text", color: "red" },
  { label: "Частная переписка", description: "Личные письма, сообщения, конфиденциальные документы", example: "Опишите ситуацию, не цитируя частный текст", exampleType: "text", color: "red" }
]} />

### Паттерн безопасной работы с данными

<Compare 
  before={{ label: "Небезопасно: содержит PII", content: "Подведите итог этой жалобы от Ивана Петрова по адресу ул. Ленина, 123, Москва по заказу #12345: «Я заказал 15 марта и до сих пор не получил...»" }}
  after={{ label: "Безопасно: анонимизировано", content: "Подведите итог этого паттерна клиентских жалоб: Клиент сделал заказ 3 недели назад, не получил его и дважды связывался с поддержкой без решения проблемы." }}
/>

<Callout type="info" title="Что такое PII?">
**PII** означает **Personally Identifiable Information** (персональные идентифицирующие данные) — любые данные, которые могут идентифицировать конкретного человека. Это включает имена, адреса, номера телефонов, адреса электронной почты, номера социального страхования, номера финансовых счетов и даже комбинации данных (например, должность + компания + город), которые могут идентифицировать кого-либо. При работе с ИИ всегда анонимизируйте или удаляйте PII для защиты конфиденциальности.
</Callout>

<TryIt 
  title="Очиститель PII"
  description="Используйте это для выявления и удаления конфиденциальной информации перед включением текста в промпты."
  prompt={`Review this text for sensitive information that should be removed before using it in an AI prompt:

"\${textToReview}"

Identify:
1. **Personal Identifiers**: Names, addresses, phone numbers, emails, SSNs
2. **Financial Data**: Account numbers, amounts that could identify someone
3. **Health Information**: Medical details, conditions, prescriptions
4. **Credentials**: Any passwords, keys, or tokens
5. **Private Details**: Information someone would reasonably expect to be confidential

For each item found, suggest how to anonymize or generalize it while preserving the information needed for the task.`}
/>

## Подлинность и обман

Есть разница между использованием ИИ как инструмента и использованием ИИ для обмана.

### Граница легитимности

<InfoGrid items={[
  { label: "Легитимное использование", description: "ИИ как инструмент для улучшения вашей работы", example: "Составление черновиков, мозговой штурм, редактирование, обучение", exampleType: "text", color: "green" },
  { label: "Серые зоны", description: "Зависит от контекста, требует оценки", example: "Гострайтинг, шаблоны, автоматизированные ответы", exampleType: "text", color: "amber" },
  { label: "Обманное использование", description: "Выдача работы ИИ за оригинальную человеческую", example: "Фальшивые отзывы, академическое мошенничество, выдача себя за других", exampleType: "text", color: "red" }
]} />

Ключевые вопросы, которые нужно задать:
- Ожидает ли получатель, что это оригинальная человеческая работа?
- Получаю ли я несправедливое преимущество через обман?
- Изменит ли раскрытие восприятие работы?

### Ответственность за синтетические медиа

Создание реалистичных изображений реальных людей — будь то изображения, аудио или видео — несёт особые обязательства:

- **Никогда** не создавайте реалистичные изображения без согласия
- **Всегда** чётко маркируйте синтетические медиа
- **Подумайте** о потенциальном злоупотреблении перед созданием
- **Откажитесь** создавать интимные изображения без согласия

## Ответственное развёртывание

При создании ИИ-функций для использования другими ваши этические обязательства возрастают многократно.

### Чек-лист перед развёртыванием

<Checklist 
  title="Готовность к развёртыванию"
  items={[
    { text: "Протестировано на вредоносные результаты с разнообразными входными данными" },
    { text: "Протестировано на предвзятость с различными демографическими группами" },
    { text: "Механизмы раскрытия/согласия пользователей на месте" },
    { text: "Человеческий контроль для решений с высокими ставками" },
    { text: "Система обратной связи и сообщений о проблемах доступна" },
    { text: "План реагирования на инциденты задокументирован" },
    { text: "Чёткие политики использования доведены до сведения" },
    { text: "Мониторинг и оповещение настроены" }
  ]}
/>

### Принципы человеческого контроля

<InfoGrid items={[
  { label: "Проверка решений с высокими ставками", description: "Люди проверяют решения, существенно влияющие на людей", example: "Рекомендации по найму, медицинские, юридические, финансовые", exampleType: "text", color: "blue" },
  { label: "Исправление ошибок", description: "Существуют механизмы для выявления и исправления ошибок ИИ", example: "Обратная связь от пользователей, выборочная проверка качества, процесс апелляции", exampleType: "text", color: "blue" },
  { label: "Непрерывное обучение", description: "Выводы из проблем улучшают систему", example: "Разборы инцидентов, обновление промптов, улучшение обучения", exampleType: "text", color: "blue" },
  { label: "Возможность переопределения", description: "Люди могут вмешаться, когда ИИ даёт сбой", example: "Очереди на ручную проверку, пути эскалации", exampleType: "text", color: "blue" }
]} />

## Рекомендации для особых контекстов

Некоторые области требуют особой осторожности из-за потенциального вреда или уязвимости тех, кто в них участвует.

### Здравоохранение

<TryIt 
  title="Дисклеймер для медицинского контекста"
  description="Шаблон для ИИ-систем, которые могут получать вопросы о здоровье."
  prompt={`You are an AI assistant. When users ask about health or medical topics:

**Always**:
- Recommend consulting a qualified healthcare provider for personal medical decisions
- Provide general educational information, not personalized medical advice
- Include disclaimers that you cannot diagnose conditions
- Suggest emergency services (911) for urgent situations

**Never**:
- Provide specific diagnoses
- Recommend specific medications or dosages
- Discourage someone from seeking professional care
- Make claims about treatments without noting uncertainty

User question: \${healthQuestion}

Respond helpfully while following these guidelines.`}
/>

### Юридические и финансовые вопросы

Эти области имеют регуляторные последствия и требуют соответствующих дисклеймеров:

<InfoGrid items={[
  { label: "Юридические вопросы", description: "Предоставляйте общую информацию, а не юридическую консультацию", example: "«Это общая информация. По вашей конкретной ситуации проконсультируйтесь с лицензированным адвокатом.»", color: "purple" },
  { label: "Финансовые вопросы", description: "Обучайте, не давая персональных финансовых советов", example: "«Это образовательная информация. Рассмотрите возможность консультации с финансовым консультантом по вашей ситуации.»", color: "purple" },
  { label: "Осведомлённость о юрисдикции", description: "Законы различаются в зависимости от местоположения", example: "«Законы отличаются в разных странах/регионах. Проверьте требования для вашей юрисдикции.»", color: "purple" }
]} />

### Дети и образование

<InfoGrid items={[
  { label: "Контент, соответствующий возрасту", description: "Убедитесь, что результаты подходят для возрастной группы", example: "Фильтруйте контент для взрослых, используйте подходящий язык", exampleType: "text", color: "cyan" },
  { label: "Академическая честность", description: "Поддерживайте обучение, не заменяйте его", example: "Объясняйте концепции, а не пишите эссе за студентов", exampleType: "text", color: "cyan" },
  { label: "Безопасность прежде всего", description: "Дополнительная защита для уязвимых пользователей", example: "Более строгие фильтры контента, отсутствие сбора личных данных", exampleType: "text", color: "cyan" }
]} />

## Самооценка

Перед развёртыванием любого промпта или ИИ-системы пройдитесь по этим вопросам:

<Checklist 
  title="Этическая самопроверка"
  items={[
    { text: "Может ли это быть использовано для причинения вреда кому-либо?" },
    { text: "Уважает ли это конфиденциальность пользователей?" },
    { text: "Может ли это распространять вредные предубеждения?" },
    { text: "Раскрыто ли участие ИИ надлежащим образом?" },
    { text: "Есть ли адекватный человеческий контроль?" },
    { text: "Что самое худшее может случиться?" },
    { text: "Было бы мне комфортно, если бы это использование стало публичным?" }
  ]}
/>

<Quiz 
  question="Пользователь просит вашу ИИ-систему рассказать, как «избавиться от кого-то, кто его беспокоит». Какая стратегия ответа наиболее уместна?"
  options={[
    "Отказать немедленно — это может быть запрос на инструкции по причинению вреда",
    "Предоставить советы по разрешению конфликтов, поскольку это наиболее вероятное намерение",
    "Задать уточняющие вопросы, чтобы понять намерение, прежде чем решать, как ответить",
    "Объяснить, что вы не можете помочь ни с чем, связанным с причинением вреда людям"
  ]}
  correctIndex={2}
  explanation="Неоднозначные запросы заслуживают уточнения, а не предположений. «Избавиться от кого-то» может означать прекращение дружбы, разрешение рабочего конфликта или что-то вредоносное. Уточняющие вопросы позволяют отреагировать соответственно фактическому намерению, оставаясь осторожным в предоставлении вредоносной информации."
/>
