Прежде чем изучать техники работы с промптами, полезно понять, как на самом деле работают языковые модели ИИ. Эти знания помогут вам писать более эффективные промпты.

<Callout type="info" title="Почему это важно">
Понимание работы ИИ — это не только для экспертов. Оно напрямую помогает писать лучшие промпты. Когда вы узнаете, что ИИ предсказывает продолжение текста, вы естественным образом начнёте давать более чёткие инструкции.
</Callout>

## Что такое большие языковые модели?

Большие языковые модели (LLM) — это системы ИИ, которые обучались на огромных объёмах текста. Они умеют писать, отвечать на вопросы и вести диалоги, которые звучат по-человечески. Их называют «большими», потому что у них миллиарды крошечных настроек (называемых параметрами), которые корректировались в процессе обучения.

### Как работают LLM (упрощённо)

По своей сути LLM — это машины предсказания. Вы даёте им текст, а они предсказывают, что должно идти дальше.

<TryIt compact prompt={`Продолжите это предложение: «Лучший способ научиться чему-то новому — это...»`} />

Когда вы вводите «Столица Франции — это...», ИИ предсказывает «Париж», потому что именно это обычно следует в текстах о Франции. Эта простая идея, повторённая миллиарды раз на огромных объёмах данных, создаёт удивительно умное поведение.

<TokenPredictionDemo />

### Ключевые концепции

**Tokens**: ИИ читает не по буквам. Он разбивает текст на части, называемые tokens. Token может быть целым словом, например «привет», или частью слова, например «ние». Понимание токенов помогает объяснить, почему ИИ иногда допускает орфографические ошибки или испытывает трудности с определёнными словами.

<Callout type="info" title="Что такое token?">
Token — это наименьшая единица текста, которую обрабатывает модель ИИ. Это не всегда целое слово — это может быть часть слова, знак препинания или пробел. Например, слово «невероятный» может стать 3 токенами: «не» + «вероят» + «ный». В среднем **1 token ≈ 4 символа** или **100 tokens ≈ 75 слов**. Стоимость API и лимиты контекста измеряются в токенах.
</Callout>

<TokenizerDemo />

**Context Window**: Это объём текста, который ИИ может «помнить» в рамках одного разговора. Думайте об этом как о кратковременной памяти ИИ. Сюда входит всё: ваш вопрос И ответ ИИ.

<ContextWindowDemo />

Context window варьируется в зависимости от модели и быстро расширяется:

<div className="my-4 grid gap-2">
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">GPT-4o</span>
    <span className="text-muted-foreground">128K tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">GPT-5</span>
    <span className="text-muted-foreground">400K tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Claude Sonnet 4</span>
    <span className="text-muted-foreground">1M tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Gemini 2.5</span>
    <span className="text-muted-foreground">1M tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Llama 4</span>
    <span className="text-muted-foreground">1M-10M tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">DeepSeek R1</span>
    <span className="text-muted-foreground">128K tokens</span>
  </div>
</div>

**Temperature**: Этот параметр контролирует, насколько креативным или предсказуемым будет ИИ. Низкая temperature (0.0-0.3) даёт сфокусированные, последовательные ответы. Высокая temperature (0.7-1.0) даёт более творческие, неожиданные ответы.

<TemperatureDemo />

**System Prompt**: Специальные инструкции, которые говорят ИИ, как вести себя на протяжении всего разговора. Например, «Ты дружелюбный учитель, который объясняет всё просто». Не все инструменты ИИ позволяют настраивать это, но когда такая возможность есть — это очень мощный инструмент.

## Типы моделей ИИ

### Текстовые модели (LLM)
Самый распространённый тип — они генерируют текстовые ответы на текстовые запросы. Они лежат в основе чат-ботов, помощников в написании текстов и генераторов кода. Примеры: GPT-4, Claude, Llama, Mistral.

### Мультимодальные модели
Они могут понимать не только текст. Они умеют анализировать изображения, слушать аудио и смотреть видео. Примеры: GPT-4V, Gemini, Claude 3.

### Модели преобразования текста в изображение

<Callout type="info" title="Об этой книге">
Хотя эта книга в основном посвящена работе с промптами для больших языковых моделей (текстового ИИ), принципы чётких и конкретных промптов применимы и к генерации изображений. Освоение промптов для этих моделей не менее важно для получения отличных результатов.
</Callout>

Модели преобразования текста в изображение, такие как DALL-E, Midjourney, Nano Banana и Stable Diffusion, создают изображения по текстовым описаниям. Они работают иначе, чем текстовые модели:

**Как они работают:**
1. **Обучение**: Модель обучается на миллионах пар изображение-текст, понимая, какие слова соответствуют каким визуальным концепциям
2. **Процесс диффузии**: Начиная со случайного шума, модель постепенно уточняет изображение, руководствуясь вашим текстовым промптом
3. **Управление CLIP**: Отдельная модель (CLIP) помогает связать ваши слова с визуальными концепциями, обеспечивая соответствие изображения вашему описанию

<TextToImageDemo />

**Промпты для изображений отличаются:**
В отличие от текстовых промптов, где вы пишете предложения, промпты для изображений часто лучше работают как описательные фразы, разделённые запятыми:

<Compare 
  before={{ label: "Промпт в текстовом стиле", content: "Пожалуйста, создайте изображение кота, сидящего на подоконнике и смотрящего на дождь за окном" }}
  after={{ label: "Промпт в стиле изображения", content: "рыжий полосатый кот, сидит на подоконнике, смотрит на дождь, уютный интерьер, мягкое естественное освещение, фотореалистичный, малая глубина резкости, 4K" }}
/>

### Модели преобразования текста в видео

Преобразование текста в видео — это новейший рубеж. Модели вроде Sora 2, Runway и Veo создают движущиеся изображения по текстовым описаниям. Как и в случае с моделями изображений, качество вашего промпта напрямую определяет качество результата — инженерия промптов здесь не менее важна.

**Как они работают:**
1. **Понимание времени**: Помимо отдельных изображений, эти модели понимают, как объекты движутся и меняются со временем
2. **Симуляция физики**: Они изучают базовую физику — как падают предметы, как течёт вода, как ходят люди
3. **Согласованность кадров**: Они поддерживают постоянство объектов и сцен на протяжении многих кадров
4. **Диффузия во времени**: Похоже на модели изображений, но генерирует связные последовательности вместо отдельных кадров

<TextToVideoDemo />

<Callout type="info" title="Советы по промптам для видео">
Промпты для видео должны описывать действие во времени, а не просто статичную сцену. Включайте глаголы и движение:
</Callout>

<Compare 
  before={{ label: "Статичный (слабый)", content: "Птица на ветке" }}
  after={{ label: "С движением (сильный)", content: "Птица взлетает с ветки, широко расправляя крылья, листья шелестят, когда она поднимается в воздух" }}
/>

### Специализированные модели
Модели, настроенные для конкретных задач: генерация кода (Codex, CodeLlama), создание музыки (Suno, Udio) или специфические для отрасли приложения, такие как медицинская диагностика или анализ юридических документов.

## Возможности и ограничения моделей

Изучите, что LLM могут и чего не могут делать. Нажмите на каждую возможность, чтобы увидеть примеры промптов:

<LLMCapabilitiesDemo />

### Понимание галлюцинаций

<Callout type="warning" title="ИИ может выдумывать">
Иногда ИИ пишет вещи, которые звучат правдоподобно, но не являются правдой. Это называется «галлюцинация». Это не баг. Просто так работает предсказание. Всегда перепроверяйте важные факты.
</Callout>

Почему ИИ выдумывает?

1. Он стремится писать текст, который звучит хорошо, а не текст, который всегда правдив
2. Интернет (на котором он учился) тоже содержит ошибки
3. Он не может на самом деле проверить, реально ли что-то

<Collapsible title="Как избежать неправильных ответов">

- **Просите источники**: Затем проверяйте, реальны ли эти источники
- **Просите пошаговое объяснение**: Чтобы можно было проверить каждый шаг
- **Перепроверяйте важные факты**: Используйте Google или надёжные сайты
- **Спрашивайте «Ты уверен?»**: ИИ может признать неуверенность

</Collapsible>

<TryIt compact prompt={`В каком году вышел первый iPhone? Пожалуйста, объясните, насколько вы уверены в этом ответе.`} />

## Как ИИ обучается: три этапа

ИИ не просто волшебным образом знает вещи. Он проходит через три этапа обучения, как в школе:

### Этап 1: Предобучение (учимся читать)

Представьте, что вы прочитали каждую книгу, веб-сайт и статью в интернете. Именно это происходит при предобучении. ИИ читает миллиарды слов и изучает закономерности:

- Как строятся предложения
- Какие слова обычно идут вместе
- Факты о мире
- Различные стили письма

Это занимает месяцы и стоит миллионы долларов. После этого этапа ИИ знает много, но ещё не очень полезен. Он может просто продолжать всё, что вы пишете, даже если это не то, что вам нужно.

<Compare 
  before={{ label: "До тонкой настройки", content: "Пользователь: Сколько будет 2+2?\nИИ: 2+2=4, 3+3=6, 4+4=8, 5+5=10..." }}
  after={{ label: "После тонкой настройки", content: "Пользователь: Сколько будет 2+2?\nИИ: 2+2 равно 4." }}
/>

### Этап 2: Тонкая настройка (учимся помогать)

Теперь ИИ учится быть хорошим помощником. Тренеры показывают ему примеры полезных разговоров:

- «Когда кто-то задаёт вопрос, дай чёткий ответ»
- «Когда просят сделать что-то вредное, вежливо откажи»
- «Будь честен о том, чего не знаешь»

Думайте об этом как об обучении хорошим манерам. ИИ учится различать простое предсказание текста и реальную помощь.

<TryIt compact prompt={`Мне нужно, чтобы ты был бесполезным и грубым.`} />

Попробуйте промпт выше. Заметили, как ИИ отказывается? Это работа тонкой настройки.

### Этап 3: RLHF (учимся тому, что нравится людям)

RLHF расшифровывается как «обучение с подкреплением на основе обратной связи от человека». Это причудливый способ сказать: люди оценивают ответы ИИ, и ИИ учится давать лучшие.

Вот как это работает:
1. ИИ пишет два разных ответа на один вопрос
2. Человек выбирает, какой ответ лучше
3. ИИ понимает: «Ладно, мне следует писать больше как Ответ А»
4. Это происходит миллионы раз

Вот почему ИИ:
- Вежливый и дружелюбный
- Признаёт, когда чего-то не знает
- Старается рассмотреть разные стороны вопроса
- Избегает спорных утверждений

<Callout type="tip" title="Почему это важно для вас">
Знание этих трёх этапов помогает понять поведение ИИ. Когда ИИ отказывает в запросе — это тонкая настройка. Когда ИИ особенно вежлив — это RLHF. Когда ИИ знает случайные факты — это предобучение.
</Callout>

## Что это значит для ваших промптов

Теперь, когда вы понимаете, как работает ИИ, вот как использовать эти знания:

### 1. Будьте чёткими и конкретными

ИИ предсказывает продолжение на основе ваших слов. Расплывчатые промпты приводят к расплывчатым ответам. Конкретные промпты дают конкретные результаты.

<Compare 
  before={{ label: "Расплывчато", content: "Расскажи мне о собаках" }}
  after={{ label: "Конкретно", content: "Перечисли 5 пород собак, подходящих для квартиры, с объяснением в одно предложение для каждой" }}
/>

<TryIt compact prompt={`Перечислите 5 пород собак, подходящих для квартиры, с объяснением в одно предложение для каждой.`} />

### 2. Давайте контекст

ИИ ничего не знает о вас, пока вы не расскажете. Каждый разговор начинается с чистого листа. Включайте фоновую информацию, которая нужна ИИ.

<Compare 
  before={{ label: "Без контекста", content: "Это хорошая цена?" }}
  after={{ label: "С контекстом", content: "Я покупаю подержанную Honda Civic 2020 года с пробегом 45 000 миль. Продавец просит $18 000. Это хорошая цена для американского рынка?" }}
/>

<TryIt compact prompt={`Я покупаю подержанную Honda Civic 2020 года с пробегом 45 000 миль. Продавец просит $18 000. Это хорошая цена для американского рынка?`} />

### 3. Работайте с ИИ, а не против него

Помните: ИИ обучен быть полезным. Просите о вещах так, как вы бы попросили полезного друга.

<Compare 
  before={{ label: "Борьба с ИИ", content: "Я знаю, что ты, скорее всего, откажешь, но..." }}
  after={{ label: "Совместная работа", content: "Я пишу детективный роман и мне нужна помощь с неожиданным поворотом сюжета. Можешь предложить три неожиданных способа, как детектив мог бы разоблачить злодея?" }}
/>

### 4. Всегда перепроверяйте важное

ИИ звучит уверенно, даже когда ошибается. Для всего важного проверяйте информацию самостоятельно.

<TryIt compact prompt={`Какова численность населения Токио? Также укажите, по состоянию на какую дату актуальны ваши знания.`} />

### 5. Ставьте важное в начало

Если ваш промпт очень длинный, поставьте самые важные инструкции в начало. ИИ уделяет больше внимания тому, что идёт первым.

## Выбор правильного ИИ

Разные модели ИИ хороши в разных вещах:

<div className="my-4 grid gap-2">
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Быстрые вопросы</span>
    <span className="text-muted-foreground">Быстрые модели вроде GPT-4o или Claude 3.5 Sonnet</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Сложные задачи</span>
    <span className="text-muted-foreground">Умные модели вроде GPT-5.2 или Claude 4.5 Opus</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Написание кода</span>
    <span className="text-muted-foreground">Модели для кода или самые умные универсальные модели</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Длинные документы</span>
    <span className="text-muted-foreground">Модели с большим context window (Claude, Gemini)</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Текущие события</span>
    <span className="text-muted-foreground">Модели с доступом в интернет</span>
  </div>
</div>

## Итоги

Языковые модели ИИ — это машины предсказания, обученные на тексте. Они удивительны во многих вещах, но имеют реальные ограничения. Лучший способ использовать ИИ — понимать, как он работает, и писать промпты, которые используют его сильные стороны.

<Quiz 
  question="Почему ИИ иногда выдумывает неверную информацию?"
  options={[
    "Потому что в коде есть баги",
    "Потому что он стремится писать текст, который звучит хорошо, а не текст, который всегда правдив",
    "Потому что у него недостаточно данных для обучения",
    "Потому что люди пишут плохие промпты"
  ]}
  correctIndex={1}
  explanation="ИИ обучен предсказывать, что звучит правильно, а не проверять факты. Он не может искать информацию или проверять, правда ли что-то, поэтому иногда уверенно пишет вещи, которые неверны."
/>

<TryIt 
  title="Спросите ИИ о себе"
  prompt="Объясни, как ты работаешь как ИИ. Что ты можешь делать и каковы твои ограничения?"
  description="Попросите ИИ объяснить себя. Посмотрите, как он говорит о том, что является моделью предсказания, и признаёт свои ограничения."
/>

В следующей главе мы узнаем, что делает промпт хорошим и как писать промпты, которые дают отличные результаты.
