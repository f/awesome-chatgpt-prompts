Prompt chaining breaks complex tasks into sequences of simpler prompts, where each step's output feeds into the next. This technique dramatically improves reliability and enables sophisticated workflows.

## Why Chain Prompts?

Single prompts struggle with:
- Multi-step reasoning
- Tasks requiring different "modes" of thinking
- Complex outputs requiring multiple perspectives
- Quality control and verification

Chaining solves these by decomposing complexity.

## Basic Chaining Pattern

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  Prompt 1   │────▶│  Prompt 2   │────▶│  Prompt 3   │
│  (Extract)  │     │ (Analyze)   │     │ (Generate)  │
└─────────────┘     └─────────────┘     └─────────────┘
     Input               ↓                   Output
                    Intermediate
                       Result
```

## Chain Types

### Sequential Chain

Each step depends on the previous:

```
STEP 1: Extract key information
Prompt: "Extract all dates, names, and numbers from: [text]"
Output: {dates: [...], names: [...], numbers: [...]}

STEP 2: Analyze patterns
Prompt: "Given this extracted data: [step1_output], identify 
        relationships and patterns."
Output: {patterns: [...], relationships: [...]}

STEP 3: Generate report
Prompt: "Using these patterns: [step2_output], write a summary 
        report highlighting the most significant findings."
Output: Final report
```

### Parallel Chain

Independent analyses combined:

```
INPUT: Product review text

PARALLEL BRANCHES:
├── Prompt A: "Analyze sentiment: [text]" → sentiment_score
├── Prompt B: "Extract features mentioned: [text]" → features
├── Prompt C: "Identify user persona: [text]" → persona
└── Prompt D: "Check for actionable feedback: [text]" → actions

MERGE:
Prompt: "Combine these analyses into a unified report:
        Sentiment: [A_output]
        Features: [B_output]
        Persona: [C_output]
        Actions: [D_output]"
```

### Conditional Chain

Different paths based on intermediate results:

```
STEP 1: Classify input
Prompt: "Classify this customer message as: complaint, question, 
        feedback, or other. Message: [text]"

IF complaint:
  STEP 2a: "Identify the issue and severity: [text]"
  STEP 3a: "Generate empathetic response with resolution: [analysis]"

IF question:
  STEP 2b: "Identify what information is needed: [text]"
  STEP 3b: "Provide clear answer: [question_analysis]"

IF feedback:
  STEP 2c: "Categorize feedback as positive/negative/suggestion: [text]"
  STEP 3c: "Generate appropriate acknowledgment: [feedback_type]"
```

### Iterative Chain

Loop until quality threshold met:

```
STEP 1: Generate initial draft
Prompt: "Write a product description for: [product]"
Output: draft_v1

LOOP:
  STEP 2: Evaluate quality
  Prompt: "Rate this description 1-10 on: clarity, persuasiveness, 
          accuracy. Identify specific improvements needed.
          Description: [current_draft]"
  Output: {score, improvements}

  IF score >= 8: EXIT LOOP

  STEP 3: Improve draft
  Prompt: "Improve this description based on this feedback:
          Current: [current_draft]
          Feedback: [improvements]"
  Output: improved_draft
  
  current_draft = improved_draft
  CONTINUE LOOP (max 3 iterations)
```

## Common Chain Patterns

### Extract → Transform → Generate

```
1. EXTRACT
"From this document, extract:
- Main topic
- Key arguments (list)
- Supporting evidence (list)
- Conclusions
Return as JSON."

2. TRANSFORM
"Reorganize this information for [target audience]:
[extracted_data]
Focus on: [specific angle]
Remove: [irrelevant aspects]"

3. GENERATE
"Using this restructured information, write a [format]:
[transformed_data]
Tone: [desired tone]
Length: [word count]"
```

### Analyze → Plan → Execute

```
1. ANALYZE
"Analyze this codebase structure and identify:
- Architecture pattern
- Main components
- Dependencies
- Potential issues
[code]"

2. PLAN
"Based on this analysis, create a refactoring plan:
[analysis_output]
Goal: [improvement goal]
Constraints: [limitations]"

3. EXECUTE
"Implement step 1 of this plan:
[plan_output]
Show the refactored code with explanations."
```

### Generate → Critique → Refine

```
1. GENERATE
"Write a marketing email for [product] targeting [audience]."

2. CRITIQUE
"As a marketing expert, critique this email:
[generated_email]
Evaluate: subject line, hook, value proposition, CTA, tone
Score each 1-10 and explain."

3. REFINE
"Rewrite the email addressing this feedback:
Original: [generated_email]
Critique: [critique_output]
Focus on the lowest-scored elements."
```

## Implementing Chains

### Manual Chaining

Copy-paste approach for experimentation:

```python
# Pseudocode for manual chaining
step1_output = call_ai("Extract entities from: " + input_text)
step2_output = call_ai("Analyze relationships: " + step1_output)
final_output = call_ai("Generate report: " + step2_output)
```

### Programmatic Chaining

```python
def analysis_chain(document):
    # Step 1: Summarize
    summary = call_ai(f"""
        Summarize the key points of this document in 5 bullets:
        {document}
    """)
    
    # Step 2: Extract entities
    entities = call_ai(f"""
        Extract named entities (people, organizations, locations) 
        from this summary. Return as JSON.
        {summary}
    """)
    
    # Step 3: Generate insights
    insights = call_ai(f"""
        Based on this summary and entities, generate 3 actionable 
        insights for a business analyst.
        Summary: {summary}
        Entities: {entities}
    """)
    
    return {
        "summary": summary,
        "entities": json.loads(entities),
        "insights": insights
    }
```

### Using Chain Templates

Create reusable chain templates:

```yaml
# chain_template.yaml
name: "Document Analysis Chain"
steps:
  - name: "extract"
    prompt: |
      Extract key information from this document:
      {input}
      Return JSON with: topics, entities, dates, numbers
    
  - name: "analyze"
    prompt: |
      Analyze this extracted data for patterns:
      {extract.output}
      Identify: trends, anomalies, relationships
    
  - name: "report"
    prompt: |
      Generate an executive summary based on:
      Data: {extract.output}
      Analysis: {analyze.output}
      Format: 3 paragraphs, business tone
```

## Error Handling in Chains

### Validation Between Steps

```
STEP 1: Generate data
...

VALIDATION:
Prompt: "Validate this output. Check for:
        - Required fields present
        - Data types correct
        - Values within expected ranges
        If invalid, return 'INVALID: [reason]'
        If valid, return 'VALID'
        Data: [step1_output]"

IF INVALID:
  RETRY Step 1 with: "Previous attempt was invalid because: 
                      [reason]. Please try again."
```

### Fallback Chains

```
PRIMARY CHAIN:
Try: Complex analysis approach
Catch: If fails or low confidence

FALLBACK CHAIN:
Use: Simpler, more reliable approach
Note: May have reduced capability but higher reliability
```

## Chain Optimization

### Reducing Latency

```
1. Parallelize independent steps
2. Cache intermediate results
3. Use smaller models for simple steps
4. Batch similar operations
```

### Reducing Cost

```
1. Use cheaper models for classification/extraction
2. Limit iterations in loops
3. Short-circuit when possible
4. Cache repeated queries
```

### Improving Reliability

```
1. Add validation between steps
2. Include retry logic
3. Log intermediate results
4. Implement fallback paths
```

## Real-World Chain Example

### Content Pipeline Chain

```
INPUT: Raw article idea

STEP 1: Research & Outline
Prompt: "Create a detailed outline for an article about [topic].
        Include: main points, subpoints, key facts to include,
        target word count per section."

STEP 2: Draft Each Section (parallel)
For each section in outline:
  Prompt: "Write the [section_name] section based on:
          Outline: [section_outline]
          Previous sections: [context]
          Style: [style_guide]"

STEP 3: Assemble & Review
Prompt: "Review this assembled article for:
        - Flow between sections
        - Consistency of tone
        - Missing transitions
        Provide specific edit suggestions.
        Article: [assembled_sections]"

STEP 4: Final Edit
Prompt: "Apply these edits and polish the final article:
        Article: [assembled_sections]
        Edits: [review_suggestions]"

STEP 5: Generate Metadata
Prompt: "For this article, generate:
        - SEO title (60 chars)
        - Meta description (155 chars)
        - 5 keywords
        - Social media post (280 chars)
        Article: [final_article]"

OUTPUT: Complete article package
```

## Summary

Prompt chaining enables:
- Complex multi-step workflows
- Higher quality through specialization
- Better error handling and validation
- Modular, reusable prompt components

Key principles:
1. Break complex tasks into simple steps
2. Design clear interfaces between steps
3. Validate intermediate outputs
4. Build in error handling and fallbacks
5. Optimize for your constraints (speed, cost, quality)
