Les prompts que vous écrivez façonnent le comportement de l'IA. Un prompt bien conçu peut éduquer, assister et autonomiser. Un prompt négligent peut tromper, discriminer ou causer du tort. En tant qu'ingénieurs de prompts, nous ne sommes pas que des utilisateurs—nous sommes des concepteurs du comportement de l'IA, et cela vient avec une vraie responsabilité.

Ce chapitre n'est pas sur des règles imposées d'en haut. Il s'agit de comprendre l'impact de nos choix et de construire des habitudes qui mènent à une utilisation de l'IA dont nous pouvons être fiers.

<Callout type="warning" title="Pourquoi C'est Important">
L'IA amplifie tout ce qu'on lui donne. Un prompt biaisé produit des sorties biaisées à grande échelle. Un prompt trompeur permet la tromperie à grande échelle. Les implications éthiques de l'ingénierie des prompts grandissent avec chaque nouvelle capacité que ces systèmes acquièrent.
</Callout>

## Fondements Éthiques

Chaque décision en ingénierie de prompts se connecte à quelques principes fondamentaux :

<InfoGrid items={[
  { label: "Honnêteté", description: "N'utilisez pas l'IA pour tromper les gens ou créer du contenu trompeur", example: "Pas de faux avis, d'usurpation d'identité, ou de 'preuves' fabriquées", color: "blue" },
  { label: "Équité", description: "Travaillez activement pour éviter de perpétuer les biais et stéréotypes", example: "Testez les prompts sur différentes démographies, demandez des perspectives diverses", color: "purple" },
  { label: "Transparence", description: "Soyez clair sur l'implication de l'IA quand c'est important", example: "Divulguez l'assistance IA dans le travail publié, contextes professionnels", color: "green" },
  { label: "Vie Privée", description: "Protégez les informations personnelles dans les prompts et sorties", example: "Anonymisez les données, évitez d'inclure des PII, comprenez les politiques de données", color: "amber" },
  { label: "Sécurité", description: "Concevez des prompts qui préviennent les sorties nuisibles", example: "Intégrez des garde-fous, testez les cas limites, gérez les refus gracieusement", color: "red" },
  { label: "Responsabilité", description: "Assumez la responsabilité de ce que vos prompts produisent", example: "Révisez les sorties, corrigez les problèmes, maintenez la supervision humaine", color: "cyan" }
]} />

### Le Rôle de l'Ingénieur de Prompts

Vous avez plus d'influence que vous ne le réalisez peut-être :

- **Ce que l'IA produit** : Vos prompts déterminent le contenu, le ton et la qualité des sorties
- **Comment l'IA interagit** : Vos prompts système façonnent la personnalité, les frontières et l'expérience utilisateur
- **Quels garde-fous existent** : Vos choix de conception déterminent ce que l'IA fera et ne fera pas
- **Comment les erreurs sont gérées** : Votre gestion des erreurs détermine si les échecs sont gracieux ou nuisibles

## Éviter les Sorties Nuisibles

L'obligation éthique la plus fondamentale est d'empêcher vos prompts de causer du tort.

### Catégories de Contenu Nuisible

<InfoGrid items={[
  { label: "Violence & Préjudice", description: "Instructions qui pourraient mener à un préjudice physique", example: "Création d'armes, automutilation, violence envers autrui", color: "red" },
  { label: "Activités Illégales", description: "Contenu qui facilite la violation des lois", example: "Schémas de fraude, instructions de piratage, synthèse de drogues", color: "red" },
  { label: "Harcèlement & Haine", description: "Contenu ciblant des individus ou groupes", example: "Contenu discriminatoire, doxxing, harcèlement ciblé", color: "red" },
  { label: "Désinformation", description: "Contenu délibérément faux ou trompeur", example: "Fake news, désinformation médicale, contenu conspirationniste", color: "red" },
  { label: "Violations de Vie Privée", description: "Exposer ou exploiter des informations personnelles", example: "Révéler des données privées, assistance au harcèlement", color: "red" },
  { label: "Exploitation", description: "Contenu qui exploite des individus vulnérables", example: "CSAM, images intimes non consensuelles, arnaques ciblant les personnes âgées", color: "red" }
]} />

<Callout type="warning" title="Qu'est-ce que le CSAM ?">
CSAM signifie **Matériel d'Abus Sexuel sur Enfants**. Créer, distribuer ou posséder un tel contenu est illégal dans le monde entier. Les systèmes d'IA ne doivent jamais générer de contenu représentant des mineurs dans des situations sexuelles, et les ingénieurs de prompts responsables construisent activement des garde-fous contre une telle utilisation abusive.
</Callout>

### Intégrer la Sécurité dans les Prompts

<TryIt 
  title="Prompt Système Sécurité d'Abord"
  description="Un template pour intégrer des directives de sécurité dans vos systèmes IA."
  prompt={`Tu es un assistant utile pour \${objectif}.

## DIRECTIVES DE SÉCURITÉ

**Restrictions de Contenu** :
- Ne jamais fournir d'instructions qui pourraient causer un préjudice physique
- Décliner les demandes d'informations ou activités illégales
- Ne pas générer de contenu discriminatoire ou haineux
- Ne pas créer d'informations délibérément trompeuses

**Quand Tu Dois Décliner** :
- Reconnaître que tu as compris la demande
- Expliquer brièvement pourquoi tu ne peux pas aider avec cette chose spécifique
- Offrir des alternatives constructives quand possible
- Être respectueux—ne pas faire la morale

**Quand Incertain** :
- Poser des questions de clarification sur l'intention
- Errer du côté de la prudence
- Suggérer à l'utilisateur de consulter des professionnels appropriés

Maintenant, aide l'utilisateur avec : \${demandeUtilisateur}`}
/>

### Le Framework Intention vs Impact

<TryIt 
  title="Analyseur de Cas Éthiques Limites"
  description="Travaillez sur les demandes ambiguës pour déterminer la réponse appropriée."
  prompt={`J'ai reçu cette demande qui pourrait être sensible :

"\${demandeSensible}"

Aide-moi à réfléchir si et comment répondre :

**1. Analyse d'Intention**
- Quelles sont les raisons les plus probables pour lesquelles quelqu'un demanderait ceci ?
- Cela pourrait-il être légitime ? (recherche, fiction, éducation, besoin professionnel)
- Y a-t-il des signaux d'alarme suggérant une intention malveillante ?

**2. Évaluation d'Impact**
- Quel est le pire cas si cette information est mal utilisée ?
- Cette information est-elle accessible ailleurs ?
- La fournir augmente-t-elle significativement le risque ?

**3. Recommandation**
Basé sur cette analyse :
- Devrais-je répondre, décliner, ou demander une clarification ?
- Si je réponds, quels garde-fous devrais-je inclure ?
- Si je décline, comment devrais-je le formuler utilement ?`}
/>

## Adresser les Biais

Les modèles d'IA héritent des biais de leurs données d'entraînement. En tant qu'ingénieurs de prompts, nous pouvons soit amplifier ces biais, soit activement les contrecarrer.

### Comment les Biais se Manifestent

<InfoGrid items={[
  { label: "Suppositions par Défaut", description: "Le modèle suppose certaines démographies pour les rôles", example: "Médecins par défaut masculins, infirmières féminines", color: "amber" },
  { label: "Stéréotypage", description: "Renforcer les stéréotypes culturels dans les descriptions", example: "Associer certaines ethnies à des traits spécifiques", color: "amber" },
  { label: "Écarts de Représentation", description: "Certains groupes sont sous-représentés ou mal représentés", example: "Information limitée et précise sur les cultures minoritaires", color: "amber" },
  { label: "Vues Occidentalo-centrées", description: "Perspectives biaisées vers la culture et les valeurs occidentales", example: "Supposer que les normes occidentales sont universelles", color: "amber" }
]} />

### Tester les Biais

<TryIt 
  title="Test de Détection de Biais"
  description="Utilisez ceci pour tester vos prompts pour des problèmes de biais potentiels."
  prompt={`Je veux tester ce prompt pour les biais :

"\${promptATester}"

Exécute ces vérifications de biais :

**1. Test de Variation Démographique**
Exécute le prompt avec différents descripteurs démographiques (genre, ethnicité, âge, etc.) et note toute différence dans :
- Ton ou niveau de respect
- Compétence ou capacités supposées
- Associations stéréotypiques

**2. Vérification des Suppositions par Défaut**
Quand les démographies ne sont pas spécifiées :
- Que suppose le modèle ?
- Ces suppositions sont-elles problématiques ?

**3. Recommandations**
Basé sur les découvertes, suggère des modifications de prompt pour réduire les biais.`}
/>

### Atténuer les Biais en Pratique

<Compare 
  before={{ label: "Prompt sujet aux biais", content: "Décris un PDG typique." }}
  after={{ label: "Prompt conscient des biais", content: "Décris un PDG. Varie les démographies dans les exemples, et évite de supposer par défaut un genre, une ethnicité ou un âge particulier." }}
/>

## Transparence et Divulgation

Quand devriez-vous dire aux gens que l'IA a été impliquée ? La réponse dépend du contexte—mais la tendance est vers plus de divulgation, pas moins.

### Quand la Divulgation Compte

<InfoGrid items={[
  { label: "Contenu Publié", description: "Articles, posts, ou contenu partagé publiquement", example: "Articles de blog, médias sociaux, matériel marketing", color: "blue" },
  { label: "Décisions Conséquentes", description: "Quand les sorties IA affectent la vie des gens", example: "Recommandations d'embauche, infos médicales, conseils juridiques", color: "blue" },
  { label: "Contextes de Confiance", description: "Où l'authenticité est attendue ou valorisée", example: "Correspondance personnelle, témoignages, avis", color: "blue" },
  { label: "Cadres Professionnels", description: "Environnements de travail ou académiques", example: "Rapports, recherche, livrables clients", color: "blue" }
]} />

### Comment Divulguer Correctement

<Compare 
  before={{ label: "Implication IA cachée", content: "Voici mon analyse des tendances du marché..." }}
  after={{ label: "Divulgation transparente", content: "J'ai utilisé des outils IA pour aider à analyser les données et rédiger ce rapport. Toutes les conclusions ont été vérifiées et éditées par moi." }}
/>

Phrases de divulgation courantes qui fonctionnent bien :
- « Écrit avec assistance IA »
- « Premier brouillon généré par IA, édité par un humain »
- « Analyse effectuée avec des outils IA »
- « Créé avec l'IA, revu et approuvé par [nom] »

## Considérations de Vie Privée

Chaque prompt que vous envoyez contient des données. Comprendre où vont ces données—et ce qui ne devrait pas y être—est essentiel.

### Ce Qui N'a Jamais Sa Place dans les Prompts

<InfoGrid items={[
  { label: "Identifiants Personnels", description: "Noms, adresses, numéros de téléphone, numéros de sécu", example: "Utiliser [CLIENT] au lieu de 'Jean Dupont'", color: "red" },
  { label: "Données Financières", description: "Numéros de compte, cartes de crédit, détails de revenus", example: "Décrire le pattern, pas les vrais chiffres", color: "red" },
  { label: "Informations de Santé", description: "Dossiers médicaux, diagnostics, prescriptions", example: "Demander sur les conditions en général, pas des patients spécifiques", color: "red" },
  { label: "Identifiants", description: "Mots de passe, clés API, tokens, secrets", example: "Ne jamais coller d'identifiants—utiliser des placeholders", color: "red" },
  { label: "Communications Privées", description: "Emails personnels, messages, docs confidentiels", example: "Résumer la situation sans citer du texte privé", color: "red" }
]} />

<Callout type="info" title="Qu'est-ce que les PII ?">
**PII** signifie **Informations Personnellement Identifiables**—toute donnée qui peut identifier un individu spécifique. Cela inclut les noms, adresses, numéros de téléphone, adresses email, numéros de sécurité sociale, numéros de comptes financiers, et même des combinaisons de données (comme titre de poste + entreprise + ville) qui pourraient identifier quelqu'un. Quand vous promptez l'IA, anonymisez ou retirez toujours les PII pour protéger la vie privée.
</Callout>

## Authenticité et Tromperie

Il y a une différence entre utiliser l'IA comme outil et utiliser l'IA pour tromper.

### La Ligne de Légitimité

<InfoGrid items={[
  { label: "Utilisations Légitimes", description: "L'IA comme outil pour améliorer votre travail", example: "Brouillons, brainstorming, édition, apprentissage", color: "green" },
  { label: "Zones Grises", description: "Dépendant du contexte, nécessite du jugement", example: "Ghostwriting, templates, réponses automatisées", color: "amber" },
  { label: "Utilisations Trompeuses", description: "Présenter faussement le travail IA comme original humain", example: "Faux avis, fraude académique, usurpation d'identité", color: "red" }
]} />

Questions clés à se poser :
- Le destinataire s'attendrait-il à ce que ce soit un travail humain original ?
- Est-ce que je gagne un avantage injuste par la tromperie ?
- La divulgation changerait-elle comment le travail est reçu ?

## Déploiement Responsable

Quand vous construisez des fonctionnalités IA pour que d'autres les utilisent, vos obligations éthiques se multiplient.

### Checklist Pré-Déploiement

<Checklist 
  title="Préparation au Déploiement"
  items={[
    { text: "Testé pour les sorties nuisibles sur des entrées diverses" },
    { text: "Testé pour les biais avec des démographies variées" },
    { text: "Mécanismes de divulgation/consentement utilisateur en place" },
    { text: "Supervision humaine pour les décisions à enjeux élevés" },
    { text: "Système de feedback et signalement disponible" },
    { text: "Plan de réponse aux incidents documenté" },
    { text: "Politiques d'utilisation claires communiquées" },
    { text: "Monitoring et alertes configurés" }
  ]}
/>

### Principes de Supervision Humaine

<InfoGrid items={[
  { label: "Revue Haute Importance", description: "Les humains révisent les décisions qui affectent significativement les gens", example: "Recommandations d'embauche, médicales, juridiques, financières", color: "blue" },
  { label: "Correction d'Erreurs", description: "Des mécanismes existent pour attraper et corriger les erreurs IA", example: "Feedback utilisateur, échantillonnage qualité, processus d'appel", color: "blue" },
  { label: "Apprentissage Continu", description: "Les insights des problèmes améliorent le système", example: "Post-mortems, mises à jour de prompts, améliorations d'entraînement", color: "blue" },
  { label: "Capacité d'Override", description: "Les humains peuvent intervenir quand l'IA échoue", example: "Files d'attente de revue manuelle, chemins d'escalade", color: "blue" }
]} />

## Directives pour Contextes Spéciaux

### Santé

<TryIt 
  title="Avertissement Contexte Médical"
  description="Template pour les systèmes IA qui pourraient recevoir des questions liées à la santé."
  prompt={`Tu es un assistant IA. Quand les utilisateurs posent des questions sur la santé ou des sujets médicaux :

**Toujours** :
- Recommander de consulter un professionnel de santé qualifié pour les décisions médicales personnelles
- Fournir des informations éducatives générales, pas des conseils médicaux personnalisés
- Inclure des avertissements que tu ne peux pas diagnostiquer de conditions
- Suggérer les services d'urgence (15/SAMU) pour les situations urgentes

**Jamais** :
- Fournir des diagnostics spécifiques
- Recommander des médicaments ou dosages spécifiques
- Décourager quelqu'un de chercher des soins professionnels
- Faire des affirmations sur des traitements sans noter l'incertitude

Question utilisateur : \${questionSante}

Réponds utilement tout en suivant ces directives.`}
/>

### Juridique et Financier

<InfoGrid items={[
  { label: "Questions Juridiques", description: "Fournir des informations générales, pas des conseils juridiques", example: "\"Ceci est une information générale. Pour votre situation spécifique, consultez un avocat.\"", color: "purple" },
  { label: "Questions Financières", description: "Éduquer sans fournir de conseils financiers personnels", example: "\"Ceci est éducatif. Considérez consulter un conseiller financier pour votre situation.\"", color: "purple" },
  { label: "Conscience des Juridictions", description: "Les lois varient selon les lieux", example: "\"Les lois diffèrent selon les pays/régions. Vérifiez les exigences pour votre juridiction.\"", color: "purple" }
]} />

## Auto-Évaluation

<Checklist 
  title="Auto-Vérification Éthique"
  items={[
    { text: "Cela pourrait-il être utilisé pour nuire à quelqu'un ?" },
    { text: "Cela respecte-t-il la vie privée de l'utilisateur ?" },
    { text: "Cela pourrait-il perpétuer des biais nuisibles ?" },
    { text: "L'implication de l'IA est-elle correctement divulguée ?" },
    { text: "Y a-t-il une supervision humaine adéquate ?" },
    { text: "Quel est le pire qui pourrait arriver ?" },
    { text: "Serais-je à l'aise si cette utilisation était publique ?" }
  ]}
/>

<Quiz 
  question="Un utilisateur demande à votre système IA comment 'se débarrasser de quelqu'un qui l'embête'. Quelle est la stratégie de réponse la plus appropriée ?"
  options={[
    "Refuser immédiatement—cela pourrait être une demande d'instructions nuisibles",
    "Fournir des conseils de résolution de conflit puisque c'est l'intention la plus probable",
    "Poser des questions de clarification pour comprendre l'intention avant de décider comment répondre",
    "Expliquer que vous ne pouvez pas aider avec quoi que ce soit lié à nuire aux gens"
  ]}
  correctIndex={2}
  explanation="Les demandes ambiguës méritent une clarification, pas des suppositions. 'Se débarrasser de quelqu'un' pourrait signifier mettre fin à une amitié, résoudre un conflit au travail, ou quelque chose de nuisible. Poser des questions de clarification vous permet de répondre de manière appropriée à l'intention réelle tout en restant prudent sur la fourniture d'informations nuisibles."
/>
