Pendant la majeure partie de l'histoire, les ordinateurs travaillaient avec un seul type de données à la fois : du texte dans un programme, des images dans un autre, de l'audio ailleurs. Mais les humains ne vivent pas le monde ainsi. Nous voyons, entendons, lisons et parlons simultanément.

**L'IA multimodale** change tout. Ces modèles peuvent traiter plusieurs types d'informations ensemble—analyser une image tout en lisant votre question à son sujet, ou générer des images à partir de vos descriptions textuelles.

<Callout type="info" title="Que Signifie Multimodal ?">
« Multi » signifie plusieurs, et « modal » fait référence aux modes ou types de données. Un modèle multimodal peut travailler avec plusieurs modalités : texte, images, audio, vidéo, ou même du code.
</Callout>

## Pourquoi le Multimodal Est Important

L'IA traditionnelle vous obligeait à tout décrire en mots. Voulez-vous poser une question sur une image ? Vous deviez d'abord la décrire. Les modèles multimodaux éliminent ces barrières.

<InfoGrid items={[
  { label: "Voir et Comprendre", description: "Téléchargez une image et posez des questions directement—pas de description nécessaire", example: "\"Qu'est-ce qui ne va pas avec ce schéma de circuit ?\"", color: "blue" },
  { label: "Créer à partir de Mots", description: "Décrivez ce que vous voulez et générez des images, audio ou vidéos", example: "\"Un coucher de soleil sur les montagnes en style aquarelle\"", color: "purple" },
  { label: "Combiner le Tout", description: "Mélangez texte, images et autres médias dans une seule conversation", example: "\"Compare ces deux designs et dis-moi lequel est meilleur pour mobile\"", color: "green" },
  { label: "Analyser des Documents", description: "Extraire des informations de photos de documents, reçus ou captures d'écran", example: "\"Extrais tous les éléments de cette photo de facture\"", color: "amber" }
]} />

## Pourquoi le Prompting Est Encore Plus Important pour le Multimodal

Avec les modèles texte uniquement, l'IA reçoit exactement ce que vous tapez. Mais avec les modèles multimodaux, l'IA doit interpréter l'information visuelle ou audio—et l'interprétation nécessite un guidage.

<Compare 
  before={{ label: "Prompt multimodal vague", content: "Que vois-tu dans cette image ?\n\n[image d'un tableau de bord complexe]" }}
  after={{ label: "Prompt multimodal guidé", content: "Ceci est une capture d'écran de notre tableau de bord analytics. Concentre-toi sur :\n1. Le graphique du taux de conversion en haut à droite\n2. Tout indicateur d'erreur ou avertissement\n3. Si les données semblent normales ou anormales\n\n[image d'un tableau de bord complexe]" }}
/>

**Sans guidage**, le modèle pourrait décrire des couleurs, la mise en page ou des détails non pertinents. **Avec guidage**, il se concentre sur ce qui compte vraiment pour vous.

<Callout type="warning" title="L'Écart d'Interprétation">
Quand vous regardez une image, vous savez instantanément ce qui est important selon votre contexte et vos objectifs. L'IA n'a pas ce contexte à moins que vous ne le fournissiez. Une photo d'une fissure dans un mur pourrait être : une préoccupation d'ingénierie structurelle, une texture artistique, ou un arrière-plan sans importance.
</Callout>

## Le Paysage Multimodal

Différents modèles ont différentes capacités. Voici ce qui est disponible en 2025 :

### Modèles de Compréhension (Entrée → Analyse)

<InfoGrid items={[
  { label: "GPT-4o / GPT-5", description: "Texte + Images + Audio → Texte. Modèle phare d'OpenAI avec contexte de 128K.", color: "green" },
  { label: "Claude 4 Sonnet/Opus", description: "Texte + Images → Texte. Modèle d'Anthropic axé sur la sécurité avec raisonnement avancé.", color: "purple" },
  { label: "Gemini 2.5", description: "Texte + Images + Audio + Vidéo → Texte. Modèle de Google avec contexte de 1M tokens.", color: "blue" },
  { label: "LLaMA 4 Scout", description: "Texte + Images + Vidéo → Texte. Modèle open-source de Meta avec contexte massif de 10M tokens.", color: "cyan" }
]} />

### Modèles de Génération (Texte → Média)

<InfoGrid items={[
  { label: "DALL-E 3", description: "Texte → Images. Générateur d'images d'OpenAI avec haute précision aux descriptions.", color: "amber" },
  { label: "Midjourney", description: "Texte + Images → Images. Connu pour la qualité artistique et le contrôle du style.", color: "pink" },
  { label: "Sora", description: "Texte → Vidéo. Modèle de génération vidéo d'OpenAI.", color: "red" },
  { label: "Whisper", description: "Audio → Texte. Speech-to-text d'OpenAI avec haute précision multilingue.", color: "cyan" }
]} />

## Prompts de Compréhension d'Image

Le cas d'usage multimodal le plus courant est de demander à l'IA d'analyser des images.

### Analyse d'Image Basique

<TryIt 
  title="Analyse d'Image Structurée"
  description="Ce prompt fournit un cadre clair pour l'analyse d'image."
  prompt={`Analyse cette image et décris :

1. **Sujet Principal** : Quel est le focus principal de cette image ?
2. **Cadre** : Où cela semble-t-il être ? (intérieur/extérieur, type de lieu)
3. **Ambiance** : Quel ton émotionnel ou atmosphère transmet-elle ?
4. **Contenu Textuel** : Tout texte visible, panneaux ou étiquettes ?
5. **Détails Notables** : Qu'est-ce que quelqu'un pourrait manquer au premier coup d'œil ?
6. **Qualité Technique** : Comment sont l'éclairage, la mise au point et la composition ?

Description de l'image : \${descriptionImage}`}
/>

### Sortie Structurée pour Images

<TryIt 
  title="Analyse d'Image JSON"
  description="Obtenez des données structurées de l'analyse d'image faciles à parser."
  prompt={`Analyse cette image et retourne un objet JSON avec la structure suivante :

{
  "resume": "Description en une phrase",
  "objets": ["Liste des objets principaux visibles"],
  "personnes": {
    "nombre": "nombre ou 'aucune'",
    "activites": ["Ce qu'elles font, le cas échéant"]
  },
  "texte_detecte": ["Tout texte visible dans l'image"],
  "couleurs": {
    "dominantes": ["Top 3 couleurs"],
    "ambiance": "Chaude/Froide/Neutre"
  },
  "cadre": {
    "type": "interieur/exterieur/inconnu",
    "description": "Description de lieu plus spécifique"
  },
  "confiance": "haute/moyenne/basse"
}

Image à analyser : \${descriptionImage}`}
/>

### Analyse Comparative

<TryIt 
  title="Comparaison d'Images"
  description="Comparez deux images ou plus avec des critères spécifiques."
  prompt={`Compare ces images pour \${objectif} :

**Image A** : \${imageA}
**Image B** : \${imageB}

Analyse chaque image sur ces critères :
1. \${critere1} (importance : haute)
2. \${critere2} (importance : moyenne)
3. \${critere3} (importance : basse)

Fournis :
- Comparaison côte à côte pour chaque critère
- Forces et faiblesses de chacune
- Recommandation claire avec raisonnement
- Toute préoccupation ou mise en garde`}
/>

## Analyse de Documents et Captures d'Écran

### Extraction de Documents

<TryIt 
  title="Extracteur de Données de Documents"
  description="Extrais des données structurées de photos de documents, reçus, factures ou formulaires."
  prompt={`Ceci est une photo/scan d'un(e) \${typeDocument}.

Extrais toutes les informations en format JSON structuré :

{
  "type_document": "type détecté",
  "date": "si présente",
  "champs_cles": {
    "nom_champ": "valeur"
  },
  "elements": [
    {"description": "", "montant": ""}
  ],
  "totaux": {
    "sous_total": "",
    "taxe": "",
    "total": ""
  },
  "notes_manuscrites": ["tout texte manuscrit"],
  "sections_floues": ["zones difficiles à lire"],
  "confiance": "haute/moyenne/basse"
}

IMPORTANT : Si du texte n'est pas clair, note-le dans "sections_floues" plutôt que de deviner.

Description du document : \${descriptionDocument}`}
/>

### Analyse de Captures d'Écran et UI

<TryIt 
  title="Analyseur de Captures UI/UX"
  description="Obtenez une analyse détaillée de captures d'écran pour le débogage ou la revue UX."
  prompt={`Ceci est une capture d'écran de \${nomApplication}.

Analyse cette interface :

**Identification**
- Quel écran/page/état est-ce ?
- Qu'est-ce que l'utilisateur essaie probablement d'accomplir ici ?

**Éléments UI**
- Éléments interactifs clés (boutons, formulaires, menus)
- État actuel (quelque chose de sélectionné, rempli ou développé ?)
- Messages d'erreur, avertissements ou notifications ?

**Évaluation UX**
- La mise en page est-elle claire et intuitive ?
- Éléments confus ou libellés peu clairs ?
- Préoccupations d'accessibilité (contraste, taille du texte) ?

**Problèmes Détectés**
- Bugs visuels ou désalignements ?
- Texte tronqué ou problèmes de débordement ?
- Style incohérent ?

Description de la capture : \${descriptionCapture}`}
/>

## Prompts de Génération d'Image

Générer des images à partir de descriptions textuelles est un art. Plus votre prompt est spécifique et structuré, plus le résultat correspondra à votre vision.

### L'Anatomie d'un Prompt d'Image

<InfoGrid items={[
  { label: "Sujet", description: "Quel est le focus principal de l'image ?", example: "Un golden retriever jouant dans les feuilles d'automne", color: "blue" },
  { label: "Style", description: "Quel style artistique ou médium ?", example: "Peinture aquarelle, art digital, photoréaliste", color: "purple" },
  { label: "Composition", description: "Comment la scène est-elle arrangée ?", example: "Portrait en gros plan, paysage large, vue aérienne", color: "green" },
  { label: "Éclairage", description: "Quelle est la source et qualité de lumière ?", example: "Lumière matinale douce, ombres dramatiques, lueur néon", color: "amber" },
  { label: "Ambiance", description: "Quel sentiment doit-elle évoquer ?", example: "Paisible, énergique, mystérieux, nostalgique", color: "pink" },
  { label: "Détails", description: "Éléments spécifiques à inclure ou éviter", example: "Inclure : fleurs. Éviter : texte, filigranes", color: "cyan" }
]} />

### Génération d'Image Basique

<TryIt 
  title="Prompt d'Image Structuré"
  description="Utilisez ce template pour créer des prompts de génération d'image détaillés."
  prompt={`Crée une image avec ces spécifications :

**Sujet** : \${sujet}

**Style** : \${style}
**Médium** : \${medium} (ex : peinture à l'huile, art digital, photographie)

**Composition** :
- Cadrage : \${cadrage} (gros plan, plan moyen, grand angle)
- Perspective : \${perspective} (niveau des yeux, contre-plongée, vue de dessus)
- Focus : \${zoneFocus}

**Éclairage** :
- Source : \${sourceLumiere}
- Qualité : \${qualiteLumiere} (douce, dure, diffuse)
- Moment de la journée : \${momentJournee}

**Palette de Couleurs** : \${couleurs}

**Ambiance/Atmosphère** : \${ambiance}

**Doit Inclure** : \${elementsInclure}
**Doit Éviter** : \${elementsEviter}

**Technique** : ratio d'aspect \${ratioAspect}, haute qualité`}
/>

## Prompting Audio

Le traitement audio ouvre la transcription, l'analyse et la compréhension du contenu parlé.

### Transcription Améliorée

<TryIt 
  title="Transcription Intelligente"
  description="Obtenez des transcriptions précises avec étiquettes de locuteurs et horodatages."
  prompt={`Transcris cet enregistrement audio.

**Contexte** : \${typeEnregistrement} (réunion, interview, podcast, cours, etc.)
**Locuteurs Attendus** : \${nombreLocuteurs} (\${rolesLocuteurs})
**Domaine** : \${domaine} (termes techniques à attendre : \${termesТехнiques})

**Format de Sortie** :
[00:00] **Locuteur 1 (Nom/Rôle)** : Texte transcrit ici.
[00:15] **Locuteur 2 (Nom/Rôle)** : Sa réponse ici.

**Instructions** :
- Inclure horodatages aux pauses naturelles (toutes les 30-60 secondes ou aux changements de locuteur)
- Marquer sections floues comme [inaudible] ou [flou : meilleure supposition ?]
- Noter les sons non-verbaux entre crochets : [rires], [téléphone sonne], [longue pause]
- Signaler les points d'action avec symbole →

Description audio : \${descriptionAudio}`}
/>

## Prompting Vidéo

La vidéo combine l'analyse visuelle et audio dans le temps.

### Compréhension Vidéo

<TryIt 
  title="Analyse Vidéo Complète"
  description="Obtenez une décomposition structurée du contenu vidéo."
  prompt={`Analyse cette vidéo : \${descriptionVideo}

Fournis une analyse complète :

**1. Vue d'ensemble** (2-3 phrases)
De quoi parle cette vidéo ? Quel est le message ou objectif principal ?

**2. Chronologie des Moments Clés**
| Horodatage | Événement | Signification |
|------------|-----------|---------------|
| 0:00 | ... | ... |

**3. Analyse Visuelle**
- Cadre/Lieu : Où cela se passe-t-il ?
- Personnes : Qui apparaît ? Que font-elles ?
- Objets : Éléments ou accessoires clés présentés
- Style visuel : Qualité, montage, graphiques utilisés

**4. Analyse Audio**
- Discours : Points principaux (si dialogue)
- Musique : Type, ambiance, utilisation
- Effets sonores : Éléments audio notables

**5. Points Clés à Retenir**
Qu'est-ce qu'un spectateur devrait retenir de cette vidéo ?`}
/>

## Combinaisons Multimodales

La vraie puissance de l'IA multimodale émerge quand vous combinez différents types d'entrée.

### Vérification Image + Texte

<TryIt 
  title="Vérificateur d'Alignement Image-Texte"
  description="Vérifiez que les images représentent fidèlement leurs descriptions textuelles."
  prompt={`Analyse cette image et son texte accompagnant pour l'alignement :

**Image** : \${descriptionImage}
**Description Texte** : "\${descriptionTexte}"

Évalue :

**1. Correspondance de Précision**
- L'image montre-t-elle ce que le texte décrit ?
- Score : [1-10] avec explication

**2. Affirmations du Texte vs Réalité Visuelle**
| Affirmation dans le Texte | Visible dans l'Image ? | Notes |
|---------------------------|------------------------|-------|
| ... | Oui/Non/Partiel | ... |

**3. Éléments Visuels Non Mentionnés**
Qu'est-ce qui est visible dans l'image mais non décrit dans le texte ?

**4. Évaluation Globale**
Cette paire image-texte est-elle fiable pour \${objectif} ?`}
/>

### Capture d'Écran + Code pour Débogage

<TryIt 
  title="Débogueur de Bug Visuel"
  description="Déboguez les problèmes UI en analysant à la fois la sortie visuelle et le code source."
  prompt={`J'ai un bug UI. Voici ce que je vois et mon code :

**Description de la Capture** : \${descriptionCapture}
**Ce qui ne Va Pas** : \${descriptionBug}
**Comportement Attendu** : \${comportementAttendu}

**Code Pertinent** :
\`\`\`\${langage}
\${code}
\`\`\`

Aide-moi s'il te plaît :

**1. Analyse de la Cause Racine**
- Qu'est-ce qui dans le code cause ce problème visuel ?
- Quelle(s) ligne(s) spécifique(s) sont responsables ?

**2. La Correction**
\`\`\`\${langage}
// Code corrigé ici
\`\`\`

**3. Prévention**
- Comment éviter ce type de bug à l'avenir`}
/>

## Bonnes Pratiques pour les Prompts Multimodaux

### Ce qui Rend les Prompts Multimodaux Efficaces

<InfoGrid items={[
  { label: "Fournir du Contexte", description: "Dites au modèle ce qu'est le média et pourquoi vous l'analysez", example: "\"Ceci est une photo produit pour notre site e-commerce...\"", color: "green" },
  { label: "Être Spécifique", description: "Demandez des éléments particuliers plutôt que des impressions générales", example: "\"Concentre-toi sur le tableau de prix en haut à droite\"", color: "green" },
  { label: "Référencer les Emplacements", description: "Pointez vers des zones spécifiques avec un langage spatial", example: "\"Dans le quadrant inférieur gauche...\"", color: "green" },
  { label: "Énoncer Votre Objectif", description: "Expliquez à quoi servira l'analyse", example: "\"Je dois décider si cette image convient pour notre app mobile\"", color: "green" }
]} />

### Pièges Courants à Éviter

<InfoGrid items={[
  { label: "Supposer une Vision Parfaite", description: "Les modèles peuvent manquer de petits détails, surtout dans les images basse résolution", color: "red" },
  { label: "Attendre un OCR Parfait", description: "L'écriture manuscrite et les polices inhabituelles peuvent causer des erreurs", color: "red" },
  { label: "Ignorer les Politiques de Contenu", description: "Les modèles ont des restrictions sur certains types de contenu", color: "red" },
  { label: "Sauter la Vérification", description: "Vérifiez toujours les informations critiques extraites des médias", color: "red" }
]} />

<Quiz 
  question="Pourquoi le prompting est-il PLUS important pour les modèles multimodaux que pour les modèles texte uniquement ?"
  options={[
    "Les modèles multimodaux sont moins intelligents et ont besoin de plus d'aide",
    "Les images et l'audio sont intrinsèquement ambigus—l'IA a besoin de contexte pour savoir quels aspects comptent",
    "Les modèles multimodaux ne peuvent traiter qu'un seul type d'entrée à la fois",
    "Les prompts textuels ne fonctionnent pas avec les modèles multimodaux"
  ]}
  correctIndex={1}
  explanation="Quand vous regardez une image, vous savez instantanément ce qui est important selon vos objectifs. L'IA n'a pas ce contexte—une photo de fissure dans un mur pourrait être une préoccupation d'ingénierie, une texture artistique, ou un arrière-plan sans importance. Votre prompt détermine comment l'IA interprète le média."
/>
