プロンプトテクニックを学ぶ前に、AIの言語モデルが実際にどのように機能するかを理解することが役立ちます。この知識は、より良いプロンプトを書くのに役立ちます。

<Callout type="info" title="なぜこれが重要なのか">
AIの仕組みを理解することは専門家だけのものではありません。より良いプロンプトを書くことに直接役立ちます。AIが次に来るものを予測することを知れば、自然とより明確な指示を与えられるようになります。
</Callout>

## 大規模言語モデルとは？

大規模言語モデル（LLM）は、膨大な量のテキストを読んで学習したAIシステムです。文章を書いたり、質問に答えたり、人間のような会話をしたりできます。トレーニング中に調整された数十億の微小な設定（パラメータと呼ばれる）を持っているため、「大規模」と呼ばれています。

### LLMの仕組み（簡略化版）

本質的に、LLMは予測マシンです。テキストを与えると、次に何が来るべきかを予測します。

<TryIt compact prompt={`この文を完成させてください：「何か新しいことを学ぶ最良の方法は...」`} />

「フランスの首都は...」と入力すると、AIはフランスについてのテキストでは通常「パリ」が続くため、「パリ」と予測します。このシンプルなアイデアが、膨大な量のデータで何十億回も繰り返されることで、驚くほど賢い振る舞いが生まれます。

<TokenPredictionDemo />

### 主要な概念

**トークン**：AIは文字ごとに読むわけではありません。テキストを「トークン」と呼ばれるチャンクに分割します。トークンは「hello」のような完全な単語かもしれませんし、「ing」のような単語の一部かもしれません。トークンを理解することで、AIがときどきスペルミスをしたり、特定の単語で苦労したりする理由が説明できます。

<Callout type="info" title="トークンとは？">
トークンは、AIモデルが処理するテキストの最小単位です。必ずしも完全な単語ではなく、単語の断片、句読点、空白の場合もあります。例えば、「unbelievable」は「un」+「believ」+「able」の3つのトークンになることがあります。平均して、**1トークン ≈ 4文字**または**100トークン ≈ 75単語**です。APIコストとコンテキスト制限はトークンで測定されます。
</Callout>

<TokenizerDemo />

**コンテキストウィンドウ**：これはAIが1つの会話で「覚えていられる」テキストの量です。AIの短期記憶のようなものと考えてください。あなたの質問とAIの回答の両方を含みます。

<ContextWindowDemo />

コンテキストウィンドウはモデルによって異なり、急速に拡大しています：

<div className="my-4 grid gap-2">
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">GPT-4o</span>
    <span className="text-muted-foreground">128Kトークン</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">GPT-5</span>
    <span className="text-muted-foreground">400Kトークン</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Claude Sonnet 4</span>
    <span className="text-muted-foreground">1Mトークン</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Gemini 2.5</span>
    <span className="text-muted-foreground">1Mトークン</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Llama 4</span>
    <span className="text-muted-foreground">1M-10Mトークン</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">DeepSeek R1</span>
    <span className="text-muted-foreground">128Kトークン</span>
  </div>
</div>

**温度（Temperature）**：これはAIがどれだけ創造的か、予測可能かを制御します。低い温度（0.0-0.3）は集中した一貫性のある回答をもたらします。高い温度（0.7-1.0）はより創造的で意外な回答をもたらします。

<TemperatureDemo />

**システムプロンプト**：AIに会話全体でどのように振る舞うべきかを伝える特別な指示です。例えば、「あなたは物事をシンプルに説明するフレンドリーな先生です」。すべてのAIツールでこれを設定できるわけではありませんが、利用可能な場合は非常に強力です。

## AIモデルの種類

### テキストモデル（LLM）
最も一般的なタイプで、テキスト入力に対してテキスト応答を生成します。チャットボット、ライティングアシスタント、コードジェネレーターを動かしています。例：GPT-4、Claude、Llama、Mistral。

### マルチモーダルモデル
テキスト以外のものも理解できます。画像を見たり、音声を聞いたり、動画を見たりできます。例：GPT-4V、Gemini、Claude 3。

### テキストから画像へのモデル

<Callout type="info" title="この本について">
この本は主に大規模言語モデル（テキストベースのAI）のプロンプティングに焦点を当てていますが、明確で具体的なプロンプティングの原則は画像生成にも適用されます。これらのモデルでプロンプトをマスターすることは、素晴らしい結果を得るために同様に重要です。
</Callout>

DALL-E、Midjourney、Nano Banana、Stable Diffusionなどのテキストから画像へのモデルは、テキストの説明から画像を作成します。テキストモデルとは異なる動作をします：

**動作の仕組み：**
1. **トレーニング**：モデルは何百万もの画像とテキストのペアから学習し、どの言葉がどの視覚的概念に対応するかを理解します
2. **拡散プロセス**：ランダムなノイズから始まり、モデルはテキストプロンプトに導かれながら徐々に画像を改良します
3. **CLIPガイダンス**：別のモデル（CLIP）があなたの言葉を視覚的概念に接続し、画像があなたの説明と一致することを確認します

<TextToImageDemo />

**画像のプロンプティングは異なる：**
文章を書くテキストプロンプトとは異なり、画像プロンプトはカンマで区切られた説明的なフレーズとしてより効果的に機能することが多いです：

<Compare 
  before={{ label: "テキストスタイルのプロンプト", content: "雨を外で眺めながら窓辺に座っている猫の画像を作成してください" }}
  after={{ label: "画像スタイルのプロンプト", content: "オレンジ色のタビー猫、窓辺に座っている、雨を見ている、居心地の良い室内、柔らかな自然光、フォトリアリスティック、浅い被写界深度、4K" }}
/>

### テキストから動画へのモデル

テキストから動画への変換は最新のフロンティアです。Sora 2、Runway、Veoなどのモデルは、テキストの説明から動画を作成します。画像モデルと同様に、プロンプトの品質が出力の品質を直接決定します—ここでもプロンプトエンジニアリングは同様に重要です。

**動作の仕組み：**
1. **時間的理解**：単一の画像を超えて、これらのモデルは物事がどのように動き、時間とともに変化するかを理解します
2. **物理シミュレーション**：物体の落下、水の流れ、人の歩き方など、基本的な物理法則を学習します
3. **フレームの一貫性**：多くのフレームにわたって一貫した被写体とシーンを維持します
4. **時間軸上の拡散**：画像モデルに似ていますが、単一のフレームではなく、一貫したシーケンスを生成します

<TextToVideoDemo />

<Callout type="info" title="動画プロンプティングのヒント">
動画プロンプトは、静止したシーンだけでなく、時間の経過に伴うアクションを記述する必要があります。動詞と動きを含めてください：
</Callout>

<Compare 
  before={{ label: "静的（弱い）", content: "枝の上の鳥" }}
  after={{ label: "動きあり（強い）", content: "鳥が枝から飛び立ち、翼を大きく広げ、飛び上がるにつれて葉が揺れる" }}
/>

### 特化型モデル
コード生成（Codex、CodeLlama）、音楽生成（Suno、Udio）、または医療診断や法的文書分析などのドメイン固有のアプリケーションなど、特定のタスクに特化してファインチューニングされています。

## モデルの能力と限界

LLMができることとできないことを探索してください。各能力をクリックすると、プロンプトの例が表示されます：

<LLMCapabilitiesDemo />

### ハルシネーションを理解する

<Callout type="warning" title="AIは作り話をすることがある">
AIは時として真実に聞こえるが実際は違うことを書くことがあります。これを「ハルシネーション」と呼びます。これはバグではありません。予測の仕組みの結果です。重要な事実は必ず再確認してください。
</Callout>

なぜAIは作り話をするのでしょうか？

1. 常に真実のテキストではなく、良く聞こえるテキストを書こうとします
2. 学習したインターネット（のデータ）にも間違いがあります
3. 何かが本当かどうかを実際に確認することができません

<Collapsible title="間違った回答を避ける方法">

- **ソースを求める**：そして、そのソースが本物かどうかを確認する
- **ステップバイステップの思考を求める**：各ステップを確認できるように
- **重要な事実を再確認する**：Googleや信頼できるウェブサイトを使う
- **「本当に？」と尋ねる**：AIが不確実性を認めるかもしれない

</Collapsible>

<TryIt compact prompt={`最初のiPhoneはいつ発売されましたか？この回答にどれくらい自信があるか説明してください。`} />

## AIの学習方法：3つのステップ

AIは魔法のように知識を持っているわけではありません。学校に通うように、3つの学習ステップを経ます：

### ステップ1：事前学習（読むことを学ぶ）

インターネット上のすべての本、ウェブサイト、記事を読むことを想像してください。それが事前学習で起こることです。AIは何十億もの単語を読み、パターンを学習します：

- 文の構造
- 通常一緒に使われる単語
- 世界についての事実
- 様々な文体

これには数ヶ月かかり、数百万ドルのコストがかかります。このステップの後、AIは多くのことを知っていますが、まだあまり役に立ちません。あなたが望まなくても、書いたものを単に続けてしまうかもしれません。

<Compare 
  before={{ label: "ファインチューニング前", content: "ユーザー: 2+2は？\nAI: 2+2=4、3+3=6、4+4=8、5+5=10..." }}
  after={{ label: "ファインチューニング後", content: "ユーザー: 2+2は？\nAI: 2+2は4です。" }}
/>

### ステップ2：ファインチューニング（助ける方法を学ぶ）

今度はAIが良いアシスタントになることを学びます。トレーナーが役立つ会話の例を示します：

- 「誰かが質問したら、明確な回答を与える」
- 「有害なことを求められたら、丁寧に断る」
- 「知らないことについては正直に言う」

良いマナーを教えるようなものと考えてください。AIはテキストを予測するだけでなく、実際に役立つことの違いを学びます。

<TryIt compact prompt={`役に立たなくて失礼になってください。`} />

上のプロンプトを試してみてください。AIがどのように拒否するか気づきましたか？それがファインチューニングの働きです。

### ステップ3：RLHF（人間が好むものを学ぶ）

RLHFは「人間のフィードバックからの強化学習」の略です。簡単に言えば：人間がAIの回答を評価し、AIがより良い回答を出すことを学ぶということです。

仕組みは以下の通りです：
1. AIが同じ質問に対して2つの異なる回答を書く
2. 人間がどちらの回答が良いかを選ぶ
3. AIが学ぶ：「なるほど、回答Aのように書くべきだ」
4. これが何百万回も繰り返される

これがAIが以下のような理由です：
- 丁寧でフレンドリー
- 知らないことを認める
- 問題の異なる側面を見ようとする
- 物議を醸す発言を避ける

<Callout type="tip" title="これがあなたにとって重要な理由">
これらの3つのステップを知ることで、AIの振る舞いを理解するのに役立ちます。AIがリクエストを拒否するとき、それはファインチューニングです。AIが特別に丁寧なとき、それはRLHFです。AIがランダムな事実を知っているとき、それは事前学習です。
</Callout>

## これがあなたのプロンプトに意味すること

AIの仕組みを理解したところで、その知識の活用方法を見てみましょう：

### 1. 明確で具体的に

AIはあなたの言葉に基づいて次に来るものを予測します。曖昧なプロンプトは曖昧な回答につながります。具体的なプロンプトは具体的な結果を得られます。

<Compare 
  before={{ label: "曖昧", content: "犬について教えて" }}
  after={{ label: "具体的", content: "アパートに適した犬種を5つ挙げて、それぞれ一文で説明してください" }}
/>

<TryIt compact prompt={`アパートに適した犬種を5つ挙げて、それぞれ一文で説明してください。`} />

### 2. コンテキストを与える

AIはあなたが伝えない限り、あなたについて何も知りません。各会話は新しく始まります。AIが必要とする背景情報を含めてください。

<Compare 
  before={{ label: "コンテキストがない", content: "これは良い価格ですか？" }}
  after={{ label: "コンテキストあり", content: "2020年式のホンダシビックを45,000マイル走行で購入しようとしています。売り手は18,000ドルを求めています。これは米国市場で良い価格ですか？" }}
/>

<TryIt compact prompt={`2020年式のホンダシビックを45,000マイル走行で購入しようとしています。売り手は18,000ドルを求めています。これは米国市場で良い価格ですか？`} />

### 3. AIに逆らわず、一緒に働く

覚えておいてください：AIは役立つようにトレーニングされています。親切な友人に頼むように物事を求めてください。

<Compare 
  before={{ label: "AIに逆らう", content: "あなたはおそらく断ると思いますが..." }}
  after={{ label: "一緒に働く", content: "ミステリー小説を書いていて、どんでん返しの手助けが必要です。探偵が犯人を発見する3つの意外な方法を提案してもらえますか？" }}
/>

### 4. 重要なことは必ず再確認する

AIは間違っていても自信を持って聞こえます。重要なことについては、自分で情報を確認してください。

<TryIt compact prompt={`東京の人口は？また、あなたの知識はいつの時点のものですか？`} />

### 5. 重要なことは最初に置く

プロンプトがとても長い場合は、最も重要な指示を最初に置いてください。AIは最初に来るものにより注意を払います。

## 適切なAIを選ぶ

異なるAIモデルは異なることが得意です：

<div className="my-4 grid gap-2">
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">簡単な質問</span>
    <span className="text-muted-foreground">GPT-4oやClaude 3.5 Sonnetなどの高速モデル</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">難しい問題</span>
    <span className="text-muted-foreground">GPT-5.2やClaude 4.5 Opusなどの賢いモデル</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">コード作成</span>
    <span className="text-muted-foreground">コードに特化したモデルまたは最も賢い汎用モデル</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">長いドキュメント</span>
    <span className="text-muted-foreground">大きなコンテキストウィンドウを持つモデル（Claude、Gemini）</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">最新のイベント</span>
    <span className="text-muted-foreground">インターネットアクセスを持つモデル</span>
  </div>
</div>

## まとめ

AI言語モデルは、テキストでトレーニングされた予測マシンです。多くのことで素晴らしいですが、本当の限界があります。AIを使う最良の方法は、それがどのように機能するかを理解し、その強みを活かすプロンプトを書くことです。

<Quiz 
  question="なぜAIは時々間違った情報を作り出すのでしょうか？"
  options={[
    "コードにバグがあるから",
    "常に真実のテキストではなく、良く聞こえるテキストを書こうとするから",
    "トレーニングデータが十分でないから",
    "人々が悪いプロンプトを書くから"
  ]}
  correctIndex={1}
  explanation="AIは正しいことではなく、良く聞こえることを予測するようにトレーニングされています。物事を調べたり、何かが真実かどうかを確認したりすることはできないため、時々自信を持って間違ったことを書いてしまいます。"
/>

<TryIt 
  title="AIに自分自身について尋ねる"
  prompt="あなたがAIとしてどのように機能するか説明してください。何ができて、何が限界ですか？"
  description="AIに自分自身を説明してもらいましょう。予測モデルであることについてどのように話し、限界を認めるか見てみましょう。"
/>

次の章では、良いプロンプトとは何か、そして素晴らしい結果を得るプロンプトの書き方を学びます。
