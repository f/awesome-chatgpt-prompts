歴史の大部分において、コンピュータは一度に一種類のデータしか扱えませんでした。あるプログラムではテキスト、別のプログラムでは画像、また別の場所では音声というように。しかし、人間は世界をこのように体験していません。私たちは視覚、聴覚、読解、会話を同時に行い、これらすべての入力を組み合わせて環境を理解しています。

**マルチモーダルAI**はすべてを変えます。これらのモデルは複数の種類の情報を同時に処理できます—画像を分析しながらその画像に関するあなたの質問を読んだり、テキストの説明から画像を生成したりできます。この章では、これらの強力なシステムと効果的にコミュニケーションする方法を学びます。

<Callout type="info" title="マルチモーダルとは何か？">
「マルチ」は多数を意味し、「モーダル」はモードまたはデータの種類を指します。マルチモーダルモデルは複数のモダリティ（テキスト、画像、音声、動画、さらにはコード）を扱うことができます。各タイプごとに別々のツールを使う代わりに、1つのモデルがそれらすべてを一緒に理解します。
</Callout>

## なぜマルチモーダルが重要なのか

従来のAIでは、すべてを言葉で説明する必要がありました。画像について質問したい場合は、まずそれを説明しなければなりませんでした。文書を分析したい場合は、手動で文字起こしする必要がありました。マルチモーダルモデルはこれらの障壁を取り除きます。

<InfoGrid items={[
  { label: "見て理解する", description: "画像をアップロードして直接質問できます—説明は不要です", example: "「この回路図の何がおかしいですか？」", color: "blue" },
  { label: "言葉から創造する", description: "欲しいものを説明して画像、音声、動画を生成します", example: "「水彩画スタイルで山々に沈む夕日」", color: "purple" },
  { label: "すべてを組み合わせる", description: "テキスト、画像、その他のメディアを1つの会話で混在させます", example: "「この2つのデザインを比較して、モバイル向けにどちらが良いか教えてください」", color: "green" },
  { label: "文書を分析する", description: "文書、レシート、スクリーンショットの写真から情報を抽出します", example: "「この請求書の写真からすべての明細項目を抽出してください」", color: "amber" }
]} />

## なぜマルチモーダルではプロンプティングがより重要なのか

テキストのみのモデルでは、AIはあなたが入力したものを正確に受け取ります。しかし、マルチモーダルモデルでは、AIは視覚情報や音声情報を解釈しなければなりません—そして解釈にはガイダンスが必要です。

<Compare 
  before={{ label: "曖昧なマルチモーダルプロンプト", content: "この画像に何が見えますか？\n\n[複雑なダッシュボードの画像]" }}
  after={{ label: "ガイド付きマルチモーダルプロンプト", content: "これは私たちの分析ダッシュボードのスクリーンショットです。以下に焦点を当ててください：\n1. 右上のコンバージョン率グラフ\n2. エラー表示や警告があるか\n3. データが正常か異常か\n\n[複雑なダッシュボードの画像]" }}
/>

**ガイダンスなし**では、モデルは色、レイアウト、または無関係な詳細を説明するかもしれません。**ガイダンスあり**では、あなたにとって本当に重要なことに焦点を当てます。

<Callout type="warning" title="解釈のギャップ">
画像を見るとき、あなたはコンテキストと目標に基づいて、何が重要かを即座に判断します。AIはあなたがコンテキストを提供しない限り、このコンテキストを持っていません。壁のひび割れの写真は、構造工学上の懸念、芸術的なテクスチャ、または無関係な背景のいずれかになり得ます。あなたのプロンプトがAIの解釈方法を決定します。
</Callout>

## マルチモーダルの現状

異なるモデルには異なる能力があります。2025年時点で利用可能なものは以下の通りです：

### 理解モデル（入力 → 分析）

これらのモデルは様々なメディアタイプを受け入れ、テキスト分析や応答を生成します。

<InfoGrid items={[
  { label: "GPT-4o / GPT-5", description: "テキスト + 画像 + 音声 → テキスト。128Kコンテキストを持つOpenAIのフラッグシップモデル。強力な創造性と推論能力、幻覚率の低減。", color: "green" },
  { label: "Claude 4 Sonnet/Opus", description: "テキスト + 画像 → テキスト。高度な推論を持つAnthropicの安全性重視モデル。コーディングや複雑なマルチステップタスクに優れています。", color: "purple" },
  { label: "Gemini 2.5", description: "テキスト + 画像 + 音声 + 動画 → テキスト。100万トークンコンテキストを持つGoogleのモデル。自己ファクトチェック、コーディングと研究向けの高速処理。", color: "blue" },
  { label: "LLaMA 4 Scout", description: "テキスト + 画像 + 動画 → テキスト。長い文書やコードベース向けの1000万トークンコンテキストを持つMetaのオープンソースモデル。", color: "cyan" },
  { label: "Grok 4", description: "テキスト + 画像 → テキスト。リアルタイムデータアクセスとソーシャルメディア統合を持つxAIのモデル。最新の応答が可能。", color: "red" }
]} />

### 生成モデル（テキスト → メディア）

これらのモデルはテキストの説明から画像、音声、動画を作成します。

<InfoGrid items={[
  { label: "DALL-E 3", description: "テキスト → 画像。プロンプトの説明に高い精度を持つOpenAIの画像生成ツール。", color: "amber" },
  { label: "Midjourney", description: "テキスト + 画像 → 画像。芸術的な品質、スタイルコントロール、美的な出力で知られています。", color: "pink" },
  { label: "Sora", description: "テキスト → 動画。説明からクリップを作成するOpenAIの動画生成モデル。", color: "red" },
  { label: "Whisper", description: "音声 → テキスト。多言語で高精度を持つOpenAIの音声認識。", color: "cyan" }
]} />

<Callout type="info" title="急速な進化">
マルチモーダルの状況は急速に変化しています。新しいモデルが頻繁にリリースされ、既存のモデルもアップデートを通じて機能を獲得しています。現在の機能と制限については、常に最新のドキュメントを確認してください。
</Callout>

## 画像理解プロンプト

最も一般的なマルチモーダルのユースケースは、AIに画像を分析してもらうことです。重要なのは、何が必要かについてのコンテキストを提供することです。

### 基本的な画像分析

明確なリクエスト構造から始めましょう。モデルにどの側面に焦点を当てるべきか伝えてください。

<TryIt 
  title="構造化された画像分析"
  description="このプロンプトは画像分析のための明確なフレームワークを提供します。モデルはどの情報が必要かを正確に把握します。"
  prompt={`この画像を分析して以下を説明してください：

1. **主要な被写体**：この画像の主な焦点は何ですか？
2. **設定**：これはどこのようですか？（屋内/屋外、場所のタイプ）
3. **雰囲気**：どのような感情的なトーンや雰囲気を伝えていますか？
4. **テキストコンテンツ**：見える文字、看板、ラベルはありますか？
5. **注目すべき詳細**：一目では見落としそうなものは何ですか？
6. **技術的な品質**：照明、フォーカス、構図はどうですか？

[分析したい画像を貼り付けるか説明してください]

画像の説明またはURL：\${imageDescription}`}
/>

### 画像の構造化出力

画像分析をプログラム的に処理する必要がある場合は、JSON出力をリクエストしてください。

<TryIt 
  title="JSON画像分析"
  description="画像分析から構造化されたデータを取得し、アプリケーションで簡単に解析して使用できます。"
  prompt={`この画像を分析して、以下の構造でJSONオブジェクトを返してください：

{
  "summary": "1文での説明",
  "objects": ["見える主なオブジェクトのリスト"],
  "people": {
    "count": "数または'none'",
    "activities": ["何をしているか（いる場合）"]
  },
  "text_detected": ["画像内に見えるテキスト"],
  "colors": {
    "dominant": ["上位3色"],
    "mood": "暖色/寒色/ニュートラル"
  },
  "setting": {
    "type": "屋内/屋外/不明",
    "description": "より具体的な場所の説明"
  },
  "technical": {
    "quality": "高/中/低",
    "lighting": "照明の説明",
    "composition": "フレーミング/構図の説明"
  },
  "confidence": "高/中/低"
}

分析する画像：\${imageDescription}`}
/>

### 比較分析

複数の画像を比較するには、明確なラベル付けと具体的な比較基準が必要です。

<TryIt 
  title="画像比較"
  description="あなたの決定に重要な具体的な基準で2つ以上の画像を比較します。"
  prompt={`\${purpose}のためにこれらの画像を比較してください：

**画像A**：\${imageA}
**画像B**：\${imageB}

以下の基準で各画像を分析してください：
1. \${criterion1}（重要度：高）
2. \${criterion2}（重要度：中）
3. \${criterion3}（重要度：低）

以下を提供してください：
- 各基準の並列比較
- それぞれの強みと弱み
- 理由を添えた明確な推奨
- 懸念事項や注意点`}
/>

## 文書とスクリーンショットの分析

マルチモーダルAIの最も実用的な応用の1つは、文書、スクリーンショット、UI要素の分析です。これにより、手動での文字起こしやレビューに費やす時間を大幅に節約できます。

### 文書の抽出

スキャンした文書、レシートの写真、画像としてのPDFはすべて処理できます。重要なのは、どのタイプの文書であり、どの情報が必要かをモデルに伝えることです。

<TryIt 
  title="文書データ抽出ツール"
  description="文書、レシート、請求書、フォームの写真から構造化されたデータを抽出します。"
  prompt={`これは\${documentType}の写真/スキャンです。

すべての情報を構造化されたJSON形式で抽出してください：

{
  "document_type": "検出されたタイプ",
  "date": "存在する場合",
  "key_fields": {
    "field_name": "value"
  },
  "line_items": [
    {"description": "", "amount": ""}
  ],
  "totals": {
    "subtotal": "",
    "tax": "",
    "total": ""
  },
  "handwritten_notes": ["手書きのテキスト"],
  "unclear_sections": ["読みにくかった部分"],
  "confidence": "高/中/低"
}

重要：テキストが不明確な場合は、推測せずに「unclear_sections」に記載してください。重要な部分が読みにくかった場合は、confidenceを「低」にしてください。

文書の説明：\${documentDescription}`}
/>

### スクリーンショットとUI分析

スクリーンショットは、デバッグ、UXレビュー、ドキュメント作成の宝庫です。重要なことに焦点を当てるようAIを導いてください。

<TryIt 
  title="UI/UXスクリーンショット分析ツール"
  description="デバッグ、UXレビュー、ドキュメント作成のためのスクリーンショットの詳細分析を取得します。"
  prompt={`これは\${applicationName}のスクリーンショットです。

このインターフェースを分析してください：

**識別**
- これはどの画面/ページ/状態ですか？
- ユーザーはここで何を達成しようとしていると思われますか？

**UI要素**
- 主なインタラクティブ要素（ボタン、フォーム、メニュー）
- 現在の状態（選択、入力、展開されているものは？）
- エラーメッセージ、警告、通知はありますか？

**UX評価**
- レイアウトは明確で直感的ですか？
- 混乱を招く要素や不明確なラベルはありますか？
- アクセシビリティの懸念（コントラスト、テキストサイズなど）は？

**検出された問題**
- 視覚的なバグやズレは？
- 切り詰められたテキストやオーバーフローの問題は？
- 一貫性のないスタイリングは？

スクリーンショットの説明：\${screenshotDescription}`}
/>

### エラーメッセージの分析

エラーに遭遇した場合、スクリーンショットにはエラーテキストをコピーするだけよりも多くのコンテキストが含まれていることがよくあります。

<TryIt 
  title="スクリーンショットからのエラー診断"
  description="スクリーンショット内のエラーメッセージについて、わかりやすい説明と修正方法を取得します。"
  prompt={`\${context}でこのエラーが表示されています。

[エラーメッセージ/スクリーンショットを説明または貼り付けてください]
エラーの詳細：\${errorDetails}

以下を提供してください：

1. **わかりやすい説明**：このエラーは実際に何を意味していますか？

2. **考えられる原因**（可能性順）：
   - 最も可能性が高い：
   - その他の可能性：
   - まれなケース：

3. **ステップバイステップの修正**：
   - まず、試してみてください...
   - それでもうまくいかない場合は...
   - 最後の手段として...

4. **予防**：将来このエラーを避ける方法

5. **警告サイン**：このエラーがより深刻な問題を示している可能性がある場合`}
/>

## 画像生成プロンプト

テキストの説明から画像を生成することは一種の芸術です。プロンプトがより具体的で構造化されているほど、結果はあなたのビジョンに近づきます。

### 画像プロンプトの構造

効果的な画像生成プロンプトにはいくつかの構成要素があります：

<InfoGrid items={[
  { label: "被写体", description: "画像の主な焦点は何ですか？", example: "秋の落ち葉で遊ぶゴールデンレトリバー", color: "blue" },
  { label: "スタイル", description: "どのような芸術的スタイルや媒体ですか？", example: "水彩画、デジタルアート、フォトリアリスティック", color: "purple" },
  { label: "構図", description: "シーンはどのように配置されていますか？", example: "クローズアップポートレート、広角風景、俯瞰図", color: "green" },
  { label: "照明", description: "光源と質はどのようなものですか？", example: "柔らかい朝の光、ドラマチックな影、ネオンの輝き", color: "amber" },
  { label: "雰囲気", description: "どのような感情を呼び起こすべきですか？", example: "穏やか、エネルギッシュ、神秘的、ノスタルジック", color: "pink" },
  { label: "詳細", description: "含めるまたは避ける特定の要素", example: "含める：花。避ける：テキスト、ウォーターマーク", color: "cyan" }
]} />

### 基本的な画像生成

<TryIt 
  title="構造化された画像プロンプト"
  description="このテンプレートを使用して、詳細で具体的な画像生成プロンプトを作成します。"
  prompt={`以下の仕様で画像を作成してください：

**被写体**：\${subject}

**スタイル**：\${style}
**媒体**：\${medium}（例：油絵、デジタルアート、写真）

**構図**：
- フレーミング：\${framing}（クローズアップ、ミディアムショット、広角）
- 視点：\${perspective}（目線、ローアングル、俯瞰）
- フォーカス：\${focusArea}

**照明**：
- 光源：\${lightSource}
- 質：\${lightQuality}（柔らかい、硬い、拡散）
- 時間帯：\${timeOfDay}

**カラーパレット**：\${colors}

**雰囲気**：\${mood}

**必ず含める**：\${includeElements}
**必ず避ける**：\${avoidElements}

**技術的**：\${aspectRatio}アスペクト比、高品質`}
/>

### シーン構築

複雑なシーンでは、前景から背景へとレイヤーを説明します。

<TryIt 
  title="レイヤー化されたシーン説明"
  description="各深度レイヤーに何が表示されるかを説明して、複雑なシーンを構築します。"
  prompt={`詳細なシーンを生成してください：

**設定**：\${setting}

**前景**（視聴者に最も近い）：
\${foreground}

**中景**（メインアクションエリア）：
\${middleGround}

**背景**（遠くの要素）：
\${background}

**雰囲気の詳細**：
- 天気/空気：\${weather}
- 照明：\${lighting}
- 時間：\${timeOfDay}

**スタイル**：\${artisticStyle}
**雰囲気**：\${mood}
**カラーパレット**：\${colors}

含める追加の詳細：\${additionalDetails}`}
/>

## 音声プロンプティング

音声処理により、文字起こし、分析、話された内容の理解が可能になります。重要なのは、音声に何が含まれているかについてのコンテキストを提供することです。

### 強化された文字起こし

基本的な文字起こしは始まりに過ぎません。良いプロンプトがあれば、話者の識別、タイムスタンプ、ドメイン固有の精度を得ることができます。

<TryIt 
  title="スマート文字起こし"
  description="話者ラベル、タイムスタンプ、不明確なセクションの処理を含む正確な文字起こしを取得します。"
  prompt={`この音声録音を文字起こししてください。

**コンテキスト**：\${recordingType}（会議、インタビュー、ポッドキャスト、講義など）
**予想される話者**：\${speakerCount}人（\${speakerRoles}）
**ドメイン**：\${domain}（予想される専門用語：\${technicalTerms}）

**出力形式**：
[00:00] **話者1（名前/役割）**：ここに文字起こしされたテキスト。
[00:15] **話者2（名前/役割）**：ここに返答。

**指示**：
- 自然な区切り（30-60秒ごとまたは話者の変更時）でタイムスタンプを含める
- 不明確なセクションは[聞き取れない]または[不明確：推測？]としてマークする
- 非音声の音を括弧で記載：[笑い声]、[電話の着信音]、[長い沈黙]
- 意味がある場合のみフィラーワードを保持（えー、うーは削除可能）
- アクションアイテムや決定事項は→記号でフラグを付ける

音声の説明：\${audioDescription}`}
/>

### 音声コンテンツ分析

文字起こし以外にも、AIは音声のコンテンツ、トーン、重要な瞬間を分析できます。

<TryIt 
  title="音声コンテンツ分析ツール"
  description="要約、重要な瞬間、感情を含む音声コンテンツの包括的な分析を取得します。"
  prompt={`この音声録音を分析してください：

音声の説明：\${audioDescription}

以下を提供してください：

**1. エグゼクティブサマリー**（2-3文）
この録音は何についてですか？主な要点は何ですか？

**2. 話者**
- 何人の異なる話者がいますか？
- 特徴（識別可能な場合）：トーン、話し方、専門レベル

**3. コンテンツの内訳**
- 議論された主なトピック（おおよそのタイムスタンプ付き）
- 主なポイント
- 提起された質問

**4. 感情分析**
- 全体的なトーン（フォーマル、カジュアル、緊張、フレンドリー）
- 注目すべき感情的な瞬間
- 全体を通じてのエネルギーレベル

**5. アクション項目**
- 下された決定
- 言及されたアクションアイテム
- 必要なフォローアップ

**6. 注目すべき引用**
タイムスタンプ付きで2-3の重要な引用を抜粋

**7. 音声品質**
- 全体的な明瞭さ
- 問題点（背景ノイズ、中断、技術的な問題）`}
/>

## 動画プロンプティング

動画は視覚と音声の分析を時間を通じて組み合わせます。課題は、全体の長さにわたって関連する側面に焦点を当てるようAIを導くことです。

### 動画の理解

<TryIt 
  title="包括的な動画分析"
  description="タイムライン、視覚要素、重要な瞬間を含む動画コンテンツの構造化された内訳を取得します。"
  prompt={`この動画を分析してください：\${videoDescription}

包括的な分析を提供してください：

**1. 概要**（2-3文）
この動画は何についてですか？主なメッセージや目的は何ですか？

**2. 重要な瞬間のタイムライン**
| タイムスタンプ | イベント | 重要性 |
|---------------|---------|--------|
| 0:00 | ... | ... |

**3. 視覚分析**
- 設定/場所：これはどこで撮影されていますか？
- 人物：誰が登場しますか？何をしていますか？
- オブジェクト：主なアイテムや小道具
- 視覚スタイル：品質、編集、使用されているグラフィックス

**4. 音声分析**
- 音声：主なポイント（対話がある場合）
- 音楽：タイプ、雰囲気、どのように使用されているか
- 効果音：注目すべき音声要素

**5. 制作品質**
- 動画の品質と編集
- ペースと構成
- 目的に対する効果

**6. ターゲットオーディエンス**
この動画は誰のために作られていますか？彼らに適切に提供されていますか？

**7. 主な要点**
視聴者はこの動画から何を覚えておくべきですか？`}
/>

### 動画コンテンツの抽出

動画から特定の情報を抽出するには、必要なものについて正確に指定してください。

<TryIt 
  title="動画データ抽出ツール"
  description="タイムスタンプと構造化された出力で動画から特定の情報を抽出します。"
  prompt={`この動画から特定の情報を抽出してください：

動画タイプ：\${videoType}
動画の説明：\${videoDescription}

**抽出する情報**：
1. \${extractItem1}
2. \${extractItem2}
3. \${extractItem3}

**出力形式**：
{
  "video_summary": "簡単な説明",
  "duration": "推定の長さ",
  "extracted_data": [
    {
      "timestamp": "MM:SS",
      "item": "見つかったもの",
      "details": "追加のコンテキスト",
      "confidence": "高/中/低"
    }
  ],
  "items_not_found": ["リクエストされたが存在しなかったもののリスト"],
  "additional_observations": "明示的にリクエストされていないが関連するもの"
}`}
/>

## マルチモーダルの組み合わせ

マルチモーダルAIの真の力は、異なるタイプの入力を組み合わせるときに発揮されます。これらの組み合わせにより、単一のモダリティでは不可能だった分析が可能になります。

### 画像 + テキストの検証

画像とその説明が一致するかどうかを確認します—Eコマース、コンテンツモデレーション、品質保証に不可欠です。

<TryIt 
  title="画像とテキストの整合性チェッカー"
  description="画像がテキストの説明を正確に表しているか、またその逆を検証します。"
  prompt={`この画像と付随するテキストの整合性を分析してください：

**画像**：\${imageDescription}
**テキストの説明**：「\${textDescription}」

評価：

**1. 精度の一致**
- 画像はテキストが説明しているものを示していますか？
- スコア：[1-10] 説明付き

**2. テキストの主張 vs 視覚的な現実**
| テキストの主張 | 画像で見えますか？ | 備考 |
|---------------|-------------------|------|
| ... | はい/いいえ/部分的 | ... |

**3. 言及されていない視覚要素**
画像には見えるがテキストで説明されていないものは何ですか？

**4. 見えないテキストの主張**
テキストで説明されているが画像から確認できないものは何ですか？

**5. 推奨事項**
- テキストについて：[画像に合わせる改善点]
- 画像について：[テキストに合わせる改善点]

**6. 総合評価**
この画像とテキストのペアは\${purpose}として信頼できますか？`}
/>

### スクリーンショット + コードのデバッグ

開発者にとって最も強力な組み合わせの1つ：視覚的なバグとコードを同時に見ることができます。

<TryIt 
  title="ビジュアルバグデバッガー"
  description="視覚的な出力とソースコードの両方を一緒に分析してUIの問題をデバッグします。"
  prompt={`UIのバグがあります。見えているものとコードは以下の通りです：

**スクリーンショットの説明**：\${screenshotDescription}
**問題点**：\${bugDescription}
**期待される動作**：\${expectedBehavior}

**関連するコード**：
\`\`\`\${language}
\${code}
\`\`\`

以下を教えてください：

**1. 根本原因の分析**
- コードのどの部分がこの視覚的な問題を引き起こしていますか？
- 具体的にどの行が原因ですか？

**2. 説明**
- なぜこのコードがこの視覚的な結果を生成するのですか？
- 根底にあるメカニズムは何ですか？

**3. 修正**
\`\`\`\${language}
// 修正されたコードをここに
\`\`\`

**4. 予防**
- 将来このタイプのバグを避ける方法
- チェックすべき関連する問題`}
/>

### 複数画像の意思決定

オプションを選択する際、構造化された比較がより良い決定を下すのに役立ちます。

<TryIt 
  title="ビジュアルオプション比較ツール"
  description="基準に対して複数の画像を体系的に比較し、情報に基づいた決定を下します。"
  prompt={`\${purpose}のためにこれらのオプションから選択しています：

**オプションA**：\${optionA}
**オプションB**：\${optionB}
**オプションC**：\${optionC}

**私の基準**（重要度順）：
1. \${criterion1}（重み：高）
2. \${criterion2}（重み：中）
3. \${criterion3}（重み：低）

以下を提供してください：

**比較マトリックス**
| 基準 | オプションA | オプションB | オプションC |
|------|------------|------------|------------|
| \${criterion1} | スコア + 備考 | ... | ... |
| \${criterion2} | ... | ... | ... |
| \${criterion3} | ... | ... | ... |

**加重スコア**
- オプションA：X/10
- オプションB：X/10
- オプションC：X/10

**推奨**
あなたの述べた優先順位に基づいて、[オプション]を推奨します。なぜなら...

**注意事項**
- [条件]の場合は、代わりに[代替案]を検討してください
- [潜在的な問題]に注意してください`}
/>

## マルチモーダルプロンプトのベストプラクティス

マルチモーダルAIから素晴らしい結果を得るには、その能力と限界の両方を理解する必要があります。

### マルチモーダルプロンプトを効果的にするもの

<InfoGrid items={[
  { label: "コンテキストを提供する", description: "メディアが何であり、なぜ分析しているのかをモデルに伝えます", example: "「これはEコマースサイト用の商品写真です...」", color: "green" },
  { label: "具体的にする", description: "一般的な印象ではなく、特定の要素について尋ねます", example: "「右上の価格表に焦点を当ててください」", color: "green" },
  { label: "場所を参照する", description: "空間的な言葉を使って特定のエリアを指し示します", example: "「左下の象限に...」", color: "green" },
  { label: "目標を述べる", description: "分析を何に使用するかを説明します", example: "「この画像がモバイルアプリに適しているかどうかを判断する必要があります」", color: "green" }
]} />

### 避けるべき一般的な落とし穴

<InfoGrid items={[
  { label: "完璧な視覚を仮定する", description: "モデルは小さな詳細を見逃す可能性があります。特に低解像度の画像では", example: "圧縮されたスクリーンショットの8ptテキストについて尋ねないでください", color: "red" },
  { label: "完璧なOCRを期待する", description: "手書き、珍しいフォント、複雑なレイアウトはエラーを引き起こす可能性があります", example: "レシートやフォームから抽出したテキストを確認してください", color: "red" },
  { label: "コンテンツポリシーを無視する", description: "モデルには特定のタイプのコンテンツに対する制限があります", example: "特定の個人を識別したり、不適切なコンテンツを分析したりしません", color: "red" },
  { label: "検証をスキップする", description: "メディアから抽出した重要な情報は常に検証してください", example: "文書抽出からの数字、日付、名前を再確認してください", color: "red" }
]} />

### 制限をうまく処理する

<TryIt 
  title="不確実性を考慮した画像分析"
  description="このプロンプトは、モデルがはっきり見えない場合や不確実な場合を明示的に処理します。"
  prompt={`この画像を分析してください：\${imageDescription}

**不確実性を処理するための指示**：

何かがはっきり見えない場合：
- 詳細を推測したり作り上げたりしないでください
- 「[見えるもの]は見えますが、[不明確な要素]ははっきり認識できません」と言ってください
- どのような追加情報があれば役立つか提案してください

コンテンツが制限されているように見える場合：
- 何を分析でき、何を分析できないか説明してください
- 分析の許可された側面に焦点を当ててください

人物について尋ねられた場合：
- 行動、位置、一般的な特徴を説明してください
- 特定の個人を識別しようとしないでください
- 焦点を当てる：人数、活動、表情、服装

**あなたの分析**：
[これらのガイドラインを適用して分析を進めてください]`}
/>

<Quiz 
  question="なぜテキストのみのモデルよりもマルチモーダルモデルの方がプロンプティングがより重要なのですか？"
  options={[
    "マルチモーダルモデルは知能が低く、より多くの助けが必要だから",
    "画像と音声は本質的に曖昧であり、AIはどの側面が重要かを知るためにコンテキストが必要だから",
    "マルチモーダルモデルは一度に1種類の入力しか処理できないから",
    "テキストプロンプトはマルチモーダルモデルでは機能しないから"
  ]}
  correctIndex={1}
  explanation="画像を見るとき、あなたは目標に基づいて何が重要かを即座に判断します。AIはこのコンテキストを持っていません—壁のひび割れの写真は、工学的な懸念、芸術的なテクスチャ、または無関係な背景のいずれかになり得ます。あなたのプロンプトが、AIが提供されたメディアをどのように解釈し、焦点を当てるかを決定します。"
/>
