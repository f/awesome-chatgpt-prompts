# Appendix C: Glossary

Key terms and definitions for prompt engineering and AI.

## A

**Agent**
An AI system that can take actions, use tools, and work autonomously toward goals rather than just responding to single queries.

**Alignment**
The degree to which an AI system's behavior matches intended human values and goals.

**API (Application Programming Interface)**
A way for programs to communicate with AI services, sending prompts and receiving responses programmatically.

**Attention Mechanism**
The component of transformer models that determines which parts of the input to focus on when generating each part of the output.

## C

**Chain of Thought (CoT)**
A prompting technique that asks the model to show step-by-step reasoning, improving performance on complex tasks.

**Completion**
The text generated by an AI model in response to a prompt.

**Context Window**
The maximum amount of text (measured in tokens) that a model can process at once, including both input and output.

**Constitutional AI**
An approach to AI alignment where models are trained to follow a set of principles or "constitution."

## D

**Default Value**
In prompt templates, a value used when a variable isn't explicitly provided. Syntax: `\${variable:default}`

## E

**Embedding**
A numerical representation of text that captures semantic meaning, used for search and similarity comparisons.

**Elicitation**
In MCP, the process of requesting variable values from users when a prompt requires input.

## F

**Few-Shot Learning**
Teaching a model to perform a task by providing examples in the prompt, without any fine-tuning.

**Fine-Tuning**
Training a pre-trained model on specific data to improve performance on particular tasks.

## G

**GPT (Generative Pre-trained Transformer)**
A family of large language models developed by OpenAI, trained to generate human-like text.

**Grounding**
Connecting AI responses to verifiable information sources to reduce hallucinations.

## H

**Hallucination**
When an AI model generates plausible-sounding but incorrect or fabricated information.

## I

**Inference**
The process of running a trained model to generate outputs from inputs.

**In-Context Learning**
The ability of LLMs to learn tasks from examples provided in the prompt without weight updates.

## J

**Jailbreak**
An attempt to bypass AI safety measures through crafted prompts.

**JSON Mode**
A model setting that ensures output is valid JSON format.

## L

**Large Language Model (LLM)**
An AI model with billions of parameters trained on vast text data to understand and generate language.

**Latency**
The time between sending a prompt and receiving a response.

## M

**MCP (Model Context Protocol)**
A standard protocol for connecting AI systems with external tools and data sources.

**Multimodal**
AI models that can process multiple types of input (text, images, audio, video).

## N

**Natural Language Processing (NLP)**
The field of AI focused on enabling computers to understand and generate human language.

## O

**One-Shot Learning**
Learning from a single example, as opposed to few-shot (multiple examples) or zero-shot (no examples).

## P

**Parameter**
A value in a neural network that is learned during training. More parameters generally mean more capable models.

**Persona**
A role or character assigned to an AI in a prompt to influence its responses.

**Prompt**
The input text provided to an AI model to elicit a response.

**Prompt Chaining**
Connecting multiple prompts in sequence, where each prompt's output feeds into the next.

**Prompt Engineering**
The practice of designing and refining prompts to achieve desired AI outputs.

**Prompt Injection**
An attack where malicious instructions are embedded in user input to override system instructions.

## R

**RAG (Retrieval-Augmented Generation)**
A technique that enhances AI responses by retrieving relevant information from external sources before generating.

**RLHF (Reinforcement Learning from Human Feedback)**
A training method where human preferences guide model behavior.

**Role-Based Prompting**
Assigning a specific role or persona to the AI to influence its responses.

## S

**Semantic Search**
Search based on meaning rather than keyword matching, typically using embeddings.

**System Prompt**
Special instructions that set the AI's behavior for an entire conversation, typically hidden from users.

**Structured Output**
AI responses in specific formats like JSON or YAML that can be programmatically parsed.

## T

**Temperature**
A parameter controlling randomness in AI outputs. Lower = more deterministic, higher = more creative.

**Token**
The basic unit of text that LLMs process. Roughly 4 characters or 0.75 words in English.

**Transformer**
The neural network architecture underlying most modern LLMs, using attention mechanisms.

## V

**Variable**
A placeholder in a prompt template that can be filled with different values. Syntax: `\${variable_name}`

## Z

**Zero-Shot**
Performing a task without any examples, relying only on the model's pre-trained knowledge and instructions.

---

## Symbols & Notation

| Symbol | Meaning |
|--------|---------|
| `\${var}` | Variable placeholder |
| `\${var:default}` | Variable with default value |
| `[text]` | Placeholder for user content |
| `...` | Content continues/truncated |
| `→` | Leads to / results in |
| `✓` | Correct / recommended |
| `✗` | Incorrect / avoid |

## Common Abbreviations

| Abbr | Full Form |
|------|-----------|
| AI | Artificial Intelligence |
| API | Application Programming Interface |
| CoT | Chain of Thought |
| GPT | Generative Pre-trained Transformer |
| JSON | JavaScript Object Notation |
| LLM | Large Language Model |
| MCP | Model Context Protocol |
| NLP | Natural Language Processing |
| RAG | Retrieval-Augmented Generation |
| RLHF | Reinforcement Learning from Human Feedback |
| YAML | YAML Ain't Markup Language |
