在计算机发展的大部分历史中，它们一次只能处理一种类型的数据：文本在一个程序中，图像在另一个程序中，音频又在其他地方。但人类并不是这样体验世界的。我们同时看、听、读和说，将所有这些输入结合起来理解我们的环境。

**多模态 AI** 改变了一切。这些模型可以同时处理多种类型的信息——在阅读你关于图像的问题时分析图像，或者根据你的文字描述生成图像。本章将教你如何有效地与这些强大的系统进行沟通。

<Callout type="info" title="什么是多模态？">
"Multi"意味着多种，"modal"指的是模式或数据类型。多模态模型可以处理多种模态：文本、图像、音频、视频，甚至代码。不再需要为每种类型使用单独的工具，一个模型就能理解所有这些。
</Callout>

## 为什么多模态很重要

传统 AI 需要你用文字描述一切。想询问关于图像的问题？你必须先描述它。想分析一份文档？你需要手动转录它。多模态模型消除了这些障碍。

<InfoGrid items={[
  { label: "观看并理解", description: "上传图像并直接提问——无需描述", example: "\"这个电路图有什么问题？\"", color: "blue" },
  { label: "从文字创作", description: "描述你想要的内容，生成图像、音频或视频", example: "\"水彩风格的山间日落\"", color: "purple" },
  { label: "组合一切", description: "在单次对话中混合文本、图像和其他媒体", example: "\"比较这两个设计，告诉我哪个更适合移动端\"", color: "green" },
  { label: "分析文档", description: "从文档、收据或截图的照片中提取信息", example: "\"从这张发票照片中提取所有行项目\"", color: "amber" }
]} />

## 为什么提示词对多模态更加重要

对于纯文本模型，AI 接收的正是你输入的内容。但对于多模态模型，AI 必须解释视觉或音频信息——而解释需要引导。

<Compare 
  before={{ label: "模糊的多模态提示词", content: "你在这张图片中看到了什么？\n\n[复杂仪表盘的图像]" }}
  after={{ label: "有引导的多模态提示词", content: "这是我们分析仪表盘的截图。请关注：\n1. 右上角的转化率图表\n2. 任何错误指示器或警告\n3. 数据看起来是否正常或异常\n\n[复杂仪表盘的图像]" }}
/>

**没有引导时**，模型可能会描述颜色、布局或无关的细节。**有引导时**，它会专注于对你真正重要的内容。

<Callout type="warning" title="解释鸿沟">
当你看一张图片时，你会根据自己的背景和目标立即知道什么是重要的。AI 没有这种背景，除非你提供。一张墙上裂缝的照片可能是：结构工程问题、艺术纹理，或者无关的背景。你的提示词决定了 AI 如何解释它。
</Callout>

## 多模态领域概览

不同的模型有不同的能力。以下是 2025 年的可用情况：

### 理解模型（输入 → 分析）

这些模型接受各种媒体类型，并产生文本分析或回复。

<InfoGrid items={[
  { label: "GPT-4o / GPT-5", description: "文本 + 图像 + 音频 → 文本。OpenAI 的旗舰产品，拥有 128K 上下文，强大的创意和推理能力，幻觉率降低。", color: "green" },
  { label: "Claude 4 Sonnet/Opus", description: "文本 + 图像 → 文本。Anthropic 注重安全的模型，具有高级推理能力，非常适合编程和复杂的多步骤任务。", color: "purple" },
  { label: "Gemini 2.5", description: "文本 + 图像 + 音频 + 视频 → 文本。Google 的模型，拥有 1M token 上下文，自我事实核查，快速处理编程和研究任务。", color: "blue" },
  { label: "LLaMA 4 Scout", description: "文本 + 图像 + 视频 → 文本。Meta 的开源模型，拥有海量 10M token 上下文，适用于长文档和代码库。", color: "cyan" },
  { label: "Grok 4", description: "文本 + 图像 → 文本。xAI 的模型，具有实时数据访问和社交媒体集成，提供最新的回复。", color: "red" }
]} />

### 生成模型（文本 → 媒体）

这些模型根据文字描述创建图像、音频或视频。

<InfoGrid items={[
  { label: "DALL-E 3", description: "文本 → 图像。OpenAI 的图像生成器，对提示词描述的准确度很高。", color: "amber" },
  { label: "Midjourney", description: "文本 + 图像 → 图像。以艺术质量、风格控制和美学输出著称。", color: "pink" },
  { label: "Sora", description: "文本 → 视频。OpenAI 的视频生成模型，根据描述创建视频片段。", color: "red" },
  { label: "Whisper", description: "音频 → 文本。OpenAI 的语音转文字工具，跨语言准确率很高。", color: "cyan" }
]} />

<Callout type="info" title="快速演进">
多模态领域变化很快。新模型频繁发布，现有模型通过更新获得新功能。请务必查看最新文档以了解当前的功能和限制。
</Callout>

## 图像理解提示词

最常见的多模态用例是让 AI 分析图像。关键是提供你需要什么的背景信息。

### 基础图像分析

从清晰的请求结构开始。告诉模型要关注哪些方面。

<TryIt 
  title="结构化图像分析"
  description="这个提示词为图像分析提供了清晰的框架。模型准确知道你需要什么信息。"
  prompt={`分析这张图像并描述：

1. **主体**：这张图像的主要焦点是什么？
2. **场景**：这看起来在哪里？（室内/室外，地点类型）
3. **情绪**：它传达了什么情感基调或氛围？
4. **文字内容**：任何可见的文字、标志或标签？
5. **值得注意的细节**：有什么可能一眼看不到的内容？
6. **技术质量**：光线、对焦和构图如何？

[粘贴或描述你想分析的图像]

图像描述或 URL：\${imageDescription}`}
/>

### 图像的结构化输出

当你需要以编程方式处理图像分析时，请求 JSON 输出。

<TryIt 
  title="JSON 图像分析"
  description="从图像分析中获取结构化数据，便于在应用程序中解析和使用。"
  prompt={`分析这张图像并返回以下结构的 JSON 对象：

{
  "summary": "一句话描述",
  "objects": ["可见主要物体列表"],
  "people": {
    "count": "数量或'无'",
    "activities": ["他们在做什么，如果有的话"]
  },
  "text_detected": ["图像中可见的任何文字"],
  "colors": {
    "dominant": ["前三种主色"],
    "mood": "暖色调/冷色调/中性色调"
  },
  "setting": {
    "type": "室内/室外/未知",
    "description": "更具体的地点描述"
  },
  "technical": {
    "quality": "高/中/低",
    "lighting": "光线描述",
    "composition": "取景/构图描述"
  },
  "confidence": "高/中/低"
}

要分析的图像：\${imageDescription}`}
/>

### 对比分析

比较多张图像需要清晰的标签和具体的比较标准。

<TryIt 
  title="图像比较"
  description="使用对你决策重要的具体标准比较两张或多张图像。"
  prompt={`为 \${purpose} 比较这些图像：

**图像 A**：\${imageA}
**图像 B**：\${imageB}

根据以下标准分析每张图像：
1. \${criterion1}（重要性：高）
2. \${criterion2}（重要性：中）  
3. \${criterion3}（重要性：低）

提供：
- 每个标准的并排比较
- 每个选项的优缺点
- 带有理由的明确推荐
- 任何顾虑或注意事项`}
/>

## 文档和截图分析

多模态 AI 最实用的应用之一是分析文档、截图和 UI 元素。这可以节省数小时的手动转录和审查时间。

### 文档提取

扫描文档、收据照片和作为图像的 PDF 都可以处理。关键是告诉模型这是什么类型的文档以及你需要什么信息。

<TryIt 
  title="文档数据提取器"
  description="从文档、收据、发票或表格的照片中提取结构化数据。"
  prompt={`这是一张 \${documentType} 的照片/扫描件。

将所有信息提取为结构化 JSON 格式：

{
  "document_type": "检测到的类型",
  "date": "如果存在",
  "key_fields": {
    "field_name": "value"
  },
  "line_items": [
    {"description": "", "amount": ""}
  ],
  "totals": {
    "subtotal": "",
    "tax": "",
    "total": ""
  },
  "handwritten_notes": ["任何手写文字"],
  "unclear_sections": ["难以阅读的区域"],
  "confidence": "高/中/低"
}

重要提示：如果任何文字不清楚，请在"unclear_sections"中注明，而不是猜测。如果有大部分内容难以阅读，请将置信度标记为"低"。

文档描述：\${documentDescription}`}
/>

### 截图和 UI 分析

截图是调试、用户体验审查和文档编写的宝库。引导 AI 关注重要的内容。

<TryIt 
  title="UI/UX 截图分析器"
  description="获取截图的详细分析，用于调试、用户体验审查或文档编写。"
  prompt={`这是 \${applicationName} 的截图。

分析这个界面：

**识别**
- 这是什么屏幕/页面/状态？
- 用户在这里可能想要完成什么？

**UI 元素**
- 关键交互元素（按钮、表单、菜单）
- 当前状态（有什么被选中、填写或展开了吗？）
- 任何错误消息、警告或通知？

**UX 评估**
- 布局是否清晰直观？
- 有任何令人困惑的元素或不清楚的标签吗？
- 无障碍问题（对比度、文字大小等）？

**检测到的问题**
- 视觉错误或错位？
- 截断的文字或溢出问题？
- 不一致的样式？

截图描述：\${screenshotDescription}`}
/>

### 错误消息分析

当你遇到错误时，截图通常比单独复制错误文本包含更多上下文信息。

<TryIt 
  title="从截图诊断错误"
  description="获取截图中错误消息的通俗解释和修复方法。"
  prompt={`我在 \${context} 中看到这个错误。

[描述或粘贴错误消息/截图]
错误详情：\${errorDetails}

请提供：

1. **通俗解释**：这个错误实际上是什么意思？

2. **可能原因**（按概率排序）：
   - 最可能：
   - 也可能：
   - 较少见：

3. **逐步修复**：
   - 首先，尝试...
   - 如果不行...
   - 作为最后手段...

4. **预防**：将来如何避免这个错误

5. **警示信号**：这个错误何时可能表明更严重的问题`}
/>

## 图像生成提示词

从文字描述生成图像是一门艺术。你的提示词越具体和结构化，结果就越接近你的设想。

### 图像提示词的结构

有效的图像生成提示词包含几个组成部分：

<InfoGrid items={[
  { label: "主体", description: "图像的主要焦点是什么？", example: "一只金毛寻回犬在秋叶中玩耍", color: "blue" },
  { label: "风格", description: "什么艺术风格或媒介？", example: "水彩画、数字艺术、照片级真实感", color: "purple" },
  { label: "构图", description: "场景如何安排？", example: "特写肖像、广角风景、鸟瞰视角", color: "green" },
  { label: "光线", description: "光源和质量是什么？", example: "柔和的晨光、戏剧性的阴影、霓虹灯光", color: "amber" },
  { label: "情绪", description: "应该唤起什么感觉？", example: "宁静、充满活力、神秘、怀旧", color: "pink" },
  { label: "细节", description: "要包含或避免的具体元素", example: "包含：花朵。避免：文字、水印", color: "cyan" }
]} />

### 基础图像生成

<TryIt 
  title="结构化图像提示词"
  description="使用这个模板创建详细、具体的图像生成提示词。"
  prompt={`使用以下规格创建图像：

**主体**：\${subject}

**风格**：\${style}
**媒介**：\${medium}（如油画、数字艺术、照片）

**构图**：
- 取景：\${framing}（特写、中景、广角）
- 视角：\${perspective}（平视、仰视、俯视）
- 焦点：\${focusArea}

**光线**：
- 光源：\${lightSource}
- 质量：\${lightQuality}（柔和、强烈、漫射）
- 时间：\${timeOfDay}

**色彩调色板**：\${colors}

**情绪/氛围**：\${mood}

**必须包含**：\${includeElements}
**必须避免**：\${avoidElements}

**技术参数**：\${aspectRatio} 宽高比，高质量`}
/>

### 场景构建

对于复杂场景，从前景到背景逐层描述。

<TryIt 
  title="分层场景描述"
  description="通过描述每个深度层中出现的内容来构建复杂场景。"
  prompt={`生成一个详细的场景：

**场景设定**：\${setting}

**前景**（最靠近观众）：
\${foreground}

**中景**（主要动作区域）：
\${middleGround}

**背景**（远处元素）：
\${background}

**氛围细节**：
- 天气/空气：\${weather}
- 光线：\${lighting}
- 时间：\${timeOfDay}

**风格**：\${artisticStyle}
**情绪**：\${mood}
**色彩调色板**：\${colors}

要包含的额外细节：\${additionalDetails}`}
/>

## 音频提示词

音频处理开启了转录、分析和理解语音内容的大门。关键是提供关于音频内容的背景信息。

### 增强转录

基础转录只是开始。通过好的提示词，你可以获得说话人识别、时间戳和特定领域的准确性。

<TryIt 
  title="智能转录"
  description="获取带有说话人标签、时间戳和不清楚部分处理的准确转录。"
  prompt={`转录这段音频录音。

**背景**：\${recordingType}（会议、访谈、播客、讲座等）
**预期说话人**：\${speakerCount}（\${speakerRoles}）
**领域**：\${domain}（预期的专业术语：\${technicalTerms}）

**输出格式**：
[00:00] **说话人 1（姓名/角色）**：转录的文字在这里。
[00:15] **说话人 2（姓名/角色）**：他们的回应在这里。

**说明**：
- 在自然停顿处包含时间戳（每 30-60 秒或说话人切换时）
- 将不清楚的部分标记为 [听不清] 或 [不确定：最佳猜测？]
- 用方括号注明非语音声音：[笑声]、[电话铃声]、[长时间停顿]
- 只有在有意义时才保留填充词（嗯、啊可以删除）
- 用 → 符号标记任何行动项目或决定

音频描述：\${audioDescription}`}
/>

### 音频内容分析

除了转录，AI 还可以分析音频中的内容、语气和关键时刻。

<TryIt 
  title="音频内容分析器"
  description="获取音频内容的全面分析，包括摘要、关键时刻和情感。"
  prompt={`分析这段音频录音：

音频描述：\${audioDescription}

提供：

**1. 执行摘要**（2-3 句话）
这段录音是关于什么的？主要收获是什么？

**2. 说话人**
- 有多少不同的说话人？
- 特征（如果可辨别）：语气、说话风格、专业水平

**3. 内容细分**
- 讨论的主要话题（附大致时间戳）
- 提出的关键观点
- 提出的问题

**4. 情感分析**
- 整体语气（正式、随意、紧张、友好）
- 值得注意的情感时刻
- 整体的能量水平

**5. 可行动项目**
- 做出的决定
- 提到的行动项目
- 需要的后续跟进

**6. 值得注意的引用**
提取 2-3 句重要引用并附上时间戳

**7. 音频质量**
- 整体清晰度
- 任何问题（背景噪音、打断、技术问题）`}
/>

## 视频提示词

视频结合了随时间变化的视觉和音频分析。挑战在于引导 AI 在整个时长内关注相关方面。

### 视频理解

<TryIt 
  title="全面视频分析"
  description="获取视频内容的结构化分解，包括时间线、视觉元素和关键时刻。"
  prompt={`分析这个视频：\${videoDescription}

提供全面分析：

**1. 概述**（2-3 句话）
这个视频是关于什么的？主要信息或目的是什么？

**2. 关键时刻时间线**
| 时间戳 | 事件 | 重要性 |
|--------|------|--------|
| 0:00 | ... | ... |

**3. 视觉分析**
- 场景/地点：这发生在哪里？
- 人物：谁出现了？他们在做什么？
- 物品：展示的关键物品或道具
- 视觉风格：质量、剪辑、使用的图形

**4. 音频分析**
- 语音：主要观点（如果有对话）
- 音乐：类型、情绪、如何使用
- 音效：值得注意的音频元素

**5. 制作质量**
- 视频质量和剪辑
- 节奏和结构
- 对其目的的有效性

**6. 目标受众**
这个视频是为谁制作的？它是否很好地服务了他们？

**7. 关键要点**
观众应该从这个视频中记住什么？`}
/>

### 视频内容提取

对于从视频中提取特定信息，要精确说明你需要什么。

<TryIt 
  title="视频数据提取器"
  description="从视频中提取特定信息，附带时间戳和结构化输出。"
  prompt={`从这个视频中提取特定信息：

视频类型：\${videoType}
视频描述：\${videoDescription}

**要提取的信息**：
1. \${extractItem1}
2. \${extractItem2}
3. \${extractItem3}

**输出格式**：
{
  "video_summary": "简短描述",
  "duration": "估计时长",
  "extracted_data": [
    {
      "timestamp": "MM:SS",
      "item": "发现了什么",
      "details": "额外背景",
      "confidence": "高/中/低"
    }
  ],
  "items_not_found": ["列出请求但未找到的任何内容"],
  "additional_observations": "任何未明确请求但相关的内容"
}`}
/>

## 多模态组合

多模态 AI 的真正威力在于你组合不同类型输入时显现出来。这些组合实现了单一模态无法完成的分析。

### 图像 + 文字验证

检查图像和描述是否匹配——对于电子商务、内容审核和质量保证至关重要。

<TryIt 
  title="图像-文字对齐检查器"
  description="验证图像是否准确代表其文字描述，反之亦然。"
  prompt={`分析这张图像及其配套文字的对齐程度：

**图像**：\${imageDescription}
**文字描述**："\${textDescription}"

评估：

**1. 准确度匹配**
- 图像是否显示了文字描述的内容？
- 评分：[1-10] 附解释

**2. 文字声明与视觉现实**
| 文字中的声明 | 在图像中可见？ | 备注 |
|--------------|----------------|------|
| ... | 是/否/部分 | ... |

**3. 未提及的视觉元素**
图像中可见但文字未描述的内容有哪些？

**4. 不可见的文字声明**
文字中描述但无法从图像验证的内容有哪些？

**5. 建议**
- 对于文字：[改进以匹配图像]
- 对于图像：[改进以匹配文字]

**6. 总体评估**
这个图像-文字配对对于 \${purpose} 是否可信？`}
/>

### 截图 + 代码调试

对开发者来说最强大的组合之一：同时查看视觉错误和代码。

<TryIt 
  title="可视化错误调试器"
  description="通过同时分析视觉输出和源代码来调试 UI 问题。"
  prompt={`我有一个 UI 错误。这是我看到的和我的代码：

**截图描述**：\${screenshotDescription}
**问题所在**：\${bugDescription}
**预期行为**：\${expectedBehavior}

**相关代码**：
\`\`\`\${language}
\${code}
\`\`\`

请帮我：

**1. 根本原因分析**
- 代码中的什么导致了这个视觉问题？
- 具体是哪一行负责？

**2. 解释**
- 为什么这段代码产生了这个视觉结果？
- 底层机制是什么？

**3. 修复方案**
\`\`\`\${language}
// 修正后的代码在这里
\`\`\`

**4. 预防**
- 将来如何避免这类错误
- 任何需要检查的相关问题`}
/>

### 多图像决策

在多个选项之间做选择时，结构化比较有助于做出更好的决定。

<TryIt 
  title="视觉选项比较器"
  description="根据你的标准系统地比较多张图像，以做出明智的决定。"
  prompt={`我正在为 \${purpose} 在这些选项之间做选择：

**选项 A**：\${optionA}
**选项 B**：\${optionB}
**选项 C**：\${optionC}

**我的标准**（按重要性排序）：
1. \${criterion1}（权重：高）
2. \${criterion2}（权重：中）
3. \${criterion3}（权重：低）

提供：

**比较矩阵**
| 标准 | 选项 A | 选项 B | 选项 C |
|------|--------|--------|--------|
| \${criterion1} | 评分 + 备注 | ... | ... |
| \${criterion2} | ... | ... | ... |
| \${criterion3} | ... | ... | ... |

**加权分数**
- 选项 A：X/10
- 选项 B：X/10
- 选项 C：X/10

**推荐**
根据你陈述的优先级，我推荐 [选项] 因为...

**注意事项**
- 如果 [条件]，请考虑 [替代方案]
- 注意 [潜在问题]`}
/>

## 多模态提示词最佳实践

要从多模态 AI 获得出色的结果，需要理解它的能力和局限性。

### 什么使多模态提示词有效

<InfoGrid items={[
  { label: "提供背景", description: "告诉模型媒体是什么以及你为什么要分析它", example: "\"这是我们电商网站的产品照片...\"", color: "green" },
  { label: "具体明确", description: "询问特定元素而不是笼统印象", example: "\"关注右上角的价格表\"", color: "green" },
  { label: "引用位置", description: "使用空间语言指向特定区域", example: "\"在左下象限...\"", color: "green" },
  { label: "说明你的目标", description: "解释你将如何使用这个分析", example: "\"我需要决定这张图片是否适合我们的移动应用\"", color: "green" }
]} />

### 要避免的常见陷阱

<InfoGrid items={[
  { label: "假设完美视觉", description: "模型可能会遗漏小细节，尤其是在低分辨率图像中", example: "不要询问压缩截图中 8pt 的文字", color: "red" },
  { label: "期望完美 OCR", description: "手写字、不寻常的字体和复杂的布局可能导致错误", example: "验证从收据和表格中提取的文字", color: "red" },
  { label: "忽略内容政策", description: "模型对某些类型的内容有限制", example: "不会识别特定个人或分析不当内容", color: "red" },
  { label: "跳过验证", description: "始终验证从媒体中提取的关键信息", example: "仔细核对从文档提取中得到的数字、日期和姓名", color: "red" }
]} />

### 优雅地处理局限性

<TryIt 
  title="考虑不确定性的图像分析"
  description="这个提示词明确处理模型看不清楚或不确定的情况。"
  prompt={`分析这张图像：\${imageDescription}

**处理不确定性的说明**：

如果你看不清楚某些内容：
- 不要猜测或编造细节
- 说："我可以看到 [可见的内容] 但无法清楚地辨认 [不清楚的元素]"
- 建议什么额外信息会有帮助

如果内容似乎受限：
- 解释你能分析和不能分析的内容
- 关注分析中允许的方面

如果被问及人物：
- 描述动作、位置和一般特征
- 不要尝试识别特定个人
- 关注：人数、活动、表情、着装

**你的分析**：
[继续分析，应用这些指南]`}
/>

<Quiz 
  question="为什么提示词对多模态模型比对纯文本模型更重要？"
  options={[
    "多模态模型不够智能，需要更多帮助",
    "图像和音频本质上是模糊的——AI 需要背景信息来知道哪些方面重要",
    "多模态模型一次只能处理一种类型的输入",
    "文本提示词不适用于多模态模型"
  ]}
  correctIndex={1}
  explanation="当你看一张图片时，你会根据自己的目标立即知道什么是重要的。AI 没有这种背景——一张墙上裂缝的照片可能是工程问题、艺术纹理，或者无关的背景。你的提示词决定了 AI 如何解释和关注你提供的媒体。"
/>
