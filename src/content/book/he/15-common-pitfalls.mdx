גם מהנדסי פרומפטים מנוסים נופלים למלכודות צפויות. החדשות הטובות? ברגע שתזהו את הדפוסים האלה, קל להימנע מהם. פרק זה עובר על המלכודות הנפוצות ביותר, מסביר מדוע הן קורות, ונותן לכם אסטרטגיות קונקרטיות להתחמק מהן.

<Callout type="warning" title="מדוע מלכודות חשובות">
מלכודת בודדת יכולה להפוך בינה מלאכותית חזקה לכלי מתסכל. הבנת הדפוסים האלה היא לעתים קרובות ההבדל בין "בינה מלאכותית לא עובדת בשבילי" לבין "בינה מלאכותית שינתה את זרימת העבודה שלי."
</Callout>

## מלכודת העמימות

**הדפוס**: אתם יודעים מה אתם רוצים, אז אתם מניחים שהבינה המלאכותית תבין גם. אבל פרומפטים עמומים מייצרים תוצאות עמומות.

<Compare 
  before={{ label: "פרומפט עמום", content: "כתוב משהו על שיווק." }}
  after={{ label: "פרומפט ספציפי", content: "כתוב פוסט של 300 מילים ל-LinkedIn על חשיבות עקביות המותג עבור חברות B2B SaaS, המיועד למנהלי שיווק. השתמש בטון מקצועי אך נגיש. כלול דוגמה קונקרטית אחת." }}
/>

**מדוע זה קורה**: אנחנו באופן טבעי מדלגים על פרטים כשאנחנו חושבים שהם "ברורים מאליהם." אבל מה שברור לכם לא ברור למודל שאין לו שום הקשר על המצב, הקהל או המטרות שלכם.

<TryIt 
  title="משפר ספציפיות"
  description="קחו פרומפט עמום והפכו אותו לספציפי. שימו לב כיצד הוספת פרטים משנה את איכות התוצאות."
  prompt={`יש לי פרומפט עמום שצריך שיפור.

הפרומפט העמום המקורי: "\${vaguePrompt}"

הפוך את הפרומפט הזה לספציפי על ידי הוספת:
1. **קהל יעד**: מי יקרא/ישתמש בזה?
2. **פורמט**: איזו מבנה צריך להיות לו?
3. **אורך**: כמה ארוך הוא צריך להיות?
4. **טון**: איזה קול או סגנון?
5. **הקשר**: מה המצב או המטרה?
6. **מגבלות**: האם יש דברים שחייבים לכלול או להימנע מהם?

כתוב מחדש את הפרומפט עם כל הפרטים האלה כלולים.`}
/>

## מלכודת העומס

**הדפוס**: אתם מנסים לקבל הכל בפרומפט אחד—מקיף, מצחיק, מקצועי, ידידותי למתחילים, מתקדם, ממוטב ל-SEO, וקצר. התוצאה? הבינה המלאכותית מפספסת מחצית מהדרישות שלכם או מייצרת בלגן מבולבל.

<Compare 
  before={{ label: "פרומפט עמוס", content: "כתוב פוסט בלוג על בינה מלאכותית שהוא ממוטב ל-SEO וכולל דוגמאות קוד והוא מצחיק אבל מקצועי ומיועד למתחילים אבל גם יש בו טיפים מתקדמים וצריך להיות 500 מילים אבל מקיף ומזכיר את המוצר שלנו ויש בו קריאה לפעולה..." }}
  after={{ label: "פרומפט ממוקד", content: "כתוב פוסט בלוג של 500 מילים המציג בינה מלאכותית למתחילים.\n\nדרישות:\n1. הסבר מושג מרכזי אחד בבהירות\n2. כלול דוגמת קוד פשוטה אחת\n3. סיים עם קריאה לפעולה\n\nטון: מקצועי אך נגיש" }}
/>

**מדוע זה קורה**: פחד מאינטראקציות מרובות, או רצון "להוציא הכל" בבת אחת. אבל עומס קוגניטיבי משפיע על בינה מלאכותית בדיוק כמו שהוא משפיע על בני אדם—יותר מדי דרישות מתחרות מובילות להחמצות.

<InfoGrid items={[
  { label: "הגבילו דרישות", description: "היצמדו ל-3-5 דרישות מפתח לכל פרומפט", example: "התמקדו ב: קהל יעד, פורמט, אורך, מגבלה מרכזית אחת", exampleType: "text", color: "green" },
  { label: "השתמשו ברשימות ממוספרות", description: "מבנה מבהיר את סדרי העדיפויות", example: "1. חובה X, 2. רצוי Y, 3. נחמד שיהיה Z", exampleType: "text", color: "green" },
  { label: "שרשרו פרומפטים", description: "פרקו משימות מורכבות לשלבים", example: "ראשית: מתאר. אז: טיוטה של חלק 1. אז: טיוטה של חלק 2.", exampleType: "text", color: "green" },
  { label: "תעדפו בחוסר רחמים", description: "מה חיוני לעומת נחמד שיהיה?", example: "אם הייתי יכול לקבל רק דבר אחד נכון, מה זה היה?", color: "green" }
]} />

<Callout type="tip" title="למדו שרשור פרומפטים">
כאשר פרומפט בודד נעשה עמוס מדי, [שרשור פרומפטים](/book/11-prompt-chaining) הוא לעתים קרובות הפתרון. פרקו משימות מורכבות לרצף של פרומפטים ממוקדים, כאשר כל שלב בונה על הקודם.
</Callout>

## מלכודת ההנחות

**הדפוס**: אתם מתייחסים למשהו "מקודם" או מניחים שהבינה המלאכותית מכירה את הפרויקט שלכם, החברה שלכם, או השיחות הקודמות שלכם. היא לא מכירה.

<Compare 
  before={{ label: "מניח הקשר", content: "עדכן את הפונקציה שהראיתי לך קודם כדי להוסיף טיפול בשגיאות." }}
  after={{ label: "מספק הקשר", content: "עדכן את הפונקציה הזו כדי להוסיף טיפול בשגיאות:\n\n```python\ndef calculate_total(items):\n    return sum(item.price for item in items)\n```\n\nהוסף try/except עבור רשימות ריקות ופריטים לא תקינים." }}
/>

**מדוע זה קורה**: שיחות עם בינה מלאכותית מרגישות כמו לדבר עם עמית. אבל בניגוד לעמיתים, לרוב מודלי הבינה המלאכותית אין זיכרון מתמשך בין סשנים—כל שיחה מתחילה מחדש.

<TryIt 
  title="בדיקת שלמות הקשר"
  description="השתמשו בזה כדי לוודא שהפרומפט שלכם מכיל את כל ההקשר הנחוץ לפני שליחה."
  prompt={`בדוק את הפרומפט הזה עבור הקשר חסר:

"\${promptToCheck}"

בדוק עבור:
1. **מוזכר אך לא כלול**: האם הוא מזכיר "הקוד," "המסמך," "קודם," או "למעלה" מבלי לכלול את התוכן בפועל?

2. **ידע מונח**: האם הוא מניח ידע על פרויקט, חברה או מצב ספציפי?

3. **דרישות מרומזות**: האם יש ציפיות לא מוצהרות לגבי פורמט, אורך או סגנון?

4. **רקע חסר**: האם זר חכם היה מבין מה מבקשים?

פרט מה חסר והצע כיצד להוסיף זאת.`}
/>

## מלכודת השאלה המובילה

**הדפוס**: אתם מנסחים את השאלה שלכם בצורה שמטמיעה את ההנחה שלכם, ומקבלים בחזרה אישור במקום תובנה.

<Compare 
  before={{ label: "שאלה מובילה", content: "מדוע Python היא שפת התכנות הטובה ביותר למדעי הנתונים?" }}
  after={{ label: "שאלה ניטרלית", content: "השווה בין Python, R ו-Julia לעבודת מדעי נתונים. מהן החוזקות והחולשות של כל אחת? מתי היית בוחר באחת על פני האחרות?" }}
/>

**מדוע זה קורה**: אנחנו לעתים קרובות מחפשים אישור, לא מידע. הניסוח שלנו דוחף באופן לא מודע לכיוון התשובה שאנחנו מצפים או רוצים.

<TryIt 
  title="גלאי הטיות"
  description="בדקו את הפרומפטים שלכם עבור הטיות נסתרות ושפה מובילה."
  prompt={`נתח את הפרומפט הזה עבור הטיות ושפה מובילה:

"\${promptToAnalyze}"

בדוק עבור:
1. **הנחות מוטמעות**: האם השאלה מניחה שמשהו נכון?
2. **ניסוח מוביל**: האם "מדוע X טוב?" מניח ש-X טוב?
3. **חלופות חסרות**: האם זה מתעלם מאפשרויות אחרות?
4. **חיפוש אישור**: האם זה מבקש אישור במקום ניתוח?

כתוב מחדש את הפרומפט כך שיהיה ניטרלי ופתוח.`}
/>

## מלכודת האמון העיוור

**הדפוס**: תגובות בינה מלאכותית נשמעות בטוחות וסמכותיות, אז אתם מקבלים אותן ללא אימות. אבל ביטחון לא שווה דיוק.

<InfoGrid items={[
  { label: "תוכן לא מבוקר", description: "פרסום טקסט שנוצר על ידי בינה מלאכותית ללא בדיקת עובדות", example: "פוסטים בבלוג עם סטטיסטיקות בדויות או ציטוטים מזויפים", exampleType: "text", color: "red" },
  { label: "קוד לא נבדק", description: "שימוש בקוד של בינה מלאכותית בסביבת הייצור ללא בדיקה", example: "פרצות אבטחה, כשלים במקרי קצה, באגים עדינים", exampleType: "text", color: "red" },
  { label: "החלטות עיוורות", description: "קבלת החלטות חשובות על סמך ניתוח בינה מלאכותית בלבד", example: "אסטרטגיה עסקית מבוססת על נתוני שוק שהומצאו", exampleType: "text", color: "red" }
]} />

**מדוע זה קורה**: בינה מלאכותית נשמעת בטוחה גם כשהיא טועה לחלוטין. אנחנו גם נוטים ל"הטיית אוטומציה"—הנטייה לסמוך על פלטי מחשב יותר משצריך.

<TryIt 
  title="פרומפט אימות"
  description="השתמשו בזה כדי לגרום לבינה המלאכותית לסמן את אי-הוודאויות והשגיאות הפוטנציאליות שלה."
  prompt={`אני צריך שתספק מידע על: \${topic}

חשוב: לאחר התגובה שלך, הוסף קטע בשם "הערות אימות" שכולל:

1. **רמת ביטחון**: כמה אתה בטוח במידע הזה? (גבוהה/בינונית/נמוכה)

2. **שגיאות פוטנציאליות**: אילו חלקים בתגובה הזו סביר להניח שהם שגויים או מיושנים?

3. **מה לאמת**: אילו טענות ספציפיות המשתמש צריך לבדוק באופן עצמאי?

4. **מקורות לבדיקה**: היכן המשתמש יכול לאמת מידע זה?

היה כנה לגבי מגבלות. עדיף לסמן אי-ודאות מאשר להישמע בטוח לגבי משהו שגוי.`}
/>

## מלכודת הניסיון הבודד

**הדפוס**: אתם שולחים פרומפט אחד, מקבלים תוצאה בינונית, ומסיקים שבינה מלאכותית "לא עובדת" למקרה השימוש שלכם. אבל תוצאות מצוינות כמעט תמיד דורשות איטרציה.

<Compare 
  before={{ label: "חשיבת ניסיון בודד", content: "פלט בינוני → \"בינה מלאכותית לא יכולה לעשות את זה\" → לוותר" }}
  after={{ label: "חשיבה איטרטיבית", content: "פלט בינוני → ניתוח מה לא בסדר → שיפור הפרומפט → פלט טוב יותר → שיפור נוסף → פלט מצוין" }}
/>

**מדוע זה קורה**: אנחנו מצפים שבינה מלאכותית תקרא את המחשבות שלנו בניסיון הראשון. אנחנו לא מצפים לבצע איטרציה עם חיפושי Google, אבל איכשהו מצפים לשלמות מבינה מלאכותית.

<TryIt 
  title="עוזר איטרציה"
  description="כאשר התוצאה הראשונה לא נכונה, השתמשו בזה כדי לשפר באופן שיטתי."
  prompt={`הפרומפט המקורי שלי היה:
"\${originalPrompt}"

הפלט שקיבלתי היה:
"\${outputReceived}"

מה לא בסדר בו:
"\${whatIsWrong}"

עזור לי לבצע איטרציה:

1. **אבחון**: מדוע הפרומפט המקורי הניב תוצאה זו?

2. **אלמנטים חסרים**: לגבי מה לא הייתי מפורש שהייתי צריך להיות?

3. **פרומפט משופר**: כתוב מחדש את הפרומפט שלי כדי לטפל בבעיות האלה.

4. **על מה לשים לב**: מה עליי לבדוק בפלט החדש?`}
/>

## מלכודת הזנחת הפורמט

**הדפוס**: אתם מתמקדים במה שאתם רוצים שהבינה המלאכותית תגיד, אבל שוכחים לציין כיצד זה צריך להיות מעוצב. אז אתם מקבלים פרוזה כשהייתם צריכים JSON, או קיר של טקסט כשהייתם צריכים נקודות תבליט.

<Compare 
  before={{ label: "לא צוין פורמט", content: "חלץ את הנתונים המרכזיים מהטקסט הזה." }}
  after={{ label: "פורמט צוין", content: "חלץ את הנתונים המרכזיים מהטקסט הזה כ-JSON:\n\n{\n  \"name\": string,\n  \"date\": \"YYYY-MM-DD\",\n  \"amount\": number,\n  \"category\": string\n}\n\nהחזר רק את ה-JSON, ללא הסבר." }}
/>

**מדוע זה קורה**: אנחנו מתמקדים בתוכן על פני מבנה. אבל אם אתם צריכים לנתח את הפלט באופן תוכניתי, או להדביק אותו במקום ספציפי, הפורמט חשוב לא פחות מהתוכן.

<TryIt 
  title="בונה מפרט פורמט"
  description="צרו מפרטי פורמט ברורים לכל סוג פלט שאתם צריכים."
  prompt={`אני צריך פלט בינה מלאכותית בפורמט ספציפי.

**מה אני מבקש**: \${taskDescription}
**כיצד אשתמש בפלט**: \${intendedUse}
**פורמט מועדף**: \${formatType} (JSON, Markdown, CSV, נקודות תבליט, וכו')

צור מפרט פורמט שאוכל להוסיף לפרומפט שלי, כולל:

1. **מבנה מדויק** עם שמות שדות וסוגים
2. **פלט לדוגמה** המציג את הפורמט
3. **מגבלות** (לדוגמה, "החזר רק את ה-JSON, ללא הסבר")
4. **מקרי קצה** (מה לפלוט אם נתונים חסרים)`}
/>

## מלכודת חלון ההקשר

**הדפוס**: אתם מדביקים מסמך עצום ומצפים לניתוח מקיף. אבל למודלים יש מגבלות—הם עשויים לקצר, לאבד מיקוד, או לפספס פרטים חשובים בקלטים ארוכים.

<InfoGrid items={[
  { label: "הכירו את המגבלות", description: "למודלים שונים יש חלונות הקשר שונים", example: "GPT-4: 128K טוקנים, Claude: 200K טוקנים, Gemini: 1M טוקנים", exampleType: "text", color: "blue" },
  { label: "חלקו קלטים גדולים", description: "פרקו מסמכים לקטעים ניתנים לניהול", example: "נתחו פרקים בנפרד, ואז סנתזו", exampleType: "text", color: "blue" },
  { label: "שימו מידע חשוב בהתחלה", description: "שימו הקשר קריטי בתחילת הפרומפט", example: "דרישות מפתח ראשונות, פרטי רקע אחר כך", exampleType: "text", color: "blue" },
  { label: "קצצו את העודף", description: "הסירו הקשר מיותר", example: "האם באמת צריך את כל המסמך, או רק חלקים רלוונטיים?", exampleType: "text", color: "blue" }
]} />

<TryIt 
  title="אסטרטגיית חלוקת מסמכים"
  description="קבלו אסטרטגיה לעיבוד מסמכים שחורגים ממגבלות ההקשר."
  prompt={`יש לי מסמך גדול לניתוח:

**סוג מסמך**: \${documentType}
**אורך משוער**: \${documentLength}
**מה אני צריך לחלץ/לנתח**: \${analysisGoal}
**המודל שאני משתמש בו**: \${modelName}

צור אסטרטגיית חלוקה:

1. **כיצד לחלק**: נקודות שבירה לוגיות לסוג מסמך זה
2. **מה לכלול בכל חלק**: הקשר הנדרש לניתוח עצמאי
3. **כיצד לסנתז**: שילוב תוצאות ממספר חלקים
4. **על מה לשים לב**: מידע שעשוי להשתרע על פני חלקים`}
/>

## מלכודת האנתרופומורפיזציה

**הדפוס**: אתם מתייחסים לבינה מלאכותית כמו לעמית אנושי—מצפים שהיא "תיהנה" ממשימות, תזכור אתכם, או תאכפת מהתוצאות. היא לא.

<Compare 
  before={{ label: "מואנש", content: "אני בטוח שתיהנה מהפרויקט היצירתי הזה! אני יודע שאתה אוהב לעזור לאנשים, וזה באמת חשוב לי אישית." }}
  after={{ label: "ברור וישיר", content: "כתוב סיפור קצר יצירתי עם המפרטים הבאים:\n- ז'אנר: מדע בדיוני\n- אורך: 500 מילים\n- טון: מלא תקווה\n- חובה לכלול: סוף מפתיע" }}
/>

**מדוע זה קורה**: תגובות בינה מלאכותית כל כך דמויות אדם שאנחנו באופן טבעי נגררים לדפוסים חברתיים. אבל פניות רגשיות לא גורמות לבינה המלאכותית להתאמץ יותר—הוראות ברורות כן.

<Callout type="info" title="מה באמת עוזר">
במקום פניות רגשיות, התמקדו ב: דרישות ברורות, דוגמאות טובות, מגבלות ספציפיות, וקריטריונים מפורשים להצלחה. אלה משפרים את הפלט. "בבקשה נסה ממש חזק" לא משפר.
</Callout>

## מלכודת הזנחת האבטחה

**הדפוס**: בחיפזון לגרום לדברים לעבוד, אתם כוללים מידע רגיש בפרומפטים—מפתחות API, סיסמאות, נתונים אישיים, או מידע קנייני.

<InfoGrid items={[
  { label: "סודות בפרומפטים", description: "מפתחות API, סיסמאות, טוקנים מודבקים בפרומפטים", example: "\"השתמש במפתח API הזה: sk-abc123...\"", color: "red" },
  { label: "נתונים אישיים", description: "כולל מידע מזהה אישית שנשלח לשרתי צד שלישי", example: "שמות לקוחות, אימיילים, כתובות בפרומפטים", exampleType: "text", color: "red" },
  { label: "קלט משתמש לא מסונן", description: "העברת קלט משתמש ישירות לפרומפטים", example: "פרצות הזרקת פרומפט", exampleType: "text", color: "red" },
  { label: "מידע קנייני", description: "סודות מסחריים או נתונים חסויים", example: "אסטרטגיות פנימיות, פרטי מוצר שטרם שוחררו", exampleType: "text", color: "red" }
]} />

**מדוע זה קורה**: התמקדות בפונקציונליות על חשבון אבטחה. אבל זכרו: פרומפטים הולכים לעתים קרובות לשרתים חיצוניים, עשויים להירשם ביומן, ויכולים לשמש לאימון.

<TryIt 
  title="סקירת אבטחה"
  description="בדקו את הפרומפט שלכם עבור בעיות אבטחה לפני שליחה."
  prompt={`בדוק את הפרומפט הזה עבור חששות אבטחה:

"\${promptToReview}"

בדוק עבור:

1. **סודות חשופים**: מפתחות API, סיסמאות, טוקנים, אישורי גישה
2. **נתונים אישיים**: שמות, אימיילים, כתובות, מספרי טלפון, מספרי זהות
3. **מידע קנייני**: סודות מסחריים, אסטרטגיות פנימיות, נתונים חסויים
4. **סיכוני הזרקה**: קלט משתמש שיכול לתמרן את הפרומפט

עבור כל בעיה שנמצאה:
- הסבר את הסיכון
- הצע כיצד לצנזר או להגן על המידע
- המלץ על חלופות בטוחות יותר`}
/>

## מלכודת התעלמות מהזיות

**הדפוס**: אתם מבקשים ציטוטים, סטטיסטיקות, או עובדות ספציפיות, ומניחים שהם אמיתיים כי הבינה המלאכותית ציינה אותם בביטחון. אבל בינה מלאכותית ממציאה באופן קבוע מידע שנשמע סביר.

<Compare 
  before={{ label: "סומכים בעיוורון", content: "תן לי 5 סטטיסטיקות על פרודוקטיביות בעבודה מרחוק עם מקורות." }}
  after={{ label: "מכירים במגבלות", content: "מה ידוע על פרודוקטיביות בעבודה מרחוק? עבור כל סטטיסטיקה שתזכיר, ציין האם אלה ממצאים מבוססים היטב או יותר לא וודאיים. אאמת כל מספרים ספציפיים באופן עצמאי." }}
/>

**מדוע זה קורה**: בינה מלאכותית מייצרת טקסט שנשמע סמכותי. היא לא "יודעת" כשהיא ממציאה דברים—היא מנבאת טקסט סביר, לא מאחזרת עובדות מאומתות.

<TryIt 
  title="שאילתה עמידה להזיות"
  description="מבנו את הפרומפט שלכם כדי למזער סיכון להזיות ולסמן אי-ודאויות."
  prompt={`אני צריך מידע על: \${topic}

אנא עקוב אחר ההנחיות האלה כדי למזער שגיאות:

1. **היצמד לעובדות מבוססות היטב**. הימנע מטענות עמומות שקשה לאמת.

2. **סמן אי-ודאות**. אם אתה לא בטוח במשהו, אמור "אני מאמין ש..." או "זה עשוי לדרוש אימות..."

3. **אל תמציא מקורות**. אל תצטט מאמרים, ספרים או כתובות URL ספציפיים אלא אם אתה בטוח שהם קיימים. במקום זאת, תאר היכן למצוא סוג זה של מידע.

4. **הכר במגבלות ידע**. אם השאלה שלי עוסקת באירועים לאחר נתוני האימון שלך, אמור זאת.

5. **הפרד עובדה מהסקה**. הבחן בבירור בין "X נכון" לבין "בהתבסס על Y, X כנראה נכון."

כעת, עם ההנחיות האלה בראש: \${actualQuestion}`}
/>

## רשימת ביקורת לפני שליחה

לפני שליחת כל פרומפט חשוב, עברו על רשימת הביקורת המהירה הזו:

<Checklist 
  title="בדיקת איכות פרומפט"
  items={[
    { text: "האם זה ספציפי מספיק? (לא עמום)" },
    { text: "האם זה ממוקד? (לא עמוס בדרישות)" },
    { text: "האם זה כולל את כל ההקשר הנחוץ?" },
    { text: "האם השאלה ניטרלית? (לא מובילה)" },
    { text: "האם ציינתי את פורמט הפלט?" },
    { text: "האם הקלט בתוך מגבלות ההקשר?" },
    { text: "האם יש חששות אבטחה?" },
    { text: "האם אני מוכן לאמת את הפלט?" },
    { text: "האם אני מוכן לבצע איטרציה אם יהיה צורך?" }
  ]}
/>

<Quiz 
  question="מהי המלכודת המסוכנת ביותר בעת שימוש בבינה מלאכותית להחלטות חשובות?"
  options={[
    "שימוש בפרומפטים עמומים",
    "אמון בפלטי בינה מלאכותית ללא אימות",
    "אי-ציון פורמט פלט",
    "העמסת פרומפטים בדרישות"
  ]}
  correctIndex={1}
  explanation="בעוד שכל המלכודות גורמות לבעיות, אמון בפלטי בינה מלאכותית ללא אימות הוא המסוכן ביותר כי זה יכול להוביל לפרסום מידע שגוי, פריסת קוד עם באגים, או קבלת החלטות על סמך נתונים שהומצאו. בינה מלאכותית נשמעת בטוחה גם כשהיא טועה לחלוטין, מה שהופך אימות לחיוני לכל מקרה שימוש חשוב."
/>

## נתחו את הפרומפטים שלכם

השתמשו בבינה מלאכותית כדי לקבל משוב מיידי על איכות הפרומפט שלכם. הדביקו כל פרומפט וקבלו ניתוח מפורט:

<PromptAnalyzer 
  title="מנתח איכות פרומפט"
  description="קבלו משוב מונע בינה מלאכותית על בהירות, ספציפיות, והצעות לשיפור"
  defaultPrompt="עזור לי עם הקוד שלי"
/>

## דבגו את הפרומפט הזה

האם אתם יכולים לזהות מה לא בסדר בפרומפט הזה?

<PromptDebugger
  title="מצאו את המלכודת"
  badPrompt="כתוב פוסט בלוג על טכנולוגיה שהוא ממוטב ל-SEO עם מילות מפתח וגם מצחיק אבל מקצועי וכולל דוגמאות קוד ומיועד למתחילים אבל יש בו טיפים מתקדמים ומזכיר את המוצר שלנו TechCo ויש בו הוכחה חברתית וקריאה לפעולה והוא 500 מילים אבל מקיף."
  badOutput="הנה טיוטת פוסט בלוג על טכנולוגיה...

[תוכן גנרי, לא ממוקד שמנסה לעשות הכל אבל לא משיג כלום היטב. הטון עובר בצורה מביכה בין קז'ואל לטכני. חסרות מחצית מהדרישות.]"
  options={[
    { id: "vague", label: "הפרומפט עמום מדי", isCorrect: false, explanation: "למעשה, לפרומפט יש הרבה דרישות ספציפיות. הבעיה היא הפוכה—יותר מדי דרישות, לא מעט מדי." },
    { id: "overload", label: "הפרומפט עמוס ביותר מדי דרישות מתחרות", isCorrect: true, explanation: "נכון! הפרומפט הזה מבקש SEO + מצחיק + מקצועי + קוד + מתחילים + מתקדם + אזכור מוצר + הוכחה חברתית + קריאה לפעולה + מגבלת אורך. זה יותר מ-10 דרישות מתחרות! הבינה המלאכותית לא יכולה לספק את כולן, אז היא עושה עבודה בינונית על הכל. הפתרון: לפרק את זה לפרומפטים ממוקדים מרובים." },
    { id: "format", label: "פורמט הפלט לא צוין", isCorrect: false, explanation: "בעוד שפורמט ספציפי יותר היה עוזר, הבעיה העיקרית היא עומס דרישות. אתם לא יכולים לפתור את הבעיה של לבקש יותר מדי עם עיצוב." },
    { id: "context", label: "אין מספיק הקשר", isCorrect: false, explanation: "לפרומפט למעשה יש הרבה הקשר—אולי יותר מדי! הבעיה היא שהוא מנסה לספק יותר מדי מטרות בבת אחת." }
  ]}
  hint="ספרו כמה דרישות שונות ארוזות בפרומפט הבודד הזה."
/>
