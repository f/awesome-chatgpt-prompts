Un buon prompt fa il suo lavoro. Un prompt ottimizzato fa il suo lavoro in modo efficiente—più veloce, più economico, più coerente. Questo capitolo ti insegna come migliorare sistematicamente i prompt su molteplici dimensioni.

<Callout type="tip" title="Prova il Prompt Enhancer">
Vuoi ottimizzare i tuoi prompt automaticamente? Usa il nostro strumento [Prompt Enhancer](/developers#enhancer). Analizza il tuo prompt, applica tecniche di ottimizzazione, e ti mostra prompt simili dalla community per ispirazione.
</Callout>

## I Trade-off dell'Ottimizzazione

Ogni ottimizzazione comporta trade-off. Capirli ti aiuta a fare scelte intenzionali:

<InfoGrid items={[
  { label: "Qualità vs. Costo", description: "Qualità più alta spesso richiede più token o modelli migliori", example: "Aggiungere esempi migliora l'accuratezza ma aumenta il conteggio token", exampleType: "text", color: "blue" },
  { label: "Velocità vs. Qualità", description: "Modelli più veloci potrebbero sacrificare alcune capacità", example: "GPT-4 è più intelligente ma più lento di GPT-4o-mini", exampleType: "text", color: "purple" },
  { label: "Coerenza vs. Creatività", description: "Temperature più bassa = più prevedibile ma meno creativo", example: "Temperature 0.2 per fatti, 0.8 per brainstorming", exampleType: "text", color: "green" },
  { label: "Semplicità vs. Robustezza", description: "Gestire casi limite aggiunge complessità", example: "Prompt semplici falliscono su input inusuali", exampleType: "text", color: "amber" }
]} />

## Misurare Ciò che Conta

Prima di ottimizzare, definisci il successo. Cosa significa "migliore" per il tuo caso d'uso?

<InfoGrid items={[
  { label: "Accuratezza", description: "Quanto spesso l'output è corretto?", example: "Il 90% dei suggerimenti di codice compila senza errori", exampleType: "text", color: "blue" },
  { label: "Rilevanza", description: "Risponde a ciò che è stato effettivamente chiesto?", example: "La risposta risponde direttamente alla domanda vs. divagazioni", exampleType: "text", color: "blue" },
  { label: "Completezza", description: "Tutti i requisiti sono coperti?", example: "Tutte le 5 sezioni richieste incluse nell'output", exampleType: "text", color: "blue" },
  { label: "Latenza", description: "Quanto tempo prima che arrivi la risposta?", example: "p50 < 2s, p95 < 5s per applicazioni chat", exampleType: "text", color: "purple" },
  { label: "Efficienza Token", description: "Quanti token per lo stesso risultato?", example: "500 token vs. 1500 token per output equivalente", exampleType: "text", color: "purple" },
  { label: "Coerenza", description: "Quanto sono simili gli output per input simili?", example: "La stessa domanda ottiene risposte strutturalmente simili", exampleType: "text", color: "green" }
]} />

<Callout type="info" title="Cosa Significano p50 e p95?">
Le metriche percentili mostrano la distribuzione dei tempi di risposta. **p50** (mediana) significa che il 50% delle richieste è più veloce di questo valore. **p95** significa che il 95% è più veloce—cattura gli outlier lenti. Se il tuo p50 è 1s ma il p95 è 10s, la maggior parte degli utenti è contenta ma il 5% sperimenta ritardi frustranti.
</Callout>

<TryIt 
  title="Definisci le Tue Metriche di Successo"
  description="Usa questo template per chiarire per cosa stai ottimizzando prima di fare modifiche."
  prompt={`Aiutami a definire le metriche di successo per la mia ottimizzazione prompt.

**Il mio caso d'uso**: \${useCase}
**Pain point attuali**: \${painPoints}

Per questo caso d'uso, aiutami a definire:

1. **Metrica primaria**: Quale singola metrica conta di più?
2. **Metriche secondarie**: Cos'altro dovrei tracciare?
3. **Trade-off accettabili**: Cosa posso sacrificare per la metrica primaria?
4. **Linee rosse**: Quale livello di qualità è inaccettabile?
5. **Come misurare**: Modi pratici per valutare ogni metrica`}
/>

## Ottimizzazione Token

I token costano soldi e aggiungono latenza. Ecco come dire la stessa cosa con meno token.

### Il Principio della Compressione

<Compare 
  before={{ label: "Verboso (67 token)", content: "Vorrei che per favore mi aiutassi con il seguente compito. Ho bisogno che tu prenda il testo che ti fornirò sotto e ne crei un riassunto. Il riassunto dovrebbe catturare i punti principali ed essere conciso. Per favore assicurati di includere tutte le informazioni importanti. Ecco il testo:\n\n[testo]" }}
  after={{ label: "Conciso (12 token)", content: "Riassumi questo testo, catturando i punti principali in modo conciso:\n\n[testo]" }}
/>

**Stesso risultato, 82% meno token.**

### Tecniche di Risparmio Token

<InfoGrid items={[
  { label: "Taglia le Formalità", description: "\"Per favore\" e \"Grazie\" aggiungono token senza migliorare l'output", example: "\"Per favore riassumi\" → \"Riassumi\"", color: "green" },
  { label: "Elimina la Ridondanza", description: "Non ripeterti o dichiarare l'ovvio", example: "\"Scrivi un riassunto che riassuma\" → \"Riassumi\"", color: "green" },
  { label: "Usa Abbreviazioni", description: "Dove il significato è chiaro, abbrevia", example: "\"per esempio\" → \"es.\"", color: "green" },
  { label: "Riferisci per Posizione", description: "Indica il contenuto invece di ripeterlo", example: "\"il testo sopra\" invece di ri-quotare", color: "green" }
]} />

<TryIt 
  title="Compressore Prompt"
  description="Incolla un prompt verboso per ottenere una versione ottimizzata per token."
  prompt={`Comprimi questo prompt preservando il suo significato ed efficacia:

Prompt originale:
"\${verbosePrompt}"

Istruzioni:
1. Rimuovi formalità e parole riempitive non necessarie
2. Elimina la ridondanza
3. Usa frasi concise
4. Mantieni tutte le istruzioni e vincoli essenziali
5. Mantieni la chiarezza—non sacrificare la comprensione per la brevità

Fornisci:
- **Versione compressa**: Il prompt ottimizzato
- **Riduzione token**: Percentuale stimata risparmiata
- **Cosa è stato tagliato**: Breve spiegazione di cosa è stato rimosso e perché era sicuro rimuoverlo`}
/>

## Ottimizzazione Qualità

A volte hai bisogno di output migliori, non più economici. Ecco come migliorare la qualità.

### Booster di Accuratezza

<InfoGrid items={[
  { label: "Aggiungi Verifica", description: "Chiedi al modello di controllare il suo lavoro", example: "\"...poi verifica che la tua risposta sia corretta\"", color: "blue" },
  { label: "Richiedi Confidenza", description: "Rendi esplicita l'incertezza", example: "\"Valuta la tua confidenza 1-10 e spiega eventuali incertezze\"", color: "blue" },
  { label: "Approcci Multipli", description: "Ottieni prospettive diverse, poi scegli", example: "\"Fornisci 3 approcci e raccomanda il migliore\"", color: "blue" },
  { label: "Ragionamento Esplicito", description: "Forza il pensiero passo-passo", example: "\"Pensa passo passo e mostra il tuo ragionamento\"", color: "blue" }
]} />

### Booster di Coerenza

<InfoGrid items={[
  { label: "Specifiche Formato Dettagliate", description: "Mostra esattamente come dovrebbe apparire l'output", example: "Includi un template o schema", exampleType: "text", color: "purple" },
  { label: "Esempi Few-Shot", description: "Fornisci 2-3 esempi di output ideale", example: "\"Ecco come appare un buon risultato: [esempi]\"", color: "purple" },
  { label: "Temperature Più Bassa", description: "Riduci la casualità per output più prevedibili", example: "Temperature 0.3-0.5 per risultati coerenti", exampleType: "text", color: "purple" },
  { label: "Validazione Output", description: "Aggiungi uno step di validazione per campi critici", example: "\"Verifica che tutti i campi richiesti siano presenti\"", color: "purple" }
]} />

<TryIt 
  title="Miglioratore Qualità"
  description="Aggiungi elementi che migliorano la qualità al tuo prompt."
  prompt={`Migliora questo prompt per output di qualità superiore:

Prompt originale:
"\${originalPrompt}"

**Quale problema di qualità sto vedendo**: \${qualityIssue}

Aggiungi booster di qualità appropriati:
1. Se il problema è l'accuratezza → aggiungi step di verifica
2. Se il problema è la coerenza → aggiungi specifiche di formato o esempi
3. Se il problema è la rilevanza → aggiungi contesto e vincoli
4. Se il problema è la completezza → aggiungi requisiti espliciti

Fornisci il prompt migliorato con spiegazioni per ogni aggiunta.`}
/>

## Ottimizzazione Latenza

Quando la velocità conta, ogni millisecondo conta.

### Selezione Modello per Esigenza di Velocità

<InfoGrid items={[
  { label: "Real-time (< 500ms)", description: "Usa il modello più piccolo efficace + caching aggressivo", example: "GPT-4o-mini, Claude Haiku, risposte in cache", exampleType: "text", color: "red" },
  { label: "Interattivo (< 2s)", description: "Modelli veloci, streaming abilitato", example: "GPT-4o-mini con streaming", exampleType: "text", color: "amber" },
  { label: "Tollerante (< 10s)", description: "Modelli mid-tier, bilancia qualità/velocità", example: "GPT-4o, Claude Sonnet", exampleType: "text", color: "green" },
  { label: "Async/Batch", description: "Usa il modello migliore, elabora in background", example: "GPT-4, Claude Opus per elaborazione offline", exampleType: "text", color: "blue" }
]} />

### Tecniche di Velocità

<InfoGrid items={[
  { label: "Prompt Più Corti", description: "Meno token in input = elaborazione più veloce", example: "Comprimi i prompt, rimuovi contesto non necessario", exampleType: "text", color: "cyan" },
  { label: "Limita l'Output", description: "Imposta max_tokens per prevenire risposte senza controllo", example: "max_tokens: 500 per riassunti", exampleType: "text", color: "cyan" },
  { label: "Usa lo Streaming", description: "Ottieni i primi token più velocemente, UX migliore", example: "Stream per qualsiasi risposta > 100 token", exampleType: "text", color: "cyan" },
  { label: "Cache Aggressivo", description: "Non ricalcolare query identiche", example: "Cache domande comuni, output template", exampleType: "text", color: "cyan" }
]} />

## Ottimizzazione Costi

Su larga scala, piccoli risparmi si moltiplicano in impatto significativo sul budget.

### Capire i Costi

Usa questo calcolatore per stimare i tuoi costi API attraverso diversi modelli:

<CostCalculatorDemo />

### Strategie di Riduzione Costi

<InfoGrid items={[
  { label: "Routing Modelli", description: "Usa modelli costosi solo quando necessario", example: "Domande semplici → GPT-4o-mini, Complesse → GPT-4", exampleType: "text", color: "green" },
  { label: "Efficienza Prompt", description: "Prompt più corti = costo per richiesta più basso", example: "Taglia 50% dei token = 50% risparmio costi input", exampleType: "text", color: "green" },
  { label: "Controllo Output", description: "Limita la lunghezza risposta quando il dettaglio completo non serve", example: "\"Rispondi in 2-3 frasi\" vs. illimitato", color: "green" },
  { label: "Batching", description: "Combina query correlate in singole richieste", example: "Analizza 10 elementi in un prompt vs. 10 chiamate separate", exampleType: "text", color: "green" },
  { label: "Pre-filtraggio", description: "Non inviare richieste che non hanno bisogno di IA", example: "Matching parole chiave prima di classificazione costosa", exampleType: "text", color: "green" }
]} />

## Il Loop di Ottimizzazione

L'ottimizzazione è iterativa. Ecco un processo sistematico:

### Step 1: Stabilisci la Baseline

Non puoi migliorare ciò che non misuri. Prima di cambiare qualsiasi cosa, documenta il tuo punto di partenza rigorosamente.

<InfoGrid items={[
  { label: "Documentazione Prompt", description: "Salva il testo esatto del prompt, inclusi system prompt e template", example: "Versiona i tuoi prompt come codice", exampleType: "text", color: "blue" },
  { label: "Set di Test", description: "Crea 20-50 input rappresentativi che coprono casi comuni e casi limite", example: "Includi esempi facili, medi e difficili", exampleType: "text", color: "blue" },
  { label: "Metriche Qualità", description: "Valuta ogni output rispetto ai tuoi criteri di successo", example: "Accuratezza %, punteggio rilevanza, conformità formato", exampleType: "text", color: "purple" },
  { label: "Metriche Performance", description: "Misura token e timing per ogni caso di test", example: "Media input: 450 token, Media output: 200 token, latenza p50: 1.2s", exampleType: "text", color: "purple" }
]} />

<TryIt 
  title="Template Documentazione Baseline"
  description="Usa questo per creare una baseline completa prima di ottimizzare."
  prompt={`Crea una documentazione baseline per il mio progetto di ottimizzazione prompt.

**Prompt attuale**:
"\${currentPrompt}"

**Cosa fa il prompt**: \${promptPurpose}

**Problemi attuali che sto vedendo**: \${currentIssues}

Genera un template di documentazione baseline con:

1. **Snapshot Prompt**: Il testo esatto del prompt (per version control)

2. **Casi di Test**: Suggerisci 10 input di test rappresentativi che dovrei usare, coprendo:
   - 3 casi tipici/facili
   - 4 casi di complessità media  
   - 3 casi limite o input difficili

3. **Metriche da Tracciare**:
   - Metriche qualità specifiche per questo caso d'uso
   - Metriche efficienza (token, latenza)
   - Come valutare ogni metrica

4. **Ipotesi Baseline**: Cosa mi aspetto che sia la performance attuale?

5. **Criteri di Successo**: Quali numeri mi renderebbero soddisfatto dell'ottimizzazione?`}
/>

### Step 2: Formula un'Ipotesi

<Compare 
  before={{ label: "Obiettivo vago", content: "Voglio rendere il mio prompt migliore." }}
  after={{ label: "Ipotesi testabile", content: "Se aggiungo 2 esempi few-shot, l'accuratezza migliorerà dal 75% all'85% perché il modello imparerà il pattern atteso." }}
/>

### Step 3: Testa un Cambiamento

Cambia una cosa alla volta. Esegui entrambe le versioni sugli stessi input di test. Misura le metriche che contano.

### Step 4: Analizza e Decidi

Ha funzionato? Tieni il cambiamento. Ha peggiorato? Ripristina. Era neutrale? Ripristina (più semplice è meglio).

### Step 5: Ripeti

Genera nuove ipotesi basandoti su ciò che hai imparato. Continua a iterare finché non raggiungi i tuoi obiettivi o arrivi a rendimenti decrescenti.

## Checklist Ottimizzazione

<Checklist 
  title="Prima di Deployare un Prompt Ottimizzato"
  items={[
    { text: "Definite metriche di successo chiare" },
    { text: "Misurata performance baseline" },
    { text: "Testati i cambiamenti su input rappresentativi" },
    { text: "Verificato che la qualità non sia regredita" },
    { text: "Controllata la gestione dei casi limite" },
    { text: "Calcolato il costo alla scala prevista" },
    { text: "Testata la latenza sotto carico" },
    { text: "Documentato cosa è cambiato e perché" }
  ]}
/>

<Quiz 
  question="Hai un prompt che funziona bene ma costa troppo su larga scala. Qual è la PRIMA cosa che dovresti fare?"
  options={[
    "Passare immediatamente a un modello più economico",
    "Rimuovere parole dal prompt per ridurre i token",
    "Misurare quale parte del prompt sta usando più token",
    "Aggiungere caching per tutte le richieste"
  ]}
  correctIndex={2}
  explanation="Prima di ottimizzare, misura. Devi capire dove stanno andando i token prima di poterli ridurre efficacemente. Il prompt potrebbe avere contesto non necessario, istruzioni verbose, o generare output più lunghi del necessario. La misurazione ti dice dove concentrare i tuoi sforzi di ottimizzazione."
/>
