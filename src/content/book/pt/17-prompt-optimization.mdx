Um bom prompt faz o trabalho. Um prompt otimizado faz o trabalho de forma eficiente—mais rápido, mais barato, mais consistente. Este capítulo ensina como melhorar sistematicamente prompts em múltiplas dimensões.

<Callout type="tip" title="Experimente o Aprimorador de Prompt">
Quer otimizar seus prompts automaticamente? Use nossa ferramenta [Aprimorador de Prompt](/developers#enhancer). Ela analisa seu prompt, aplica técnicas de otimização e mostra prompts similares da comunidade para inspiração.
</Callout>

## Os Trade-offs de Otimização

Toda otimização envolve trade-offs. Entendê-los ajuda você a fazer escolhas intencionais:

<InfoGrid items={[
  { label: "Qualidade vs. Custo", description: "Maior qualidade frequentemente requer mais tokens ou melhores modelos", example: "Adicionar exemplos melhora precisão mas aumenta contagem de tokens", exampleType: "text", color: "blue" },
  { label: "Velocidade vs. Qualidade", description: "Modelos mais rápidos podem sacrificar alguma capacidade", example: "GPT-4 é mais inteligente mas mais lento que GPT-4o-mini", exampleType: "text", color: "purple" },
  { label: "Consistência vs. Criatividade", description: "Temperatura menor = mais previsível mas menos criativo", example: "Temperatura 0.2 para fatos, 0.8 para brainstorming", exampleType: "text", color: "green" },
  { label: "Simplicidade vs. Robustez", description: "Tratamento de casos limite adiciona complexidade", example: "Prompts simples falham em entradas incomuns", exampleType: "text", color: "amber" }
]} />

## Medindo o Que Importa

Antes de otimizar, defina sucesso. O que "melhor" significa para seu caso de uso?

<InfoGrid items={[
  { label: "Precisão", description: "Com que frequência a saída está correta?", example: "90% das sugestões de código compilam sem erros", exampleType: "text", color: "blue" },
  { label: "Relevância", description: "Ela aborda o que foi realmente perguntado?", example: "Resposta diretamente responde a pergunta vs. tangentes", exampleType: "text", color: "blue" },
  { label: "Completude", description: "Todos requisitos foram cobertos?", example: "Todas 5 seções requisitadas incluídas na saída", exampleType: "text", color: "blue" },
  { label: "Latência", description: "Quanto tempo até a resposta chegar?", example: "p50 < 2s, p95 < 5s para aplicações de chat", exampleType: "text", color: "purple" },
  { label: "Eficiência de Tokens", description: "Quantos tokens para o mesmo resultado?", example: "500 tokens vs. 1500 tokens para saída equivalente", exampleType: "text", color: "purple" },
  { label: "Consistência", description: "Quão similares são saídas para entradas similares?", example: "Mesma pergunta recebe respostas estruturalmente similares", exampleType: "text", color: "green" }
]} />

<Callout type="info" title="O Que p50 e p95 Significam?">
Métricas de percentil mostram distribuição de tempo de resposta. **p50** (mediana) significa que 50% das requisições são mais rápidas que este valor. **p95** significa que 95% são mais rápidas—captura outliers lentos. Se seu p50 é 1s mas p95 é 10s, maioria dos usuários está feliz mas 5% experienciam atrasos frustrantes.
</Callout>

<TryIt 
  title="Defina Suas Métricas de Sucesso"
  description="Use este template para esclarecer para o que você está otimizando antes de fazer mudanças."
  prompt={`Ajude-me a definir métricas de sucesso para minha otimização de prompt.

**Meu caso de uso**: \${casoDeUso}
**Pontos de dor atuais**: \${pontosDeDor}

Para este caso de uso, ajude-me a definir:

1. **Métrica primária**: Qual única métrica mais importa?
2. **Métricas secundárias**: O que mais devo acompanhar?
3. **Trade-offs aceitáveis**: O que posso sacrificar pela métrica primária?
4. **Linhas vermelhas**: Que nível de qualidade é inaceitável?
5. **Como medir**: Formas práticas de avaliar cada métrica`}
/>

## Otimização de Tokens

Tokens custam dinheiro e adicionam latência. Aqui está como dizer a mesma coisa com menos tokens.

### O Princípio da Compressão

<Compare 
  before={{ label: "Verboso (67 tokens)", content: "Eu gostaria que você por favor me ajudasse com a seguinte tarefa. Preciso que você pegue o texto que vou fornecer abaixo e crie um resumo dele. O resumo deve capturar os pontos principais e ser conciso. Por favor certifique-se de incluir toda informação importante. Aqui está o texto:\n\n[texto]" }}
  after={{ label: "Conciso (12 tokens)", content: "Resuma este texto, capturando pontos principais de forma concisa:\n\n[texto]" }}
/>

**Mesmo resultado, 82% menos tokens.**

### Técnicas de Economia de Tokens

<InfoGrid items={[
  { label: "Corte Cortesias", description: "\"Por favor\" e \"Obrigado\" adicionam tokens sem melhorar saída", example: "\"Por favor resuma\" → \"Resuma\"", color: "green" },
  { label: "Elimine Redundância", description: "Não se repita ou declare o óbvio", example: "\"Escreva um resumo que resuma\" → \"Resuma\"", color: "green" },
  { label: "Use Abreviações", description: "Onde significado é claro, abrevie", example: "\"por exemplo\" → \"ex.\"", color: "green" },
  { label: "Referencie por Posição", description: "Aponte para conteúdo em vez de repetir", example: "\"o texto acima\" em vez de re-citar", color: "green" }
]} />

<TryIt 
  title="Compressor de Prompt"
  description="Cole um prompt verboso para obter versão otimizada em tokens."
  prompt={`Comprima este prompt preservando seu significado e eficácia:

Prompt original:
"\${promptVerboso}"

Instruções:
1. Remova cortesias e palavras de preenchimento desnecessárias
2. Elimine redundância
3. Use fraseamento conciso
4. Mantenha todas instruções e restrições essenciais
5. Mantenha clareza—não sacrifique entendimento por brevidade

Forneça:
- **Versão comprimida**: O prompt otimizado
- **Redução de tokens**: Porcentagem estimada economizada
- **O que foi cortado**: Breve explicação do que foi removido e por que foi seguro remover`}
/>

## Otimização de Qualidade

Às vezes você precisa de saídas melhores, não mais baratas. Aqui está como melhorar qualidade.

### Impulsionadores de Precisão

<InfoGrid items={[
  { label: "Adicione Verificação", description: "Peça ao modelo para verificar seu próprio trabalho", example: "\"...então verifique se sua resposta está correta\"", color: "blue" },
  { label: "Solicite Confiança", description: "Torne incerteza explícita", example: "\"Avalie sua confiança de 1-10 e explique qualquer incerteza\"", color: "blue" },
  { label: "Múltiplas Abordagens", description: "Obtenha diferentes perspectivas, depois escolha", example: "\"Forneça 3 abordagens e recomende a melhor\"", color: "blue" },
  { label: "Raciocínio Explícito", description: "Force pensamento passo a passo", example: "\"Pense passo a passo e mostre seu raciocínio\"", color: "blue" }
]} />

### Impulsionadores de Consistência

<InfoGrid items={[
  { label: "Specs de Formato Detalhados", description: "Mostre exatamente como saída deve parecer", example: "Inclua um template ou schema", exampleType: "text", color: "purple" },
  { label: "Exemplos Few-Shot", description: "Forneça 2-3 exemplos de saída ideal", example: "\"Aqui está como bom parece: [exemplos]\"", color: "purple" },
  { label: "Temperatura Menor", description: "Reduza aleatoriedade para saída mais previsível", example: "Temperatura 0.3-0.5 para resultados consistentes", exampleType: "text", color: "purple" },
  { label: "Validação de Saída", description: "Adicione etapa de validação para campos críticos", example: "\"Verifique se todos campos obrigatórios estão presentes\"", color: "purple" }
]} />

<TryIt 
  title="Aprimorador de Qualidade"
  description="Adicione elementos de melhoria de qualidade ao seu prompt."
  prompt={`Aprimore este prompt para saídas de maior qualidade:

Prompt original:
"\${promptOriginal}"

**Que problema de qualidade estou vendo**: \${problemaQualidade}

Adicione impulsionadores de qualidade apropriados:
1. Se precisão é o problema → adicione etapas de verificação
2. Se consistência é o problema → adicione especificações de formato ou exemplos
3. Se relevância é o problema → adicione contexto e restrições
4. Se completude é o problema → adicione requisitos explícitos

Forneça o prompt aprimorado com explicações para cada adição.`}
/>

## Otimização de Latência

Quando velocidade importa, cada milissegundo conta.

### Seleção de Modelo por Necessidade de Velocidade

<InfoGrid items={[
  { label: "Tempo Real (< 500ms)", description: "Use menor modelo eficaz + caching agressivo", example: "GPT-4o-mini, Claude Haiku, respostas cacheadas", exampleType: "text", color: "red" },
  { label: "Interativo (< 2s)", description: "Modelos rápidos, streaming habilitado", example: "GPT-4o-mini com streaming", exampleType: "text", color: "amber" },
  { label: "Tolerante (< 10s)", description: "Modelos de nível médio, balanceie qualidade/velocidade", example: "GPT-4o, Claude Sonnet", exampleType: "text", color: "green" },
  { label: "Async/Batch", description: "Use melhor modelo, processe em background", example: "GPT-4, Claude Opus para processamento offline", exampleType: "text", color: "blue" }
]} />

### Técnicas de Velocidade

<InfoGrid items={[
  { label: "Prompts Mais Curtos", description: "Menos tokens de entrada = processamento mais rápido", example: "Comprima prompts, remova contexto desnecessário", exampleType: "text", color: "cyan" },
  { label: "Limite Saída", description: "Defina max_tokens para prevenir respostas descontroladas", example: "max_tokens: 500 para resumos", exampleType: "text", color: "cyan" },
  { label: "Use Streaming", description: "Obtenha primeiros tokens mais rápido, melhor UX", example: "Stream para qualquer resposta > 100 tokens", exampleType: "text", color: "cyan" },
  { label: "Cache Agressivamente", description: "Não recompute queries idênticas", example: "Cache perguntas comuns, saídas de template", exampleType: "text", color: "cyan" }
]} />

## Otimização de Custo

Em escala, pequenas economias multiplicam em impacto significativo de orçamento.

### Entendendo Custos

Use esta calculadora para estimar seus custos de API em diferentes modelos:

<CostCalculatorDemo />

### Estratégias de Redução de Custo

<InfoGrid items={[
  { label: "Roteamento de Modelo", description: "Use modelos caros apenas quando necessário", example: "Perguntas simples → GPT-4o-mini, Complexas → GPT-4", exampleType: "text", color: "green" },
  { label: "Eficiência de Prompt", description: "Prompts mais curtos = menor custo por requisição", example: "Corte 50% dos tokens = 50% economia de custo de entrada", exampleType: "text", color: "green" },
  { label: "Controle de Saída", description: "Limite comprimento de resposta quando detalhe completo não é necessário", example: "\"Responda em 2-3 frases\" vs. ilimitado", color: "green" },
  { label: "Batching", description: "Combine queries relacionadas em requisições únicas", example: "Analise 10 itens em um prompt vs. 10 chamadas separadas", exampleType: "text", color: "green" },
  { label: "Pré-filtragem", description: "Não envie requisições que não precisam de IA", example: "Matching de palavras-chave antes de classificação cara", exampleType: "text", color: "green" }
]} />

## O Loop de Otimização

Otimização é iterativa. Aqui está um processo sistemático:

### Passo 1: Estabeleça Baseline

Você não pode melhorar o que não mede. Antes de mudar qualquer coisa, documente seu ponto de partida rigorosamente.

<InfoGrid items={[
  { label: "Documentação de Prompt", description: "Salve o texto exato do prompt, incluindo prompts de sistema e quaisquer templates", example: "Versione seus prompts como código", exampleType: "text", color: "blue" },
  { label: "Conjunto de Testes", description: "Crie 20-50 entradas representativas cobrindo casos comuns e casos limite", example: "Inclua exemplos fáceis, médios e difíceis", exampleType: "text", color: "blue" },
  { label: "Métricas de Qualidade", description: "Pontue cada saída contra seus critérios de sucesso", example: "% de precisão, score de relevância, conformidade de formato", exampleType: "text", color: "purple" },
  { label: "Métricas de Performance", description: "Meça tokens e timing para cada caso de teste", example: "Média entrada: 450 tokens, Média saída: 200 tokens, p50 latência: 1.2s", exampleType: "text", color: "purple" }
]} />

<TryIt 
  title="Template de Documentação de Baseline"
  description="Use para criar documentação abrangente de baseline antes de otimizar."
  prompt={`Crie documentação de baseline para meu projeto de otimização de prompt.

**Prompt atual**:
"\${promptAtual}"

**O que o prompt faz**: \${propositoPrompt}

**Problemas atuais que estou vendo**: \${problemasAtuais}

Gere um template de documentação de baseline com:

1. **Snapshot do Prompt**: O texto exato do prompt (para controle de versão)

2. **Casos de Teste**: Sugira 10 entradas de teste representativas que devo usar, cobrindo:
   - 3 casos típicos/fáceis
   - 4 casos de complexidade média  
   - 3 casos limite ou entradas difíceis

3. **Métricas a Acompanhar**:
   - Métricas de qualidade específicas para este caso de uso
   - Métricas de eficiência (tokens, latência)
   - Como pontuar cada métrica

4. **Hipótese de Baseline**: O que espero que a performance atual seja?

5. **Critérios de Sucesso**: Que números me deixariam satisfeito com a otimização?`}
/>

### Passo 2: Forme uma Hipótese

<Compare 
  before={{ label: "Objetivo vago", content: "Quero melhorar meu prompt." }}
  after={{ label: "Hipótese testável", content: "Se eu adicionar 2 exemplos few-shot, precisão vai melhorar de 75% para 85% porque o modelo vai aprender o padrão esperado." }}
/>

### Passo 3: Teste Uma Mudança

Mude uma coisa de cada vez. Execute ambas versões nas mesmas entradas de teste. Meça as métricas que importam.

### Passo 4: Analise e Decida

Funcionou? Mantenha a mudança. Prejudicou? Reverta. Foi neutro? Reverta (mais simples é melhor).

### Passo 5: Repita

Gere novas hipóteses baseadas no que aprendeu. Continue iterando até atingir seus objetivos ou alcançar retornos decrescentes.

## Checklist de Otimização

<Checklist 
  title="Antes de Implantar um Prompt Otimizado"
  items={[
    { text: "Definiu métricas de sucesso claras" },
    { text: "Mediu performance de baseline" },
    { text: "Testou mudanças em entradas representativas" },
    { text: "Verificou que qualidade não regrediu" },
    { text: "Verificou tratamento de casos limite" },
    { text: "Calculou custo na escala esperada" },
    { text: "Testou latência sob carga" },
    { text: "Documentou o que mudou e por quê" }
  ]}
/>

<Quiz 
  question="Você tem um prompt que funciona bem mas custa muito em escala. Qual é a PRIMEIRA coisa que deve fazer?"
  options={[
    "Mudar para um modelo mais barato imediatamente",
    "Remover palavras do prompt para reduzir tokens",
    "Medir qual parte do prompt está usando mais tokens",
    "Adicionar caching para todas requisições"
  ]}
  correctIndex={2}
  explanation="Antes de otimizar, meça. Você precisa entender para onde os tokens estão indo antes de poder reduzi-los efetivamente. O prompt pode ter contexto desnecessário, instruções verbosas ou gerar saídas mais longas que o necessário. Medição diz onde focar seus esforços de otimização."
/>
