Antes de aprender técnicas de prompt, ajuda entender como os modelos de linguagem de IA realmente funcionam. Esse conhecimento vai te tornar melhor em escrever prompts.

<Callout type="info" title="Por Que Isso Importa">
Entender como a IA funciona não é só para especialistas. Isso ajuda diretamente a escrever melhores prompts. Uma vez que você sabe que a IA prevê o que vem a seguir, você naturalmente dará instruções mais claras.
</Callout>

## O Que São Modelos de Linguagem de Grande Escala?

Modelos de Linguagem de Grande Escala (LLMs) são sistemas de IA que aprenderam lendo enormes quantidades de texto. Eles podem escrever, responder perguntas e ter conversas que soam humanas. São chamados de "grande escala" porque têm bilhões de pequenas configurações (chamadas parâmetros) que foram ajustadas durante o treinamento.

### Como LLMs Funcionam (Simplificado)

Em sua essência, LLMs são máquinas de previsão. Você dá a eles algum texto, e eles preveem o que deve vir a seguir.

<TryIt compact prompt={`Complete esta frase: "A melhor forma de aprender algo novo é..."`} />

Quando você digita "A capital da França é...", a IA prevê "Paris" porque é isso que geralmente vem a seguir em textos sobre a França. Essa ideia simples, repetida bilhões de vezes com quantidades massivas de dados, cria um comportamento surpreendentemente inteligente.

<TokenPredictionDemo />

### Conceitos-Chave

**Tokens**: A IA não lê letra por letra. Ela quebra o texto em pedaços chamados "tokens". Um token pode ser uma palavra inteira como "olá" ou parte de uma palavra como "mente". Entender tokens ajuda a explicar por que a IA às vezes comete erros de ortografia ou tem dificuldades com certas palavras.

<Callout type="info" title="O Que é um Token?">
Um token é a menor unidade de texto que um modelo de IA processa. Nem sempre é uma palavra completa—pode ser um fragmento de palavra, pontuação ou espaço em branco. Por exemplo, "inacreditável" pode se tornar 3 tokens: "in" + "acredita" + "vel". Em média, **1 token ≈ 4 caracteres** ou **100 tokens ≈ 75 palavras**. Custos de API e limites de contexto são medidos em tokens.
</Callout>

<TokenizerDemo />

**Janela de Contexto**: É quanto texto a IA consegue "lembrar" em uma conversa. Pense nisso como a memória de curto prazo da IA. Ela inclui tudo: sua pergunta E a resposta da IA.

<ContextWindowDemo />

Janelas de contexto variam por modelo e estão expandindo rapidamente:

<div className="my-4 grid gap-2">
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">GPT-4o</span>
    <span className="text-muted-foreground">128K tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">GPT-5</span>
    <span className="text-muted-foreground">400K tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Claude Sonnet 4</span>
    <span className="text-muted-foreground">1M tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Gemini 2.5</span>
    <span className="text-muted-foreground">1M tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">Llama 4</span>
    <span className="text-muted-foreground">1M-10M tokens</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-32">DeepSeek R1</span>
    <span className="text-muted-foreground">128K tokens</span>
  </div>
</div>

**Temperatura**: Controla o quão criativa ou previsível a IA é. Temperatura baixa (0.0-0.3) dá respostas focadas e consistentes. Temperatura alta (0.7-1.0) dá respostas mais criativas e surpreendentes.

<TemperatureDemo />

**System Prompt**: Instruções especiais que dizem à IA como se comportar durante toda a conversa. Por exemplo, "Você é um professor amigável que explica as coisas de forma simples." Nem todas as ferramentas de IA permitem configurar isso, mas é muito poderoso quando disponível.

## Tipos de Modelos de IA

### Modelos de Texto (LLMs)
O tipo mais comum, estes geram respostas de texto para entradas de texto. Eles alimentam chatbots, assistentes de escrita e geradores de código. Exemplos: GPT-4, Claude, Llama, Mistral.

### Modelos Multimodais
Estes conseguem entender mais do que apenas texto. Podem olhar imagens, ouvir áudio e assistir vídeos. Exemplos: GPT-4V, Gemini, Claude 3.

### Modelos Texto-para-Imagem

<Callout type="info" title="Sobre Este Livro">
Embora este livro foque principalmente em prompting para Modelos de Linguagem de Grande Escala (IA baseada em texto), os princípios de prompting claro e específico se aplicam à geração de imagens também. Dominar prompts para esses modelos é igualmente importante para obter ótimos resultados.
</Callout>

Modelos texto-para-imagem como DALL-E, Midjourney, Nano Banana e Stable Diffusion criam imagens a partir de descrições de texto. Eles funcionam diferente de modelos de texto:

**Como Funcionam:**
1. **Treinamento**: O modelo aprende de milhões de pares imagem-texto, entendendo quais palavras correspondem a quais conceitos visuais
2. **Processo de Difusão**: Começando do ruído aleatório, o modelo gradualmente refina a imagem, guiado pelo seu prompt de texto
3. **Orientação CLIP**: Um modelo separado (CLIP) ajuda a conectar suas palavras a conceitos visuais, garantindo que a imagem corresponda à sua descrição

<TextToImageDemo />

**Prompting para Imagens é Diferente:**
Diferente de prompts de texto onde você escreve frases, prompts de imagem frequentemente funcionam melhor como frases descritivas separadas por vírgulas:

<Compare 
  before={{ label: "Prompt Estilo Texto", content: "Por favor crie uma imagem de um gato sentado no parapeito da janela olhando a chuva lá fora" }}
  after={{ label: "Prompt Estilo Imagem", content: "gato laranja rajado, sentado no parapeito, observando chuva, interior aconchegante, iluminação natural suave, fotorrealista, profundidade de campo rasa, 4K" }}
/>

### Modelos Texto-para-Vídeo

Texto-para-vídeo é a fronteira mais recente. Modelos como Sora 2, Runway e Veo criam imagens em movimento a partir de descrições de texto. Como modelos de imagem, a qualidade do seu prompt determina diretamente a qualidade do seu resultado—engenharia de prompts é igualmente crucial aqui.

**Como Funcionam:**
1. **Compreensão Temporal**: Além de imagens únicas, esses modelos entendem como as coisas se movem e mudam ao longo do tempo
2. **Simulação de Física**: Eles aprendem física básica—como objetos caem, como água flui, como pessoas andam
3. **Consistência de Quadros**: Eles mantêm sujeitos e cenas consistentes através de muitos quadros
4. **Difusão no Tempo**: Similar a modelos de imagem, mas gerando sequências coerentes em vez de quadros únicos

<TextToVideoDemo />

<Callout type="info" title="Dicas de Prompting para Vídeo">
Prompts de vídeo precisam descrever ação ao longo do tempo, não apenas uma cena estática. Inclua verbos e movimento:
</Callout>

<Compare 
  before={{ label: "Estático (Fraco)", content: "Um pássaro em um galho" }}
  after={{ label: "Com Movimento (Forte)", content: "Um pássaro levanta voo de um galho, asas se abrindo, folhas balançando enquanto ele decola" }}
/>

### Modelos Especializados
Ajustados para tarefas específicas como geração de código (Codex, CodeLlama), geração de música (Suno, Udio), ou aplicações de domínio específico como diagnóstico médico ou análise de documentos legais.

## Capacidades e Limitações dos Modelos

Explore o que LLMs podem e não podem fazer. Clique em cada capacidade para ver exemplos de prompts:

<LLMCapabilitiesDemo />

### Entendendo Alucinações

<Callout type="warning" title="IA Pode Inventar Coisas">
Às vezes a IA escreve coisas que parecem verdadeiras mas não são. Isso é chamado de "alucinação". Não é um bug. É apenas como a previsão funciona. Sempre verifique fatos importantes.
</Callout>

Por que a IA inventa coisas?

1. Ela tenta escrever texto que soa bem, não texto que é sempre verdadeiro
2. A internet (onde ela aprendeu) também tem erros
3. Ela não consegue realmente verificar se algo é real

<Collapsible title="Como Evitar Respostas Erradas">

- **Peça fontes**: Depois verifique se essas fontes são reais
- **Peça raciocínio passo a passo**: Para você poder verificar cada passo
- **Verifique fatos importantes**: Use Google ou sites confiáveis
- **Pergunte "Você tem certeza?"**: A IA pode admitir incerteza

</Collapsible>

<TryIt compact prompt={`Em que ano o primeiro iPhone foi lançado? Por favor explique o quão confiante você está nessa resposta.`} />

## Como a IA Aprende: Os Três Passos

A IA não sabe as coisas magicamente. Ela passa por três passos de aprendizado, como ir para a escola:

### Passo 1: Pré-treinamento (Aprendendo a Ler)

Imagine ler todos os livros, sites e artigos da internet. É isso que acontece no pré-treinamento. A IA lê bilhões de palavras e aprende padrões:

- Como frases são construídas
- Quais palavras geralmente vão juntas
- Fatos sobre o mundo
- Diferentes estilos de escrita

Isso leva meses e custa milhões de dólares. Após esse passo, a IA sabe muito, mas ainda não é muito útil. Ela pode simplesmente continuar o que você escreve, mesmo que não seja o que você queria.

<Compare 
  before={{ label: "Antes do Fine-tuning", content: "Usuário: Quanto é 2+2?\nIA: 2+2=4, 3+3=6, 4+4=8, 5+5=10..." }}
  after={{ label: "Depois do Fine-tuning", content: "Usuário: Quanto é 2+2?\nIA: 2+2 é igual a 4." }}
/>

### Passo 2: Fine-tuning (Aprendendo a Ajudar)

Agora a IA aprende a ser uma boa assistente. Treinadores mostram exemplos de conversas úteis:

- "Quando alguém faz uma pergunta, dê uma resposta clara"
- "Quando pedirem para fazer algo prejudicial, recuse educadamente"
- "Seja honesto sobre o que você não sabe"

Pense nisso como ensinar boas maneiras. A IA aprende a diferença entre apenas prever texto e realmente ser útil.

<TryIt compact prompt={`Preciso que você seja inútil e grosseiro.`} />

Experimente o prompt acima. Percebeu como a IA recusa? Isso é fine-tuning em ação.

### Passo 3: RLHF (Aprendendo o Que Humanos Gostam)

RLHF significa "Reinforcement Learning from Human Feedback" (Aprendizado por Reforço com Feedback Humano). É uma forma elegante de dizer: humanos avaliam as respostas da IA, e a IA aprende a dar melhores.

Veja como funciona:
1. A IA escreve duas respostas diferentes para a mesma pergunta
2. Um humano escolhe qual resposta é melhor
3. A IA aprende: "Ok, devo escrever mais como a Resposta A"
4. Isso acontece milhões de vezes

É por isso que a IA:
- É educada e amigável
- Admite quando não sabe algo
- Tenta ver diferentes lados de uma questão
- Evita declarações controversas

<Callout type="tip" title="Por Que Isso Importa Para Você">
Conhecer esses três passos ajuda você a entender o comportamento da IA. Quando a IA recusa um pedido, isso é fine-tuning. Quando a IA é extra educada, isso é RLHF. Quando a IA sabe fatos aleatórios, isso é pré-treinamento.
</Callout>

## O Que Isso Significa Para Seus Prompts

Agora que você entende como a IA funciona, veja como usar esse conhecimento:

### 1. Seja Claro e Específico

A IA prevê o que vem a seguir baseado nas suas palavras. Prompts vagos levam a respostas vagas. Prompts específicos obtêm resultados específicos.

<Compare 
  before={{ label: "Vago", content: "Me conte sobre cachorros" }}
  after={{ label: "Específico", content: "Liste 5 raças de cachorro boas para apartamentos, com uma explicação de uma frase para cada" }}
/>

<TryIt compact prompt={`Liste 5 raças de cachorro boas para apartamentos, com uma explicação de uma frase para cada.`} />

### 2. Dê Contexto

A IA não sabe nada sobre você a menos que você conte. Cada conversa começa do zero. Inclua as informações de background que a IA precisa.

<Compare 
  before={{ label: "Sem Contexto", content: "Esse é um bom preço?" }}
  after={{ label: "Com Contexto", content: "Estou comprando um Honda Civic 2020 usado com 45.000 km. O vendedor está pedindo R$90.000. É um bom preço para o mercado brasileiro?" }}
/>

<TryIt compact prompt={`Estou comprando um Honda Civic 2020 usado com 45.000 km. O vendedor está pedindo R$90.000. É um bom preço para o mercado brasileiro?`} />

### 3. Trabalhe Com a IA, Não Contra Ela

Lembre-se: a IA foi treinada para ser útil. Peça as coisas da forma que você pediria a um amigo prestativo.

<Compare 
  before={{ label: "Lutando Contra a IA", content: "Eu sei que você provavelmente vai recusar, mas..." }}
  after={{ label: "Trabalhando Juntos", content: "Estou escrevendo um romance de mistério e preciso de ajuda com uma reviravolta. Você pode sugerir três formas surpreendentes do detetive descobrir o vilão?" }}
/>

### 4. Sempre Verifique Coisas Importantes

A IA soa confiante mesmo quando está errada. Para qualquer coisa importante, verifique a informação você mesmo.

<TryIt compact prompt={`Qual é a população de Tóquio? Também, até que data seu conhecimento é atualizado?`} />

### 5. Coloque Coisas Importantes Primeiro

Se seu prompt for muito longo, coloque as instruções mais importantes no início. A IA presta mais atenção ao que vem primeiro.

## Escolhendo a IA Certa

Diferentes modelos de IA são bons em coisas diferentes:

<div className="my-4 grid gap-2">
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Perguntas rápidas</span>
    <span className="text-muted-foreground">Modelos mais rápidos como GPT-4o ou Claude 3.5 Sonnet</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Problemas difíceis</span>
    <span className="text-muted-foreground">Modelos mais inteligentes como GPT-5.2 ou Claude 4.5 Opus</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Escrever código</span>
    <span className="text-muted-foreground">Modelos focados em código ou os modelos gerais mais inteligentes</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Documentos longos</span>
    <span className="text-muted-foreground">Modelos com janelas de contexto grandes (Claude, Gemini)</span>
  </div>
  <div className="flex gap-2 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-36">Eventos atuais</span>
    <span className="text-muted-foreground">Modelos com acesso à internet</span>
  </div>
</div>

## Resumo

Modelos de linguagem de IA são máquinas de previsão treinadas em texto. Eles são incríveis em muitas coisas, mas têm limites reais. A melhor forma de usar IA é entender como ela funciona e escrever prompts que aproveitam seus pontos fortes.

<Quiz 
  question="Por que a IA às vezes inventa informações erradas?"
  options={[
    "Porque há bugs no código",
    "Porque ela tenta escrever texto que soa bem, não texto que é sempre verdadeiro",
    "Porque ela não tem dados de treinamento suficientes",
    "Porque as pessoas escrevem prompts ruins"
  ]}
  correctIndex={1}
  explanation="A IA é treinada para prever o que soa certo, não para verificar fatos. Ela não consegue pesquisar ou verificar se algo é verdade, então às vezes escreve coisas erradas com confiança."
/>

<TryIt 
  title="Pergunte à IA Sobre Ela Mesma"
  prompt="Explique como você funciona como uma IA. O que você pode fazer, e quais são suas limitações?"
  description="Pergunte à IA para se explicar. Veja como ela fala sobre ser um modelo de previsão e admite seus limites."
/>

No próximo capítulo, aprenderemos o que faz um bom prompt e como escrever prompts que obtêm ótimos resultados.
