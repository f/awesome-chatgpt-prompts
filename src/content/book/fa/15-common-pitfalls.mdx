حتی مهندسان پرامپت با تجربه نیز در دام‌های قابل پیش‌بینی گرفتار می‌شوند. خبر خوب این است که وقتی این الگوها را بشناسید، اجتناب از آن‌ها آسان است. این فصل رایج‌ترین دام‌ها را بررسی می‌کند، توضیح می‌دهد که چرا رخ می‌دهند و استراتژی‌های عملی برای دوری از آن‌ها ارائه می‌دهد.

<Callout type="warning" title="چرا دام‌ها اهمیت دارند">
یک دام واحد می‌تواند یک هوش مصنوعی قدرتمند را به ابزاری ناامیدکننده تبدیل کند. درک این الگوها اغلب تفاوت بین «هوش مصنوعی برای من کار نمی‌کند» و «هوش مصنوعی جریان کارم را متحول کرد» است.
</Callout>

## دام ابهام

**الگو**: شما می‌دانید چه می‌خواهید، بنابراین فرض می‌کنید هوش مصنوعی هم متوجه خواهد شد. اما پرامپت‌های مبهم نتایج مبهم تولید می‌کنند.

<Compare 
  before={{ label: "پرامپت مبهم", content: "چیزی درباره بازاریابی بنویس." }}
  after={{ label: "پرامپت مشخص", content: "یک پست ۳۰۰ کلمه‌ای برای LinkedIn درباره اهمیت یکپارچگی برند برای شرکت‌های B2B SaaS بنویس که مدیران بازاریابی را هدف قرار می‌دهد. از لحن حرفه‌ای اما صمیمی استفاده کن. یک مثال عملی هم بیاور." }}
/>

**چرا این اتفاق می‌افتد**: ما طبیعتاً جزئیاتی را که فکر می‌کنیم «واضح» هستند نادیده می‌گیریم. اما آنچه برای شما واضح است، برای مدلی که هیچ زمینه‌ای درباره موقعیت، مخاطبان یا اهداف شما ندارد، واضح نیست.

<TryIt 
  title="بهبوددهنده دقت"
  description="یک پرامپت مبهم را بگیرید و آن را مشخص کنید. توجه کنید که چگونه افزودن جزئیات کیفیت نتایج را متحول می‌کند."
  prompt={`من یک پرامپت مبهم دارم که نیاز به بهبود دارد.

پرامپت مبهم اصلی: "\${vaguePrompt}"

این پرامپت را با افزودن موارد زیر مشخص کنید:
1. **مخاطب**: چه کسی این را خواهد خواند/استفاده خواهد کرد؟
2. **قالب**: چه ساختاری باید داشته باشد؟
3. **طول**: چقدر باید باشد؟
4. **لحن**: چه صدا یا سبکی؟
5. **زمینه**: موقعیت یا هدف چیست؟
6. **محدودیت‌ها**: چه چیزهایی حتماً باید باشد یا نباید باشد؟

پرامپت را با تمام این جزئیات بازنویسی کنید.`}
/>

## دام بارگذاری بیش از حد

**الگو**: شما سعی می‌کنید همه چیز را در یک پرامپت جای دهید—جامع، خنده‌دار، حرفه‌ای، مناسب مبتدیان، پیشرفته، بهینه‌سازی شده برای SEO، و کوتاه. نتیجه؟ هوش مصنوعی نیمی از الزامات شما را از دست می‌دهد یا یک آشفتگی گیج‌کننده تولید می‌کند.

<Compare 
  before={{ label: "پرامپت بارگذاری شده", content: "یک پست وبلاگ درباره هوش مصنوعی بنویس که SEO بهینه باشد و مثال‌های کد داشته باشد و خنده‌دار باشد اما حرفه‌ای و مبتدیان را هدف قرار دهد اما نکات پیشرفته هم داشته باشد و باید ۵۰۰ کلمه باشد اما جامع و محصول ما را ذکر کند و دعوت به اقدام داشته باشد..." }}
  after={{ label: "پرامپت متمرکز", content: "یک پست وبلاگ ۵۰۰ کلمه‌ای بنویس که هوش مصنوعی را به مبتدیان معرفی می‌کند.\n\nالزامات:\n۱. یک مفهوم اصلی را واضح توضیح بده\n۲. یک مثال کد ساده بیاور\n۳. با یک دعوت به اقدام تمام کن\n\nلحن: حرفه‌ای اما صمیمی" }}
/>

**چرا این اتفاق می‌افتد**: ترس از تعاملات متعدد، یا تمایل به «بیرون ریختن همه چیز» در یک بار. اما بار شناختی بیش از حد بر هوش مصنوعی همان تأثیری را دارد که بر انسان‌ها دارد—الزامات رقابتی بیش از حد منجر به از دست دادن موارد می‌شود.

<InfoGrid items={[
  { label: "محدود کردن الزامات", description: "در هر پرامپت به ۳ تا ۵ الزام کلیدی بچسبید", example: "تمرکز بر: مخاطب، قالب، طول، یک محدودیت کلیدی", exampleType: "text", color: "green" },
  { label: "استفاده از لیست‌های شماره‌دار", description: "ساختار اولویت‌ها را واضح می‌کند", example: "۱. باید X داشته باشد، ۲. باید Y داشته باشد، ۳. خوب است Z داشته باشد", exampleType: "text", color: "green" },
  { label: "زنجیره کردن پرامپت‌ها", description: "وظایف پیچیده را به مراحل تقسیم کنید", example: "اول: طرح کلی. سپس: پیش‌نویس بخش ۱. سپس: پیش‌نویس بخش ۲.", exampleType: "text", color: "green" },
  { label: "اولویت‌بندی بی‌رحمانه", description: "چه چیزی ضروری است در مقابل چه چیزی خوب است داشته باشیم؟", example: "اگر فقط می‌توانستم یک چیز را درست انجام دهم، چه می‌بود؟", color: "green" }
]} />

<Callout type="tip" title="زنجیره‌سازی پرامپت را یاد بگیرید">
وقتی یک پرامپت واحد بیش از حد بارگذاری می‌شود، [زنجیره‌سازی پرامپت](/book/11-prompt-chaining) اغلب راه‌حل است. وظایف پیچیده را به توالی از پرامپت‌های متمرکز تقسیم کنید، جایی که هر مرحله بر مرحله قبلی بنا می‌شود.
</Callout>

## دام فرض

**الگو**: شما به چیزی «از قبل» اشاره می‌کنید یا فرض می‌کنید هوش مصنوعی پروژه، شرکت، یا مکالمات قبلی شما را می‌شناسد. این‌طور نیست.

<Compare 
  before={{ label: "فرض زمینه", content: "تابعی که قبلاً نشانت دادم را برای افزودن مدیریت خطا به‌روزرسانی کن." }}
  after={{ label: "ارائه زمینه", content: "این تابع را برای افزودن مدیریت خطا به‌روزرسانی کن:\n\n```python\ndef calculate_total(items):\n    return sum(item.price for item in items)\n```\n\ntry/except برای لیست‌های خالی و آیتم‌های نامعتبر اضافه کن." }}
/>

**چرا این اتفاق می‌افتد**: مکالمات هوش مصنوعی مثل صحبت با یک همکار احساس می‌شود. اما برخلاف همکاران، اکثر مدل‌های هوش مصنوعی حافظه پایدار بین جلسات ندارند—هر مکالمه از صفر شروع می‌شود.

<TryIt 
  title="بررسی کامل بودن زمینه"
  description="از این استفاده کنید تا قبل از ارسال، تأیید کنید که پرامپت شما تمام زمینه‌های لازم را دارد."
  prompt={`این پرامپت را برای زمینه‌های گمشده بررسی کنید:

"\${promptToCheck}"

بررسی کنید:
1. **ارجاع داده شده اما شامل نشده**: آیا به «کد»، «سند»، «قبلاً» یا «بالا» اشاره می‌کند بدون اینکه محتوای واقعی را شامل شود؟

2. **دانش فرض شده**: آیا دانش درباره یک پروژه، شرکت یا موقعیت خاص را فرض می‌کند؟

3. **الزامات ضمنی**: آیا انتظارات نگفته‌ای درباره قالب، طول یا سبک وجود دارد؟

4. **پیش‌زمینه گمشده**: آیا یک غریبه باهوش متوجه خواهد شد چه چیزی خواسته می‌شود؟

آنچه گمشده است را لیست کنید و پیشنهاد دهید چگونه اضافه شود.`}
/>

## دام سؤال جهت‌دار

**الگو**: شما سؤال خود را به گونه‌ای بیان می‌کنید که فرض شما در آن جاسازی شده است، و به جای بینش، تأیید دریافت می‌کنید.

<Compare 
  before={{ label: "سؤال جهت‌دار", content: "چرا Python بهترین زبان برنامه‌نویسی برای علم داده است؟" }}
  after={{ label: "سؤال بی‌طرف", content: "Python، R و Julia را برای کار علم داده مقایسه کن. نقاط قوت و ضعف هر کدام چیست؟ چه زمانی یکی را بر دیگری ترجیح می‌دهید؟" }}
/>

**چرا این اتفاق می‌افتد**: ما اغلب به دنبال تأیید هستیم، نه اطلاعات. بیان ما به طور ناخودآگاه به سمت پاسخی که انتظار داریم یا می‌خواهیم هل می‌دهد.

<TryIt 
  title="آشکارساز تعصب"
  description="پرامپت‌های خود را برای تعصبات پنهان و زبان جهت‌دار بررسی کنید."
  prompt={`این پرامپت را برای تعصب و زبان جهت‌دار تحلیل کنید:

"\${promptToAnalyze}"

بررسی کنید:
1. **فرض‌های جاسازی شده**: آیا سؤال چیزی را درست فرض می‌کند؟
2. **بیان جهت‌دار**: آیا «چرا X خوب است؟» فرض می‌کند X خوب است؟
3. **جایگزین‌های گمشده**: آیا امکانات دیگر را نادیده می‌گیرد؟
4. **تأیید‌طلبی**: آیا به جای تحلیل، اعتبارسنجی می‌خواهد؟

پرامپت را بازنویسی کنید تا بی‌طرف و باز باشد.`}
/>

## دام اعتماد به همه چیز

**الگو**: پاسخ‌های هوش مصنوعی مطمئن و معتبر به نظر می‌رسند، بنابراین شما آن‌ها را بدون تأیید می‌پذیرید. اما اطمینان برابر با دقت نیست.

<InfoGrid items={[
  { label: "محتوای بررسی نشده", description: "انتشار متن تولید شده توسط هوش مصنوعی بدون بررسی واقعیت", example: "پست‌های وبلاگ با آمارهای ساختگی یا نقل‌قول‌های جعلی", exampleType: "text", color: "red" },
  { label: "کد تست نشده", description: "استفاده از کد هوش مصنوعی در تولید بدون تست", example: "آسیب‌پذیری‌های امنیتی، خرابی‌های موارد لبه‌ای، باگ‌های ظریف", exampleType: "text", color: "red" },
  { label: "تصمیمات کورکورانه", description: "گرفتن تصمیمات مهم فقط بر اساس تحلیل هوش مصنوعی", example: "استراتژی کسب‌وکار بر اساس داده‌های بازار توهم‌زده", exampleType: "text", color: "red" }
]} />

**چرا این اتفاق می‌افتد**: هوش مصنوعی حتی وقتی کاملاً اشتباه است هم مطمئن به نظر می‌رسد. ما همچنین مستعد «تعصب اتوماسیون» هستیم—تمایل به اعتماد بیش از حد به خروجی‌های کامپیوتر.

<TryIt 
  title="پرامپت تأیید"
  description="از این استفاده کنید تا هوش مصنوعی عدم قطعیت‌ها و خطاهای احتمالی خود را علامت‌گذاری کند."
  prompt={`من به اطلاعاتی درباره این موضوع نیاز دارم: \${topic}

مهم: بعد از پاسخ خود، بخشی به نام «یادداشت‌های تأیید» اضافه کنید که شامل موارد زیر باشد:

1. **سطح اطمینان**: چقدر درباره این اطلاعات مطمئن هستید؟ (بالا/متوسط/پایین)

2. **خطاهای احتمالی**: کدام بخش‌های این پاسخ احتمالاً اشتباه یا قدیمی هستند؟

3. **چه چیزی تأیید شود**: کدام ادعاهای خاص را کاربر باید مستقلاً بررسی کند؟

4. **منابع برای بررسی**: کاربر کجا می‌تواند این اطلاعات را تأیید کند؟

درباره محدودیت‌ها صادق باشید. بهتر است عدم قطعیت را علامت‌گذاری کنید تا اینکه درباره چیز اشتباهی مطمئن به نظر برسید.`}
/>

## دام تک‌تلاش

**الگو**: شما یک پرامپت می‌فرستید، نتیجه متوسطی می‌گیرید، و نتیجه می‌گیرید که هوش مصنوعی «برای مورد استفاده شما کار نمی‌کند». اما نتایج عالی تقریباً همیشه نیاز به تکرار دارند.

<Compare 
  before={{ label: "تفکر تک‌تلاش", content: "خروجی متوسط → «هوش مصنوعی نمی‌تواند این کار را انجام دهد» → تسلیم شدن" }}
  after={{ label: "تفکر تکراری", content: "خروجی متوسط → تحلیل اشکال → اصلاح پرامپت → خروجی بهتر → اصلاح مجدد → خروجی عالی" }}
/>

**چرا این اتفاق می‌افتد**: ما انتظار داریم هوش مصنوعی در اولین تلاش ذهن ما را بخواند. ما انتظار نداریم با جستجوهای Google تکرار کنیم، اما به نوعی از هوش مصنوعی انتظار کمال داریم.

<TryIt 
  title="کمک‌کننده تکرار"
  description="وقتی نتیجه اول درست نیست، از این برای بهبود سیستماتیک استفاده کنید."
  prompt={`پرامپت اصلی من این بود:
"\${originalPrompt}"

خروجی‌ای که گرفتم این بود:
"\${outputReceived}"

مشکل آن:
"\${whatIsWrong}"

کمکم کنید تکرار کنم:

1. **تشخیص**: چرا پرامپت اصلی این نتیجه را تولید کرد؟

2. **عناصر گمشده**: درباره چه چیزی صریح نبودم که باید می‌بودم؟

3. **پرامپت اصلاح‌شده**: پرامپت من را برای رفع این مشکلات بازنویسی کنید.

4. **چه چیزی را بررسی کنم**: در خروجی جدید چه چیزی را باید بررسی کنم؟`}
/>

## دام غفلت از قالب

**الگو**: شما بر آنچه می‌خواهید هوش مصنوعی بگوید تمرکز می‌کنید، اما فراموش می‌کنید مشخص کنید چگونه قالب‌بندی شود. سپس وقتی به JSON نیاز داشتید نثر می‌گیرید، یا وقتی به نقاط گلوله‌ای نیاز داشتید دیواری از متن می‌گیرید.

<Compare 
  before={{ label: "قالب مشخص نشده", content: "داده‌های کلیدی را از این متن استخراج کن." }}
  after={{ label: "قالب مشخص شده", content: "داده‌های کلیدی را از این متن به صورت JSON استخراج کن:\n\n{\n  \"name\": string,\n  \"date\": \"YYYY-MM-DD\",\n  \"amount\": number,\n  \"category\": string\n}\n\nفقط JSON را برگردان، بدون توضیح." }}
/>

**چرا این اتفاق می‌افتد**: ما بر محتوا تمرکز می‌کنیم نه ساختار. اما اگر نیاز دارید خروجی را به صورت برنامه‌نویسی تجزیه کنید، یا در جایی خاص بچسبانید، قالب به اندازه محتوا مهم است.

<TryIt 
  title="سازنده مشخصات قالب"
  description="مشخصات قالب واضح برای هر نوع خروجی که نیاز دارید تولید کنید."
  prompt={`من به خروجی هوش مصنوعی در قالب خاصی نیاز دارم.

**آنچه می‌خواهم**: \${taskDescription}
**نحوه استفاده از خروجی**: \${intendedUse}
**قالب ترجیحی**: \${formatType} (JSON، Markdown، CSV، نقاط گلوله‌ای و غیره)

یک مشخصات قالب تولید کنید که بتوانم به پرامپت خود اضافه کنم، شامل:

1. **ساختار دقیق** با نام فیلدها و انواع
2. **خروجی نمونه** که قالب را نشان می‌دهد
3. **محدودیت‌ها** (مثلاً «فقط JSON را برگردان، بدون توضیح»)
4. **موارد لبه‌ای** (اگر داده‌ای گم باشد چه چیزی خروجی شود)`}
/>

## دام پنجره زمینه

**الگو**: شما یک سند بسیار بزرگ می‌چسبانید و انتظار تحلیل جامع دارید. اما مدل‌ها محدودیت دارند—ممکن است برش دهند، تمرکز را از دست بدهند، یا جزئیات مهم در ورودی‌های طولانی را از دست بدهند.

<InfoGrid items={[
  { label: "محدودیت‌های خود را بشناسید", description: "مدل‌های مختلف پنجره‌های زمینه متفاوتی دارند", example: "GPT-4: ۱۲۸ هزار توکن، Claude: ۲۰۰ هزار توکن، Gemini: ۱ میلیون توکن", exampleType: "text", color: "blue" },
  { label: "ورودی‌های بزرگ را تکه کنید", description: "اسناد را به بخش‌های قابل مدیریت تقسیم کنید", example: "فصل‌ها را جداگانه تحلیل کنید، سپس ترکیب کنید", exampleType: "text", color: "blue" },
  { label: "اطلاعات مهم را جلو بیاورید", description: "زمینه حیاتی را در ابتدای پرامپت قرار دهید", example: "الزامات کلیدی اول، جزئیات پیش‌زمینه بعد", exampleType: "text", color: "blue" },
  { label: "چربی را حذف کنید", description: "زمینه غیرضروری را حذف کنید", example: "آیا واقعاً به کل سند نیاز دارید، یا فقط بخش‌های مربوطه؟", exampleType: "text", color: "blue" }
]} />

<TryIt 
  title="استراتژی تکه‌کردن سند"
  description="یک استراتژی برای پردازش اسنادی که از محدودیت‌های زمینه فراتر می‌روند بگیرید."
  prompt={`من یک سند بزرگ برای تحلیل دارم:

**نوع سند**: \${documentType}
**طول تقریبی**: \${documentLength}
**آنچه باید استخراج/تحلیل کنم**: \${analysisGoal}
**مدلی که استفاده می‌کنم**: \${modelName}

یک استراتژی تکه‌کردن ایجاد کنید:

1. **نحوه تقسیم**: نقاط شکست منطقی برای این نوع سند
2. **چه چیزی در هر تکه باشد**: زمینه لازم برای تحلیل مستقل
3. **نحوه ترکیب**: ترکیب نتایج از تکه‌های متعدد
4. **چه چیزی را بپایید**: اطلاعاتی که ممکن است بین تکه‌ها پخش شوند`}
/>

## دام انسان‌انگاری

**الگو**: شما با هوش مصنوعی مثل یک همکار انسانی رفتار می‌کنید—انتظار دارید که از وظایف «لذت ببرد»، شما را به یاد بیاورد، یا به نتایج اهمیت دهد. این‌طور نیست.

<Compare 
  before={{ label: "انسان‌انگاری شده", content: "مطمئنم از این پروژه خلاقانه لذت خواهی برد! می‌دانم که عاشق کمک به مردم هستی، و این واقعاً برای من شخصاً مهم است." }}
  after={{ label: "واضح و مستقیم", content: "یک داستان کوتاه خلاقانه با این مشخصات بنویس:\n- ژانر: علمی-تخیلی\n- طول: ۵۰۰ کلمه\n- لحن: امیدوار\n- باید شامل باشد: یک پایان غافلگیرکننده" }}
/>

**چرا این اتفاق می‌افتد**: پاسخ‌های هوش مصنوعی آنقدر شبیه انسان هستند که طبیعتاً به الگوهای اجتماعی می‌لغزیم. اما درخواست‌های احساسی هوش مصنوعی را وادار به تلاش بیشتر نمی‌کنند—دستورالعمل‌های واضح این کار را می‌کنند.

<Callout type="info" title="چه چیزی واقعاً کمک می‌کند">
به جای درخواست‌های احساسی، بر این موارد تمرکز کنید: الزامات واضح، مثال‌های خوب، محدودیت‌های خاص، و معیارهای موفقیت صریح. اینها خروجی‌ها را بهبود می‌دهند. «لطفاً واقعاً سخت تلاش کن» این کار را نمی‌کند.
</Callout>

## دام غفلت از امنیت

**الگو**: در عجله برای کار کردن چیزها، اطلاعات حساس را در پرامپت‌ها شامل می‌کنید—کلیدهای API، رمزهای عبور، داده‌های شخصی، یا اطلاعات اختصاصی.

<InfoGrid items={[
  { label: "اسرار در پرامپت‌ها", description: "کلیدهای API، رمزهای عبور، توکن‌ها در پرامپت‌ها چسبانده شده", example: "\"از این کلید API استفاده کن: sk-abc123...\"", color: "red" },
  { label: "داده‌های شخصی", description: "شامل اطلاعات شخصی که به سرورهای شخص ثالث فرستاده می‌شود", example: "نام‌های مشتری، ایمیل‌ها، آدرس‌ها در پرامپت‌ها", exampleType: "text", color: "red" },
  { label: "ورودی کاربر بدون پاکسازی", description: "ارسال مستقیم ورودی کاربر به پرامپت‌ها", example: "آسیب‌پذیری‌های تزریق پرامپت", exampleType: "text", color: "red" },
  { label: "اطلاعات اختصاصی", description: "اسرار تجاری یا داده‌های محرمانه", example: "استراتژی‌های داخلی، جزئیات محصول منتشر نشده", exampleType: "text", color: "red" }
]} />

**چرا این اتفاق می‌افتد**: تمرکز بر عملکرد به جای امنیت. اما به یاد داشته باشید: پرامپت‌ها اغلب به سرورهای خارجی می‌روند، ممکن است ثبت شوند، و می‌توانند برای آموزش استفاده شوند.

<TryIt 
  title="بررسی امنیتی"
  description="پرامپت خود را برای مسائل امنیتی قبل از ارسال بررسی کنید."
  prompt={`این پرامپت را برای نگرانی‌های امنیتی بررسی کنید:

"\${promptToReview}"

بررسی کنید:

1. **اسرار فاش شده**: کلیدهای API، رمزهای عبور، توکن‌ها، اعتبارنامه‌ها
2. **داده‌های شخصی**: نام‌ها، ایمیل‌ها، آدرس‌ها، شماره تلفن‌ها، شماره‌های ملی
3. **اطلاعات اختصاصی**: اسرار تجاری، استراتژی‌های داخلی، داده‌های محرمانه
4. **خطرات تزریق**: ورودی کاربر که می‌تواند پرامپت را دستکاری کند

برای هر مشکل یافت شده:
- خطر را توضیح دهید
- پیشنهاد دهید چگونه اطلاعات را سانسور یا محافظت کنید
- جایگزین‌های امن‌تر توصیه کنید`}
/>

## دام نادیده گرفتن توهم

**الگو**: شما استنادات، آمار، یا حقایق خاص می‌خواهید، و فرض می‌کنید واقعی هستند چون هوش مصنوعی آن‌ها را با اطمینان بیان کرد. اما هوش مصنوعی مرتباً اطلاعات باورپذیر می‌سازد.

<Compare 
  before={{ label: "اعتماد کورکورانه", content: "۵ آمار درباره بهره‌وری کار از راه دور با منابع بده." }}
  after={{ label: "پذیرش محدودیت‌ها", content: "درباره بهره‌وری کار از راه دور چه می‌دانیم؟ برای هر آماری که ذکر می‌کنی، مشخص کن آیا یافته‌های تثبیت شده هستند یا نامطمئن‌تر. من هر عدد خاصی را مستقلاً تأیید خواهم کرد." }}
/>

**چرا این اتفاق می‌افتد**: هوش مصنوعی متنی تولید می‌کند که معتبر به نظر می‌رسد. نمی‌«داند» که چه زمانی چیزها را می‌سازد—متن محتمل را پیش‌بینی می‌کند، نه حقایق تأیید شده را بازیابی می‌کند.

<TryIt 
  title="پرسش مقاوم در برابر توهم"
  description="پرامپت خود را ساختار دهید تا خطر توهم را به حداقل برسانید و عدم قطعیت‌ها را علامت‌گذاری کنید."
  prompt={`من به اطلاعاتی درباره این موضوع نیاز دارم: \${topic}

لطفاً این راهنماها را برای به حداقل رساندن خطاها دنبال کنید:

1. **به حقایق تثبیت شده بچسبید**. از ادعاهای مبهم که تأیید آن‌ها سخت است اجتناب کنید.

2. **عدم قطعیت را علامت‌گذاری کنید**. اگر درباره چیزی مطمئن نیستید، بگویید «من فکر می‌کنم...» یا «این ممکن است نیاز به تأیید داشته باشد...»

3. **منابع ساختگی نیاورید**. مقالات، کتاب‌ها یا URLهای خاص را استناد نکنید مگر مطمئن باشید وجود دارند. در عوض، توصیف کنید این نوع اطلاعات کجا پیدا می‌شود.

4. **محدودیت‌های دانش را بپذیرید**. اگر سؤال من درباره رویدادهای بعد از داده‌های آموزشی شماست، بگویید.

5. **حقیقت را از استنتاج جدا کنید**. به وضوح بین «X درست است» و «بر اساس Y، X احتمالاً درست است» تمایز قائل شوید.

حالا، با در نظر گرفتن این راهنماها: \${actualQuestion}`}
/>

## چک‌لیست قبل از ارسال

قبل از ارسال هر پرامپت مهمی، این چک‌لیست سریع را مرور کنید:

<Checklist 
  title="بررسی کیفیت پرامپت"
  items={[
    { text: "آیا به اندازه کافی مشخص است؟ (نه مبهم)" },
    { text: "آیا متمرکز است؟ (بارگذاری بیش از حد با الزامات نیست)" },
    { text: "آیا تمام زمینه‌های لازم را شامل می‌شود؟" },
    { text: "آیا سؤال بی‌طرف است؟ (جهت‌دار نیست)" },
    { text: "آیا قالب خروجی را مشخص کرده‌ام؟" },
    { text: "آیا ورودی در محدوده زمینه است؟" },
    { text: "آیا نگرانی امنیتی وجود دارد؟" },
    { text: "آیا آماده تأیید خروجی هستم؟" },
    { text: "آیا در صورت نیاز آماده تکرار هستم؟" }
  ]}
/>

<Quiz 
  question="خطرناک‌ترین دام هنگام استفاده از هوش مصنوعی برای تصمیمات مهم چیست؟"
  options={[
    "استفاده از پرامپت‌های مبهم",
    "اعتماد به خروجی‌های هوش مصنوعی بدون تأیید",
    "مشخص نکردن قالب خروجی",
    "بارگذاری بیش از حد پرامپت‌ها با الزامات"
  ]}
  correctIndex={1}
  explanation="در حالی که همه دام‌ها مشکل ایجاد می‌کنند، اعتماد به خروجی‌های هوش مصنوعی بدون تأیید خطرناک‌ترین است زیرا می‌تواند منجر به انتشار اطلاعات نادرست، استقرار کد باگ‌دار، یا تصمیم‌گیری بر اساس داده‌های توهم‌زده شود. هوش مصنوعی حتی وقتی کاملاً اشتباه است هم مطمئن به نظر می‌رسد، که تأیید را برای هر مورد استفاده مهمی ضروری می‌کند."
/>

## پرامپت‌های خود را تحلیل کنید

از هوش مصنوعی برای دریافت بازخورد فوری درباره کیفیت پرامپت خود استفاده کنید. هر پرامپتی را بچسبانید و تحلیل دقیق بگیرید:

<PromptAnalyzer 
  title="تحلیل‌گر کیفیت پرامپت"
  description="بازخورد مبتنی بر هوش مصنوعی درباره وضوح، دقت، و پیشنهادات برای بهبود بگیرید"
  defaultPrompt="کمکم کن با کدم"
/>

## این پرامپت را عیب‌یابی کنید

می‌توانید تشخیص دهید این پرامپت چه مشکلی دارد؟

<PromptDebugger
  title="دام را پیدا کنید"
  badPrompt="یک پست وبلاگ درباره فناوری بنویس که SEO بهینه با کلمات کلیدی باشد و همچنین خنده‌دار اما حرفه‌ای باشد و مثال‌های کد داشته باشد و مبتدیان را هدف قرار دهد اما نکات پیشرفته داشته باشد و محصول ما TechCo را ذکر کند و اثبات اجتماعی و دعوت به اقدام داشته باشد و ۵۰۰ کلمه باشد اما جامع."
  badOutput="اینجا یک پیش‌نویس پست وبلاگ درباره فناوری است...

[محتوای عمومی و بدون تمرکز که سعی می‌کند همه کار را انجام دهد اما هیچ کاری را خوب انجام نمی‌دهد. لحن به طرز ناشیانه‌ای بین غیررسمی و فنی تغییر می‌کند. نیمی از الزامات گمشده است.]"
  options={[
    { id: "vague", label: "پرامپت خیلی مبهم است", isCorrect: false, explanation: "در واقع، پرامپت الزامات خاص زیادی دارد. مشکل برعکس است—الزامات خیلی زیاد، نه خیلی کم." },
    { id: "overload", label: "پرامپت با الزامات رقابتی بیش از حد بارگذاری شده", isCorrect: true, explanation: "درست است! این پرامپت SEO + خنده‌دار + حرفه‌ای + کد + مبتدیان + پیشرفته + ذکر محصول + اثبات اجتماعی + دعوت به اقدام + محدودیت طول می‌خواهد. این بیش از ۱۰ الزام رقابتی است! هوش مصنوعی نمی‌تواند همه را برآورده کند، بنابراین روی همه چیز کار متوسطی انجام می‌دهد. راه‌حل: این را به چند پرامپت متمرکز تقسیم کنید." },
    { id: "format", label: "قالب خروجی مشخص نشده", isCorrect: false, explanation: "در حالی که قالب مشخص‌تر کمک می‌کرد، مشکل اصلی بارگذاری بیش از حد الزامات است. نمی‌توانید با قالب‌بندی از خواستن بیش از حد فرار کنید." },
    { id: "context", label: "زمینه کافی وجود ندارد", isCorrect: false, explanation: "پرامپت در واقع زمینه زیادی دارد—شاید بیش از حد! مشکل این است که سعی می‌کند همزمان اهداف زیادی را برآورده کند." }
  ]}
  hint="بشمارید چند الزام مختلف در این پرامپت واحد جای گرفته است."
/>
