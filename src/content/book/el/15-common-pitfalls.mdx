Ακόμα και έμπειροι μηχανικοί prompts πέφτουν σε προβλέψιμες παγίδες. Τα καλά νέα; Μόλις αναγνωρίσεις αυτά τα μοτίβα, είναι εύκολο να τα αποφύγεις. Αυτό το κεφάλαιο περνά από τις πιο κοινές παγίδες, εξηγεί γιατί συμβαίνουν, και σου δίνει συγκεκριμένες στρατηγικές για να τις παρακάμψεις.

<Callout type="warning" title="Γιατί Έχουν Σημασία οι Παγίδες">
Μια μόνο παγίδα μπορεί να μετατρέψει ένα ισχυρό AI σε απογοητευτικό εργαλείο. Η κατανόηση αυτών των μοτίβων είναι συχνά η διαφορά μεταξύ "το AI δεν δουλεύει για μένα" και "το AI μεταμόρφωσε τη ροή εργασίας μου."
</Callout>

## Η Παγίδα της Ασάφειας

**Το Μοτίβο**: Ξέρεις τι θέλεις, οπότε υποθέτεις ότι το AI θα το καταλάβει επίσης. Αλλά ασαφή prompts παράγουν ασαφή αποτελέσματα.

<Compare 
  before={{ label: "Ασαφές prompt", content: "Γράψε κάτι για το marketing." }}
  after={{ label: "Συγκεκριμένο prompt", content: "Γράψε μια ανάρτηση LinkedIn 300 λέξεων για τη σημασία της συνέπειας brand για B2B SaaS εταιρείες, στοχεύοντας marketing managers. Χρησιμοποίησε επαγγελματικό αλλά προσιτό τόνο. Συμπεριέλαβε ένα συγκεκριμένο παράδειγμα." }}
/>

**Γιατί συμβαίνει**: Φυσικά παραλείπουμε λεπτομέρειες όταν νομίζουμε ότι είναι "προφανείς." Αλλά αυτό που είναι προφανές για σένα δεν είναι προφανές σε ένα μοντέλο που δεν έχει πλαίσιο για την κατάστασή σου, το κοινό, ή τους στόχους σου.

<TryIt 
  title="Βελτιωτής Συγκεκριμένοτητας"
  description="Πάρε ένα ασαφές prompt και κάν' το συγκεκριμένο. Παρατήρησε πώς η προσθήκη λεπτομερειών μεταμορφώνει την ποιότητα των αποτελεσμάτων."
  prompt={`Έχω ένα ασαφές prompt που χρειάζεται βελτίωση.

Αρχικό ασαφές prompt: "\${vaguePrompt}"

Κάνε αυτό το prompt συγκεκριμένο προσθέτοντας:
1. **Κοινό**: Ποιος θα διαβάσει/χρησιμοποιήσει αυτό;
2. **Μορφή**: Τι δομή πρέπει να έχει;
3. **Μήκος**: Πόσο μακρύ πρέπει να είναι;
4. **Τόνος**: Ποια φωνή ή στυλ;
5. **Πλαίσιο**: Ποια είναι η κατάσταση ή ο σκοπός;
6. **Περιορισμοί**: Οτιδήποτε πρέπει οπωσδήποτε να υπάρχει ή να αποφευχθεί;

Ξαναγράψε το prompt με όλες αυτές τις λεπτομέρειες συμπεριλαμβανόμενες.`}
/>

## Η Παγίδα της Υπερφόρτωσης

**Το Μοτίβο**: Προσπαθείς να πάρεις τα πάντα σε ένα prompt—ολοκληρωμένο, αστείο, επαγγελματικό, φιλικό προς αρχάριους, προχωρημένο, SEO-βελτιστοποιημένο, και σύντομο. Το αποτέλεσμα; Το AI χάνει τις μισές απαιτήσεις σου ή παράγει ένα μπερδεμένο χάος.

<Compare 
  before={{ label: "Υπερφορτωμένο prompt", content: "Γράψε μια ανάρτηση blog για AI που είναι SEO optimized και περιλαμβάνει παραδείγματα κώδικα και είναι αστείο αλλά επαγγελματικό και στοχεύει αρχάριους αλλά έχει επίσης προχωρημένες συμβουλές και πρέπει να είναι 500 λέξεις αλλά ολοκληρωμένο και αναφέρει το προϊόν μας και έχει call to action..." }}
  after={{ label: "Εστιασμένο prompt", content: "Γράψε μια ανάρτηση blog 500 λέξεων που εισάγει το AI σε αρχάριους.\n\nΑπαιτήσεις:\n1. Εξήγησε μια βασική έννοια καθαρά\n2. Συμπεριέλαβε ένα απλό παράδειγμα κώδικα\n3. Τέλειωσε με call to action\n\nΤόνος: Επαγγελματικός αλλά προσιτός" }}
/>

**Γιατί συμβαίνει**: Φόβος πολλαπλών αλληλεπιδράσεων, ή επιθυμία να "τα βγάλεις όλα" με τη μία. Αλλά η γνωστική υπερφόρτωση επηρεάζει το AI όπως επηρεάζει τους ανθρώπους—πάρα πολλές ανταγωνιστικές απαιτήσεις οδηγούν σε παράλειψη στοιχείων.

<InfoGrid items={[
  { label: "Περιόρισε τις Απαιτήσεις", description: "Μείνε σε 3-5 βασικές απαιτήσεις ανά prompt", example: "Εστίασε σε: κοινό, μορφή, μήκος, έναν βασικό περιορισμό", exampleType: "text", color: "green" },
  { label: "Χρησιμοποίησε Αριθμημένες Λίστες", description: "Η δομή κάνει σαφείς τις προτεραιότητες", example: "1. Πρέπει να έχει X, 2. Καλό να έχει Y, 3. Προαιρετικό Z", exampleType: "text", color: "green" },
  { label: "Αλυσίδωσε Prompts", description: "Σπάσε πολύπλοκες εργασίες σε βήματα", example: "Πρώτα: περίληψη. Μετά: σχέδιο ενότητας 1. Μετά: σχέδιο ενότητας 2.", exampleType: "text", color: "green" },
  { label: "Προτεραιοποίησε Αδυσώπητα", description: "Τι είναι απαραίτητο vs. καλό να υπάρχει;", example: "Αν μπορούσα να πετύχω ΜΟΝΟ ένα πράγμα σωστά, τι θα ήταν;", color: "green" }
]} />

<Callout type="tip" title="Μάθε Prompt Chaining">
Όταν ένα μόνο prompt υπερφορτώνεται, το [prompt chaining](/book/11-prompt-chaining) είναι συχνά η λύση. Σπάσε πολύπλοκες εργασίες σε μια ακολουθία εστιασμένων prompts, όπου κάθε βήμα χτίζει πάνω στο προηγούμενο.
</Callout>

## Η Παγίδα της Υπόθεσης

**Το Μοτίβο**: Αναφέρεσαι σε κάτι "από πριν" ή υποθέτεις ότι το AI ξέρει το έργο σου, την εταιρεία σου, ή τις προηγούμενες συνομιλίες σου. Δεν ξέρει.

<Compare 
  before={{ label: "Υποθέτει context", content: "Ενημέρωσε τη συνάρτηση που σου έδειξα πριν για να προσθέσεις χειρισμό σφαλμάτων." }}
  after={{ label: "Παρέχει context", content: "Ενημέρωσε αυτή τη συνάρτηση για να προσθέσεις χειρισμό σφαλμάτων:\n\n```python\ndef calculate_total(items):\n    return sum(item.price for item in items)\n```\n\nΠρόσθεσε try/except για κενές λίστες και μη έγκυρα στοιχεία." }}
/>

**Γιατί συμβαίνει**: Οι συνομιλίες AI μοιάζουν με ομιλία σε συνάδελφο. Αλλά σε αντίθεση με τους συναδέλφους, τα περισσότερα μοντέλα AI δεν έχουν μόνιμη μνήμη μεταξύ συνεδριών—κάθε συνομιλία ξεκινά από την αρχή.

<TryIt 
  title="Έλεγχος Πληρότητας Context"
  description="Χρησιμοποίησέ το για να επαληθεύσεις ότι το prompt σου περιέχει όλο το απαραίτητο context πριν το στείλεις."
  prompt={`Αναθεώρησε αυτό το prompt για ελλείπον context:

"\${promptToCheck}"

Έλεγξε για:
1. **Αναφέρεται αλλά δεν συμπεριλαμβάνεται**: Αναφέρει "τον κώδικα," "το έγγραφο," "πριν," ή "πάνω" χωρίς να συμπεριλαμβάνει το πραγματικό περιεχόμενο;

2. **Υποτιθέμενη γνώση**: Υποθέτει γνώση για συγκεκριμένο έργο, εταιρεία, ή κατάσταση;

3. **Σιωπηρές απαιτήσεις**: Υπάρχουν αδήλωτες προσδοκίες για μορφή, μήκος, ή στυλ;

4. **Ελλείπον υπόβαθρο**: Θα καταλάβαινε ένας έξυπνος άγνωστος τι ζητείται;

Λίστα τι λείπει και πρότεινε πώς να το προσθέσεις.`}
/>

## Η Παγίδα της Καθοδηγητικής Ερώτησης

**Το Μοτίβο**: Διατυπώνεις την ερώτησή σου με τρόπο που ενσωματώνει την υπόθεσή σου, παίρνοντας πίσω επιβεβαίωση αντί για διορατικότητα.

<Compare 
  before={{ label: "Καθοδηγητική ερώτηση", content: "Γιατί είναι η Python η καλύτερη γλώσσα προγραμματισμού για data science;" }}
  after={{ label: "Ουδέτερη ερώτηση", content: "Σύγκρινε Python, R, και Julia για εργασία data science. Ποια είναι τα δυνατά και αδύνατα σημεία κάθε μιας; Πότε θα επέλεγες τη μία πάνω από τις άλλες;" }}
/>

**Γιατί συμβαίνει**: Συχνά αναζητούμε επιβεβαίωση, όχι πληροφορία. Η διατύπωσή μας ασυνείδητα ωθεί προς την απάντηση που περιμένουμε ή θέλουμε.

<TryIt 
  title="Ανιχνευτής Προκατάληψης"
  description="Έλεγξε τα prompts σου για κρυφές προκαταλήψεις και καθοδηγητική γλώσσα."
  prompt={`Ανάλυσε αυτό το prompt για προκατάληψη και καθοδηγητική γλώσσα:

"\${promptToAnalyze}"

Έλεγξε για:
1. **Ενσωματωμένες υποθέσεις**: Υποθέτει η ερώτηση ότι κάτι είναι αληθές;
2. **Καθοδηγητική διατύπωση**: Το "Γιατί είναι καλό το X;" υποθέτει ότι το X είναι καλό;
3. **Ελλείπουσες εναλλακτικές**: Αγνοεί άλλες δυνατότητες;
4. **Αναζήτηση επιβεβαίωσης**: Ζητά επικύρωση αντί για ανάλυση;

Ξαναγράψε το prompt να είναι ουδέτερο και ανοιχτό.`}
/>

## Η Παγίδα της Τυφλής Εμπιστοσύνης

**Το Μοτίβο**: Οι απαντήσεις AI ακούγονται σίγουρες και αυθεντικές, οπότε τις αποδέχεσαι χωρίς επαλήθευση. Αλλά η αυτοπεποίθηση δεν ισοδυναμεί με ακρίβεια.

<InfoGrid items={[
  { label: "Μη Ελεγμένο Περιεχόμενο", description: "Δημοσίευση AI-παραγμένου κειμένου χωρίς έλεγχο γεγονότων", example: "Αναρτήσεις blog με επινοημένα στατιστικά ή ψεύτικα αποσπάσματα", exampleType: "text", color: "red" },
  { label: "Μη Δοκιμασμένος Κώδικας", description: "Χρήση AI κώδικα σε παραγωγή χωρίς δοκιμές", example: "Ευπάθειες ασφαλείας, αποτυχίες ακραίων περιπτώσεων, λεπτά bugs", exampleType: "text", color: "red" },
  { label: "Τυφλές Αποφάσεις", description: "Λήψη σημαντικών επιλογών βασισμένες μόνο σε ανάλυση AI", example: "Επιχειρηματική στρατηγική βασισμένη σε ψευδαισθητικά δεδομένα αγοράς", exampleType: "text", color: "red" }
]} />

**Γιατί συμβαίνει**: Το AI ακούγεται σίγουρο ακόμα κι όταν είναι εντελώς λάθος. Είμαστε επίσης επιρρεπείς σε "προκατάληψη αυτοματισμού"—την τάση να εμπιστευόμαστε εξόδους υπολογιστών περισσότερο από όσο πρέπει.

<TryIt 
  title="Prompt Επαλήθευσης"
  description="Χρησιμοποίησέ το για να κάνεις το AI να σημειώσει τις δικές του αβεβαιότητες και πιθανά σφάλματα."
  prompt={`Χρειάζομαι να παρέχεις πληροφορίες για: \${topic}

ΣΗΜΑΝΤΙΚΟ: Μετά την απάντησή σου, πρόσθεσε μια ενότητα "Σημειώσεις Επαλήθευσης" που περιλαμβάνει:

1. **Επίπεδο Εμπιστοσύνης**: Πόσο σίγουρος είσαι για αυτή την πληροφορία; (Υψηλό/Μέσο/Χαμηλό)

2. **Πιθανά Σφάλματα**: Ποια τμήματα αυτής της απάντησης είναι πιθανότερο να είναι λάθος ή ξεπερασμένα;

3. **Τι να Επαληθεύσεις**: Ποιους συγκεκριμένους ισχυρισμούς πρέπει ο χρήστης να ελέγξει ανεξάρτητα;

4. **Πηγές για Έλεγχο**: Πού θα μπορούσε ο χρήστης να επαληθεύσει αυτές τις πληροφορίες;

Να είσαι ειλικρινής για τους περιορισμούς. Είναι καλύτερα να σημειώσεις αβεβαιότητα παρά να ακούγεσαι σίγουρος για κάτι λάθος.`}
/>

## Η Παγίδα της Μιας Προσπάθειας

**Το Μοτίβο**: Στέλνεις ένα prompt, παίρνεις ένα μέτριο αποτέλεσμα, και συμπεραίνεις ότι το AI "δεν λειτουργεί" για την περίπτωση χρήσης σου. Αλλά εξαιρετικά αποτελέσματα σχεδόν πάντα απαιτούν επανάληψη.

<Compare 
  before={{ label: "Σκέψη μιας προσπάθειας", content: "Μέτριο αποτέλεσμα → \"Το AI δεν μπορεί να το κάνει\" → Παράτα το" }}
  after={{ label: "Επαναληπτική σκέψη", content: "Μέτριο αποτέλεσμα → Ανάλυσε τι είναι λάθος → Βελτίωσε prompt → Καλύτερο αποτέλεσμα → Βελτίωσε ξανά → Εξαιρετικό αποτέλεσμα" }}
/>

**Γιατί συμβαίνει**: Περιμένουμε το AI να διαβάσει το μυαλό μας με την πρώτη προσπάθεια. Δεν περιμένουμε να επαναλάβουμε με αναζητήσεις Google, αλλά κάπως περιμένουμε τελειότητα από το AI.

<TryIt 
  title="Βοηθός Επανάληψης"
  description="Όταν το πρώτο σου αποτέλεσμα δεν είναι σωστό, χρησιμοποίησέ το για συστηματική βελτίωση."
  prompt={`Το αρχικό μου prompt ήταν:
"\${originalPrompt}"

Η έξοδος που πήρα ήταν:
"\${outputReceived}"

Τι είναι λάθος με αυτήν:
"\${whatIsWrong}"

Βοήθησέ με να επαναλάβω:

1. **Διάγνωση**: Γιατί το αρχικό prompt παρήγαγε αυτό το αποτέλεσμα;

2. **Ελλείποντα Στοιχεία**: Για τι δεν ήμουν ρητός που θα έπρεπε;

3. **Αναθεωρημένο Prompt**: Ξαναγράψε το prompt μου για να αντιμετωπίσει αυτά τα ζητήματα.

4. **Τι να Προσέξεις**: Τι πρέπει να ελέγξω στη νέα έξοδο;`}
/>

## Η Παγίδα της Παράλειψης Μορφής

**Το Μοτίβο**: Εστιάζεις σε τι θέλεις να πει το AI, αλλά ξεχνάς να καθορίσεις πώς πρέπει να μορφοποιηθεί. Μετά παίρνεις πεζό κείμενο όταν χρειαζόσουν JSON, ή τοίχο κειμένου όταν χρειαζόσουν κουκκίδες.

<Compare 
  before={{ label: "Χωρίς καθορισμό μορφής", content: "Εξαγάγε τα βασικά δεδομένα από αυτό το κείμενο." }}
  after={{ label: "Με καθορισμό μορφής", content: "Εξαγάγε τα βασικά δεδομένα από αυτό το κείμενο ως JSON:\n\n{\n  \"name\": string,\n  \"date\": \"YYYY-MM-DD\",\n  \"amount\": number,\n  \"category\": string\n}\n\nΕπέστρεψε ΜΟΝΟ το JSON, χωρίς εξήγηση." }}
/>

**Γιατί συμβαίνει**: Εστιάζουμε σε περιεχόμενο πάνω από δομή. Αλλά αν χρειάζεται να αναλύσεις την έξοδο προγραμματιστικά, ή να την επικολλήσεις κάπου συγκεκριμένα, η μορφή έχει τόση σημασία όσο και το περιεχόμενο.

<TryIt 
  title="Δημιουργός Προδιαγραφών Μορφής"
  description="Δημιούργησε σαφείς προδιαγραφές μορφής για οποιονδήποτε τύπο εξόδου χρειάζεσαι."
  prompt={`Χρειάζομαι έξοδο AI σε συγκεκριμένη μορφή.

**Τι ζητάω**: \${taskDescription}
**Πώς θα χρησιμοποιήσω την έξοδο**: \${intendedUse}
**Προτιμώμενη μορφή**: \${formatType} (JSON, Markdown, CSV, κουκκίδες, κλπ.)

Δημιούργησε προδιαγραφή μορφής που μπορώ να προσθέσω στο prompt μου, συμπεριλαμβανομένων:

1. **Ακριβής δομή** με ονόματα πεδίων και τύπους
2. **Παράδειγμα εξόδου** που δείχνει τη μορφή
3. **Περιορισμοί** (π.χ., "Επέστρεψε ΜΟΝΟ το JSON, χωρίς εξήγηση")
4. **Ακραίες περιπτώσεις** (τι να εξαχθεί αν λείπουν δεδομένα)`}
/>

## Η Παγίδα του Παραθύρου Context

**Το Μοτίβο**: Επικολλάς ένα τεράστιο έγγραφο και περιμένεις ολοκληρωμένη ανάλυση. Αλλά τα μοντέλα έχουν όρια—μπορεί να περικόψουν, να χάσουν εστίαση, ή να χάσουν σημαντικές λεπτομέρειες σε μακριές εισόδους.

<InfoGrid items={[
  { label: "Γνώρισε τα Όριά σου", description: "Διαφορετικά μοντέλα έχουν διαφορετικά παράθυρα context", example: "GPT-4: 128K tokens, Claude: 200K tokens, Gemini: 1M tokens", exampleType: "text", color: "blue" },
  { label: "Τεμάχισε Μεγάλες Εισόδους", description: "Σπάσε έγγραφα σε διαχειρίσιμες ενότητες", example: "Ανάλυσε κεφάλαια ξεχωριστά, μετά σύνθεσε", exampleType: "text", color: "blue" },
  { label: "Βάλε Σημαντικές Πληροφορίες Μπροστά", description: "Τοποθέτησε κρίσιμο context νωρίς στο prompt", example: "Βασικές απαιτήσεις πρώτα, λεπτομέρειες υποβάθρου μετά", exampleType: "text", color: "blue" },
  { label: "Κόψε το Περιττό", description: "Αφαίρεσε περιττό context", example: "Χρειάζεσαι πραγματικά ολόκληρο το έγγραφο, ή μόνο σχετικές ενότητες;", exampleType: "text", color: "blue" }
]} />

<TryIt 
  title="Στρατηγική Τεμαχισμού Εγγράφου"
  description="Λάβε στρατηγική για επεξεργασία εγγράφων που υπερβαίνουν τα όρια context."
  prompt={`Έχω ένα μεγάλο έγγραφο προς ανάλυση:

**Τύπος εγγράφου**: \${documentType}
**Κατά προσέγγιση μήκος**: \${documentLength}
**Τι χρειάζομαι να εξαγάγω/αναλύσω**: \${analysisGoal}
**Μοντέλο που χρησιμοποιώ**: \${modelName}

Δημιούργησε στρατηγική τεμαχισμού:

1. **Πώς να διαιρέσεις**: Λογικά σημεία διακοπής για αυτόν τον τύπο εγγράφου
2. **Τι να συμπεριλάβεις σε κάθε τεμάχιο**: Context που χρειάζεται για αυτόνομη ανάλυση
3. **Πώς να συνθέσεις**: Συνδυασμός αποτελεσμάτων από πολλαπλά τεμάχια
4. **Τι να προσέξεις**: Πληροφορίες που μπορεί να εκτείνονται σε τεμάχια`}
/>

## Η Παγίδα της Ανθρωπομορφοποίησης

**Το Μοτίβο**: Αντιμετωπίζεις το AI σαν ανθρώπινο συνάδελφο—περιμένοντάς το να "απολαύσει" εργασίες, να σε θυμάται, ή να νοιάζεται για αποτελέσματα. Δεν το κάνει.

<Compare 
  before={{ label: "Ανθρωπομορφοποιημένο", content: "Είμαι σίγουρος ότι θα απολαύσεις αυτό το δημιουργικό έργο! Ξέρω ότι αγαπάς να βοηθάς ανθρώπους, και αυτό είναι πολύ σημαντικό για μένα προσωπικά." }}
  after={{ label: "Σαφές και άμεσο", content: "Γράψε μια δημιουργική μικρή ιστορία με αυτές τις προδιαγραφές:\n- Είδος: Επιστημονική φαντασία\n- Μήκος: 500 λέξεις\n- Τόνος: Ελπιδοφόρος\n- Πρέπει να περιλαμβάνει: Ανατροπή στο τέλος" }}
/>

**Γιατί συμβαίνει**: Οι απαντήσεις AI είναι τόσο ανθρωπόμορφες που φυσικά γλιστράμε σε κοινωνικά μοτίβα. Αλλά οι συναισθηματικές εκκλήσεις δεν κάνουν το AI να προσπαθήσει περισσότερο—οι σαφείς οδηγίες το κάνουν.

<Callout type="info" title="Τι Πραγματικά Βοηθά">
Αντί για συναισθηματικές εκκλήσεις, εστίασε σε: σαφείς απαιτήσεις, καλά παραδείγματα, συγκεκριμένους περιορισμούς, και ρητά κριτήρια επιτυχίας. Αυτά βελτιώνουν τις εξόδους. Το "Παρακαλώ προσπάθησε πολύ σκληρά" όχι.
</Callout>

## Η Παγίδα της Παράλειψης Ασφάλειας

**Το Μοτίβο**: Στη βιασύνη να λειτουργήσουν τα πράγματα, συμπεριλαμβάνεις ευαίσθητες πληροφορίες σε prompts—API keys, κωδικούς, προσωπικά δεδομένα, ή ιδιοκτησιακές πληροφορίες.

<InfoGrid items={[
  { label: "Μυστικά σε Prompts", description: "API keys, κωδικοί, tokens επικολλημένα σε prompts", example: "\"Χρησιμοποίησε αυτό το API key: sk-abc123...\"", color: "red" },
  { label: "Προσωπικά Δεδομένα", description: "Συμπερίληψη PII που στέλνεται σε servers τρίτων", example: "Ονόματα πελατών, emails, διευθύνσεις σε prompts", exampleType: "text", color: "red" },
  { label: "Μη Εξυγιασμένη Είσοδος Χρήστη", description: "Πέρασμα εισόδου χρήστη απευθείας σε prompts", example: "Ευπάθειες prompt injection", exampleType: "text", color: "red" },
  { label: "Ιδιοκτησιακές Πληροφορίες", description: "Εμπορικά μυστικά ή εμπιστευτικά δεδομένα", example: "Εσωτερικές στρατηγικές, μη κυκλοφορημένες λεπτομέρειες προϊόντων", exampleType: "text", color: "red" }
]} />

**Γιατί συμβαίνει**: Εστίαση στη λειτουργικότητα πάνω από την ασφάλεια. Αλλά θυμήσου: τα prompts συχνά πηγαίνουν σε εξωτερικούς servers, μπορεί να καταγράφονται, και θα μπορούσαν να χρησιμοποιηθούν για εκπαίδευση.

<TryIt 
  title="Έλεγχος Ασφάλειας"
  description="Έλεγξε το prompt σου για ζητήματα ασφάλειας πριν το στείλεις."
  prompt={`Αναθεώρησε αυτό το prompt για ανησυχίες ασφάλειας:

"\${promptToReview}"

Έλεγξε για:

1. **Εκτεθειμένα Μυστικά**: API keys, κωδικοί, tokens, credentials
2. **Προσωπικά Δεδομένα**: Ονόματα, emails, διευθύνσεις, τηλέφωνα, ΑΜΚΑ
3. **Ιδιοκτησιακές Πληροφορίες**: Εμπορικά μυστικά, εσωτερικές στρατηγικές, εμπιστευτικά δεδομένα
4. **Κίνδυνοι Injection**: Είσοδος χρήστη που θα μπορούσε να χειραγωγήσει το prompt

Για κάθε ζήτημα που βρέθηκε:
- Εξήγησε τον κίνδυνο
- Πρότεινε πώς να αποκρύψεις ή να προστατεύσεις τις πληροφορίες
- Σύστησε ασφαλέστερες εναλλακτικές`}
/>

## Η Παγίδα της Άγνοιας Ψευδαισθήσεων

**Το Μοτίβο**: Ζητάς αναφορές, στατιστικά, ή συγκεκριμένα γεγονότα, και υποθέτεις ότι είναι αληθινά επειδή το AI τα δήλωσε με σιγουριά. Αλλά το AI τακτικά επινοεί πιθανοφανή πληροφορία.

<Compare 
  before={{ label: "Τυφλή εμπιστοσύνη", content: "Δώσε μου 5 στατιστικά για την παραγωγικότητα τηλεργασίας με πηγές." }}
  after={{ label: "Αναγνώριση περιορισμών", content: "Τι ξέρουμε για την παραγωγικότητα τηλεργασίας; Για οποιαδήποτε στατιστικά αναφέρεις, σημείωσε αν είναι καλά εδραιωμένα ευρήματα ή πιο αβέβαια. Θα επαληθεύσω συγκεκριμένους αριθμούς ανεξάρτητα." }}
/>

**Γιατί συμβαίνει**: Το AI παράγει κείμενο που ακούγεται αυθεντικό. Δεν "ξέρει" πότε επινοεί—προβλέπει πιθανό κείμενο, δεν ανακτά επαληθευμένα γεγονότα.

<TryIt 
  title="Ερώτημα Ανθεκτικό σε Ψευδαισθήσεις"
  description="Δόμησε το prompt σου για ελαχιστοποίηση κινδύνου ψευδαισθήσεων και σήμανση αβεβαιοτήτων."
  prompt={`Χρειάζομαι πληροφορίες για: \${topic}

Παρακαλώ ακολούθησε αυτές τις οδηγίες για ελαχιστοποίηση σφαλμάτων:

1. **Μείνε σε καλά εδραιωμένα γεγονότα**. Απόφυγε ασαφείς ισχυρισμούς που είναι δύσκολο να επαληθευτούν.

2. **Σήμανε αβεβαιότητα**. Αν δεν είσαι σίγουρος για κάτι, πες "Πιστεύω..." ή "Αυτό μπορεί να χρειάζεται επαλήθευση..."

3. **Καμία επινοημένη πηγή**. Μην αναφέρεις συγκεκριμένες εργασίες, βιβλία, ή URLs εκτός αν είσαι σίγουρος ότι υπάρχουν. Αντ' αυτού, περίγραψε πού να βρει κανείς αυτόν τον τύπο πληροφοριών.

4. **Αναγνώρισε όρια γνώσης**. Αν η ερώτησή μου αφορά γεγονότα μετά τα δεδομένα εκπαίδευσής σου, πες το.

5. **Διαχώρισε γεγονός από συμπέρασμα**. Διάκρινε ξεκάθαρα μεταξύ "Το X είναι αληθές" και "Βάσει του Y, το X είναι πιθανώς αληθές."

Τώρα, με αυτές τις οδηγίες στο νου: \${actualQuestion}`}
/>

## Λίστα Ελέγχου Πριν την Αποστολή

Πριν στείλεις οποιοδήποτε σημαντικό prompt, πέρνα από αυτή τη γρήγορη λίστα ελέγχου:

<Checklist 
  title="Έλεγχος Ποιότητας Prompt"
  items={[
    { text: "Είναι αρκετά συγκεκριμένο; (Όχι ασαφές)" },
    { text: "Είναι εστιασμένο; (Όχι υπερφορτωμένο με απαιτήσεις)" },
    { text: "Περιλαμβάνει όλο το απαραίτητο context;" },
    { text: "Είναι η ερώτηση ουδέτερη; (Όχι καθοδηγητική)" },
    { text: "Έχω καθορίσει τη μορφή εξόδου;" },
    { text: "Είναι η είσοδος εντός ορίων context;" },
    { text: "Υπάρχουν ανησυχίες ασφάλειας;" },
    { text: "Είμαι έτοιμος να επαληθεύσω την έξοδο;" },
    { text: "Είμαι έτοιμος να επαναλάβω αν χρειαστεί;" }
  ]}
/>

<Quiz 
  question="Ποια είναι η πιο επικίνδυνη παγίδα όταν χρησιμοποιείς AI για σημαντικές αποφάσεις;"
  options={[
    "Χρήση ασαφών prompts",
    "Εμπιστοσύνη εξόδων AI χωρίς επαλήθευση",
    "Μη καθορισμός μορφής εξόδου",
    "Υπερφόρτωση prompts με απαιτήσεις"
  ]}
  correctIndex={1}
  explanation="Ενώ όλες οι παγίδες προκαλούν προβλήματα, η εμπιστοσύνη εξόδων AI χωρίς επαλήθευση είναι η πιο επικίνδυνη γιατί μπορεί να οδηγήσει σε δημοσίευση ψευδών πληροφοριών, ανάπτυξη κώδικα με bugs, ή λήψη αποφάσεων βάσει ψευδαισθητικών δεδομένων. Το AI ακούγεται σίγουρο ακόμα κι όταν είναι εντελώς λάθος, κάνοντας την επαλήθευση απαραίτητη για κάθε σημαντική περίπτωση χρήσης."
/>

## Ανάλυσε τα Prompts σου

Χρησιμοποίησε AI για άμεση ανατροφοδότηση στην ποιότητα prompt σου. Επικόλλησε οποιοδήποτε prompt και λάβε λεπτομερή ανάλυση:

<PromptAnalyzer 
  title="Αναλυτής Ποιότητας Prompt"
  description="Λάβε AI-powered ανατροφοδότηση για σαφήνεια, συγκεκριμένοτητα, και προτάσεις βελτίωσης"
  defaultPrompt="Βοήθησέ με με τον κώδικά μου"
/>

## Εντόπισε το Πρόβλημα σε αυτό το Prompt

Μπορείς να εντοπίσεις τι είναι λάθος με αυτό το prompt;

<PromptDebugger
  title="Βρες την Παγίδα"
  badPrompt="Γράψε μια ανάρτηση blog για τεχνολογία που είναι SEO optimized με keywords και επίσης αστείο αλλά επαγγελματικό και περιλαμβάνει παραδείγματα κώδικα και στοχεύει αρχάριους αλλά έχει προχωρημένες συμβουλές και αναφέρει το προϊόν μας TechCo και έχει social proof και call to action και είναι 500 λέξεις αλλά ολοκληρωμένο."
  badOutput="Εδώ είναι ένα σχέδιο ανάρτησης blog για τεχνολογία...

[Γενικό, μη εστιασμένο περιεχόμενο που προσπαθεί να κάνει τα πάντα αλλά δεν επιτυγχάνει τίποτα καλά. Ο τόνος αλλάζει αδέξια μεταξύ casual και τεχνικού. Λείπουν οι μισές απαιτήσεις.]"
  options={[
    { id: "vague", label: "Το prompt είναι πολύ ασαφές", isCorrect: false, explanation: "Στην πραγματικότητα, το prompt έχει πολλές συγκεκριμένες απαιτήσεις. Το πρόβλημα είναι το αντίθετο—πάρα πολλές απαιτήσεις, όχι πολύ λίγες." },
    { id: "overload", label: "Το prompt είναι υπερφορτωμένο με πάρα πολλές ανταγωνιστικές απαιτήσεις", isCorrect: true, explanation: "Σωστά! Αυτό το prompt ζητά SEO + αστείο + επαγγελματικό + κώδικα + αρχάριους + προχωρημένο + αναφορά προϊόντος + social proof + CTA + περιορισμό μήκους. Αυτές είναι 10+ ανταγωνιστικές απαιτήσεις! Το AI δεν μπορεί να τις ικανοποιήσει όλες, οπότε κάνει μέτρια δουλειά σε όλα. Λύση: σπάσε αυτό σε πολλαπλά εστιασμένα prompts." },
    { id: "format", label: "Η μορφή εξόδου δεν καθορίζεται", isCorrect: false, explanation: "Ενώ μια πιο συγκεκριμένη μορφή θα βοηθούσε, το κύριο ζήτημα είναι η υπερφόρτωση απαιτήσεων. Δεν μπορείς να λύσεις το πρόβλημα με μορφοποίηση όταν ζητάς πάρα πολλά." },
    { id: "context", label: "Δεν υπάρχει αρκετό context", isCorrect: false, explanation: "Το prompt στην πραγματικότητα έχει πολύ context—ίσως πάρα πολύ! Το πρόβλημα είναι ότι προσπαθεί να ικανοποιήσει πάρα πολλούς στόχους ταυτόχρονα." }
  ]}
  hint="Μέτρησε πόσες διαφορετικές απαιτήσεις είναι συμπιεσμένες σε αυτό το μόνο prompt."
/>
