حتى مهندسو المطالبات ذوو الخبرة يقعون في فخاخ يمكن التنبؤ بها. الخبر الجيد؟ بمجرد أن تتعرف على هذه الأنماط، يسهل تجنبها. يستعرض هذا الفصل أكثر الأخطاء الشائعة، ويوضح سبب حدوثها، ويقدم لك استراتيجيات عملية لتفاديها.

<Callout type="warning" title="لماذا تهم هذه الأخطاء">
خطأ واحد يمكن أن يحول ذكاءً اصطناعياً قوياً إلى أداة محبطة. فهم هذه الأنماط غالباً ما يكون الفرق بين "الذكاء الاصطناعي لا يعمل معي" و"الذكاء الاصطناعي غيّر طريقة عملي".
</Callout>

## فخ الغموض

**النمط**: أنت تعرف ما تريد، لذلك تفترض أن الذكاء الاصطناعي سيفهمه أيضاً. لكن المطالبات الغامضة تنتج نتائج غامضة.

<Compare 
  before={{ label: "مطالبة غامضة", content: "اكتب شيئاً عن التسويق." }}
  after={{ label: "مطالبة محددة", content: "اكتب منشوراً على LinkedIn من 300 كلمة عن أهمية اتساق العلامة التجارية لشركات B2B SaaS، يستهدف مديري التسويق. استخدم نبرة احترافية لكن ودية. أضف مثالاً عملياً واحداً." }}
/>

**لماذا يحدث هذا**: نحن بطبيعتنا نتجاوز التفاصيل عندما نعتقد أنها "واضحة". لكن ما هو واضح لك ليس واضحاً لنموذج لا يملك سياقاً عن موقفك أو جمهورك أو أهدافك.

<TryIt 
  title="محسّن التحديد"
  description="خذ مطالبة غامضة واجعلها محددة. لاحظ كيف تحول إضافة التفاصيل جودة النتائج."
  prompt={`لدي مطالبة غامضة تحتاج إلى تحسين.

المطالبة الغامضة الأصلية: "\${vaguePrompt}"

اجعل هذه المطالبة محددة بإضافة:
1. **الجمهور**: من سيقرأ/يستخدم هذا؟
2. **التنسيق**: ما الهيكل المطلوب؟
3. **الطول**: كم يجب أن يكون طوله؟
4. **النبرة**: ما الصوت أو الأسلوب المطلوب؟
5. **السياق**: ما الموقف أو الغرض؟
6. **القيود**: ما الضروريات أو المحظورات؟

أعد كتابة المطالبة مع تضمين كل هذه التفاصيل.`}
/>

## فخ التحميل الزائد

**النمط**: تحاول الحصول على كل شيء في مطالبة واحدة—شاملة، مضحكة، احترافية، مناسبة للمبتدئين، متقدمة، محسّنة لمحركات البحث، وقصيرة. النتيجة؟ الذكاء الاصطناعي يفوّت نصف متطلباتك أو ينتج فوضى مربكة.

<Compare 
  before={{ label: "مطالبة محمّلة زائدة", content: "اكتب مقالة مدونة عن الذكاء الاصطناعي تكون محسّنة لمحركات البحث وتتضمن أمثلة برمجية ومضحكة لكن احترافية وتستهدف المبتدئين لكن فيها نصائح متقدمة ويجب أن تكون 500 كلمة لكن شاملة وتذكر منتجنا وفيها دعوة للعمل..." }}
  after={{ label: "مطالبة مركزة", content: "اكتب مقالة مدونة من 500 كلمة تقدم الذكاء الاصطناعي للمبتدئين.\n\nالمتطلبات:\n1. اشرح مفهوماً أساسياً واحداً بوضوح\n2. أضف مثالاً برمجياً بسيطاً واحداً\n3. اختم بدعوة للعمل\n\nالنبرة: احترافية لكن ودية" }}
/>

**لماذا يحدث هذا**: الخوف من التفاعلات المتعددة، أو الرغبة في "إخراج كل شيء" دفعة واحدة. لكن الحمل المعرفي الزائد يؤثر على الذكاء الاصطناعي تماماً كما يؤثر على البشر—كثرة المتطلبات المتنافسة تؤدي إلى إهمال بعضها.

<InfoGrid items={[
  { label: "حدد المتطلبات", description: "التزم بـ 3-5 متطلبات رئيسية لكل مطالبة", example: "ركز على: الجمهور، التنسيق، الطول، قيد رئيسي واحد", exampleType: "text", color: "green" },
  { label: "استخدم القوائم المرقمة", description: "الهيكلة توضح الأولويات", example: "1. يجب أن يحتوي X، 2. يفضل أن يحتوي Y، 3. من الجيد أن يحتوي Z", exampleType: "text", color: "green" },
  { label: "سلسل المطالبات", description: "قسّم المهام المعقدة إلى خطوات", example: "أولاً: المخطط. ثم: مسودة القسم 1. ثم: مسودة القسم 2.", exampleType: "text", color: "green" },
  { label: "رتب الأولويات بصرامة", description: "ما الضروري مقابل ما هو اختياري؟", example: "لو استطعت الحصول على شيء واحد فقط صحيح، ماذا سيكون؟", color: "green" }
]} />

<Callout type="tip" title="تعلم سلسلة المطالبات">
عندما تصبح المطالبة الواحدة محمّلة زائدة، [سلسلة المطالبات](/book/11-prompt-chaining) غالباً ما تكون الحل. قسّم المهام المعقدة إلى تسلسل من المطالبات المركزة، حيث تبني كل خطوة على الخطوة السابقة.
</Callout>

## فخ الافتراض

**النمط**: تشير إلى شيء "من قبل" أو تفترض أن الذكاء الاصطناعي يعرف مشروعك أو شركتك أو محادثاتك السابقة. هو لا يعرف.

<Compare 
  before={{ label: "يفترض السياق", content: "حدّث الدالة التي أريتك إياها سابقاً لإضافة معالجة الأخطاء." }}
  after={{ label: "يوفر السياق", content: "حدّث هذه الدالة لإضافة معالجة الأخطاء:\n\n```python\ndef calculate_total(items):\n    return sum(item.price for item in items)\n```\n\nأضف try/except للقوائم الفارغة والعناصر غير الصالحة." }}
/>

**لماذا يحدث هذا**: محادثات الذكاء الاصطناعي تبدو كالتحدث مع زميل. لكن على عكس الزملاء، معظم نماذج الذكاء الاصطناعي لا تملك ذاكرة دائمة بين الجلسات—كل محادثة تبدأ من جديد.

<TryIt 
  title="فحص اكتمال السياق"
  description="استخدم هذا للتحقق من أن مطالبتك تحتوي على كل السياق الضروري قبل إرسالها."
  prompt={`راجع هذه المطالبة بحثاً عن السياق المفقود:

"\${promptToCheck}"

تحقق من:
1. **مُشار إليه لكن غير مُضمّن**: هل تذكر "الكود" أو "المستند" أو "سابقاً" أو "أعلاه" دون تضمين المحتوى الفعلي؟

2. **معرفة مفترضة**: هل تفترض معرفة بمشروع أو شركة أو موقف معين؟

3. **متطلبات ضمنية**: هل هناك توقعات غير مذكورة حول التنسيق أو الطول أو الأسلوب؟

4. **خلفية مفقودة**: هل سيفهم شخص ذكي غريب ما المطلوب؟

اذكر ما هو مفقود واقترح كيفية إضافته.`}
/>

## فخ السؤال الموجّه

**النمط**: تصيغ سؤالك بطريقة تحتوي على افتراضك، فتحصل على تأكيد بدلاً من رؤية.

<Compare 
  before={{ label: "سؤال موجّه", content: "لماذا Python هي أفضل لغة برمجة لعلم البيانات؟" }}
  after={{ label: "سؤال محايد", content: "قارن بين Python وR وJulia لأعمال علم البيانات. ما نقاط القوة والضعف لكل منها؟ متى تختار واحدة على الأخريات؟" }}
/>

**لماذا يحدث هذا**: غالباً ما نسعى للتأكيد، لا للمعلومات. صياغتنا تدفع بشكل لاواعي نحو الإجابة التي نتوقعها أو نريدها.

<TryIt 
  title="كاشف التحيز"
  description="افحص مطالباتك بحثاً عن التحيزات الخفية واللغة الموجّهة."
  prompt={`حلل هذه المطالبة بحثاً عن التحيز واللغة الموجّهة:

"\${promptToAnalyze}"

تحقق من:
1. **افتراضات مضمّنة**: هل يفترض السؤال أن شيئاً ما صحيح؟
2. **صياغة موجّهة**: هل "لماذا X جيد؟" يفترض أن X جيد؟
3. **بدائل مفقودة**: هل يتجاهل احتمالات أخرى؟
4. **البحث عن تأكيد**: هل يطلب تصديقاً بدلاً من تحليل؟

أعد كتابة المطالبة لتكون محايدة ومفتوحة.`}
/>

## فخ الثقة العمياء

**النمط**: ردود الذكاء الاصطناعي تبدو واثقة وموثوقة، فتقبلها دون تحقق. لكن الثقة لا تعني الدقة.

<InfoGrid items={[
  { label: "محتوى غير مراجع", description: "نشر نص مولّد بالذكاء الاصطناعي دون التحقق من الحقائق", example: "مقالات مدونة بإحصائيات مختلقة أو اقتباسات وهمية", exampleType: "text", color: "red" },
  { label: "كود غير مختبر", description: "استخدام كود الذكاء الاصطناعي في الإنتاج دون اختبار", example: "ثغرات أمنية، فشل الحالات الحدية، أخطاء دقيقة", exampleType: "text", color: "red" },
  { label: "قرارات عمياء", description: "اتخاذ قرارات مهمة بناءً على تحليل الذكاء الاصطناعي فقط", example: "استراتيجية عمل مبنية على بيانات سوق مهلوسة", exampleType: "text", color: "red" }
]} />

**لماذا يحدث هذا**: الذكاء الاصطناعي يبدو واثقاً حتى عندما يكون خاطئاً تماماً. كما أننا عرضة لـ"تحيز الأتمتة"—الميل للثقة بمخرجات الحاسوب أكثر مما ينبغي.

<TryIt 
  title="مطالبة التحقق"
  description="استخدم هذا للحصول على الذكاء الاصطناعي ليحدد شكوكه وأخطائه المحتملة."
  prompt={`أحتاج معلومات عن: \${topic}

مهم: بعد ردك، أضف قسماً بعنوان "ملاحظات التحقق" يتضمن:

1. **مستوى الثقة**: ما مدى تأكدك من هذه المعلومات؟ (عالي/متوسط/منخفض)

2. **الأخطاء المحتملة**: ما أجزاء هذا الرد الأكثر احتمالاً أن تكون خاطئة أو قديمة؟

3. **ما يجب التحقق منه**: ما الادعاءات المحددة التي يجب على المستخدم التحقق منها بشكل مستقل؟

4. **مصادر للفحص**: أين يمكن للمستخدم التحقق من هذه المعلومات؟

كن صادقاً بشأن القيود. من الأفضل الإشارة إلى عدم اليقين بدلاً من أن تبدو واثقاً بشيء خاطئ.`}
/>

## فخ المحاولة الواحدة

**النمط**: ترسل مطالبة واحدة، تحصل على نتيجة متواضعة، وتستنتج أن الذكاء الاصطناعي "لا يعمل" لحالة استخدامك. لكن النتائج الممتازة تتطلب دائماً تكراراً.

<Compare 
  before={{ label: "تفكير المحاولة الواحدة", content: "نتيجة متواضعة ← \"الذكاء الاصطناعي لا يستطيع فعل هذا\" ← استسلام" }}
  after={{ label: "تفكير تكراري", content: "نتيجة متواضعة ← تحليل الخطأ ← تحسين المطالبة ← نتيجة أفضل ← تحسين مرة أخرى ← نتيجة ممتازة" }}
/>

**لماذا يحدث هذا**: نتوقع أن يقرأ الذكاء الاصطناعي أفكارنا من المحاولة الأولى. لا نتوقع التكرار مع بحث Google، لكننا نتوقع الكمال من الذكاء الاصطناعي.

<TryIt 
  title="مساعد التكرار"
  description="عندما لا تكون نتيجتك الأولى صحيحة، استخدم هذا لتحسينها بشكل منهجي."
  prompt={`مطالبتي الأصلية كانت:
"\${originalPrompt}"

الناتج الذي حصلت عليه:
"\${outputReceived}"

ما الخطأ فيه:
"\${whatIsWrong}"

ساعدني في التكرار:

1. **التشخيص**: لماذا أنتجت المطالبة الأصلية هذه النتيجة؟

2. **العناصر المفقودة**: ما الذي لم أكن صريحاً بشأنه وكان يجب أن أكون؟

3. **المطالبة المنقحة**: أعد كتابة مطالبتي لمعالجة هذه المشكلات.

4. **ما يجب مراقبته**: ما الذي يجب أن أتحقق منه في الناتج الجديد؟`}
/>

## فخ إهمال التنسيق

**النمط**: تركز على ما تريد أن يقوله الذكاء الاصطناعي، لكن تنسى تحديد كيف يجب أن يكون منسقاً. ثم تحصل على نص مستمر عندما تحتاج JSON، أو جدار من النص عندما تحتاج نقاطاً.

<Compare 
  before={{ label: "بدون تحديد تنسيق", content: "استخرج البيانات الرئيسية من هذا النص." }}
  after={{ label: "تنسيق محدد", content: "استخرج البيانات الرئيسية من هذا النص كـ JSON:\n\n{\n  \"name\": string,\n  \"date\": \"YYYY-MM-DD\",\n  \"amount\": number,\n  \"category\": string\n}\n\nأرجع JSON فقط، بدون شرح." }}
/>

**لماذا يحدث هذا**: نركز على المحتوى دون الهيكل. لكن إذا كنت تحتاج لتحليل الناتج برمجياً، أو لصقه في مكان معين، فالتنسيق مهم بقدر المحتوى.

<TryIt 
  title="منشئ مواصفات التنسيق"
  description="أنشئ مواصفات تنسيق واضحة لأي نوع ناتج تحتاجه."
  prompt={`أحتاج ناتج الذكاء الاصطناعي بتنسيق معين.

**ما أطلبه**: \${taskDescription}
**كيف سأستخدم الناتج**: \${intendedUse}
**التنسيق المفضل**: \${formatType} (JSON، Markdown، CSV، نقاط، إلخ.)

أنشئ مواصفات تنسيق يمكنني إضافتها لمطالبتي، تتضمن:

1. **الهيكل الدقيق** مع أسماء الحقول وأنواعها
2. **مثال للناتج** يوضح التنسيق
3. **القيود** (مثل: "أرجع JSON فقط، بدون شرح")
4. **الحالات الحدية** (ماذا يُخرج إذا كانت البيانات مفقودة)`}
/>

## فخ نافذة السياق

**النمط**: تلصق مستنداً ضخماً وتتوقع تحليلاً شاملاً. لكن النماذج لها حدود—قد تقتطع، أو تفقد التركيز، أو تفوّت تفاصيل مهمة في المدخلات الطويلة.

<InfoGrid items={[
  { label: "اعرف حدودك", description: "النماذج المختلفة لها نوافذ سياق مختلفة", example: "GPT-4: 128K tokens، Claude: 200K tokens، Gemini: 1M tokens", exampleType: "text", color: "blue" },
  { label: "قسّم المدخلات الكبيرة", description: "قسّم المستندات إلى أقسام قابلة للإدارة", example: "حلل الفصول بشكل منفصل، ثم اجمع النتائج", exampleType: "text", color: "blue" },
  { label: "ضع المهم أولاً", description: "ضع السياق الحرج في بداية المطالبة", example: "المتطلبات الرئيسية أولاً، تفاصيل الخلفية لاحقاً", exampleType: "text", color: "blue" },
  { label: "أزل الزوائد", description: "احذف السياق غير الضروري", example: "هل تحتاج فعلاً المستند بأكمله، أم فقط الأقسام ذات الصلة؟", exampleType: "text", color: "blue" }
]} />

<TryIt 
  title="استراتيجية تقسيم المستندات"
  description="احصل على استراتيجية لمعالجة المستندات التي تتجاوز حدود السياق."
  prompt={`لدي مستند كبير لتحليله:

**نوع المستند**: \${documentType}
**الطول التقريبي**: \${documentLength}
**ما أحتاج استخراجه/تحليله**: \${analysisGoal}
**النموذج الذي أستخدمه**: \${modelName}

أنشئ استراتيجية تقسيم:

1. **كيفية التقسيم**: نقاط الفصل المنطقية لهذا النوع من المستندات
2. **ما يُضمّن في كل قطعة**: السياق المطلوب للتحليل المستقل
3. **كيفية الدمج**: جمع النتائج من القطع المتعددة
4. **ما يجب مراقبته**: المعلومات التي قد تمتد عبر القطع`}
/>

## فخ الأنسنة

**النمط**: تتعامل مع الذكاء الاصطناعي كزميل بشري—تتوقع منه أن "يستمتع" بالمهام، أو يتذكرك، أو يهتم بالنتائج. هو لا يفعل.

<Compare 
  before={{ label: "مؤنسن", content: "أنا متأكد أنك ستستمتع بهذا المشروع الإبداعي! أعرف أنك تحب مساعدة الناس، وهذا مهم لي شخصياً." }}
  after={{ label: "واضح ومباشر", content: "اكتب قصة قصيرة إبداعية بهذه المواصفات:\n- النوع: خيال علمي\n- الطول: 500 كلمة\n- النبرة: متفائلة\n- يجب أن تتضمن: نهاية مفاجئة" }}
/>

**لماذا يحدث هذا**: ردود الذكاء الاصطناعي شبيهة بالبشر لدرجة أننا ننزلق بشكل طبيعي إلى أنماط اجتماعية. لكن المناشدات العاطفية لا تجعل الذكاء الاصطناعي يحاول بجدية أكبر—التعليمات الواضحة هي ما يفعل ذلك.

<Callout type="info" title="ما يساعد فعلاً">
بدلاً من المناشدات العاطفية، ركز على: متطلبات واضحة، أمثلة جيدة، قيود محددة، ومعايير نجاح صريحة. هذه تحسن النتائج. "من فضلك حاول جاهداً" لا تفعل ذلك.
</Callout>

## فخ إهمال الأمان

**النمط**: في الاندفاع لجعل الأمور تعمل، تضمّن معلومات حساسة في المطالبات—مفاتيح API، كلمات مرور، بيانات شخصية، أو معلومات ملكية.

<InfoGrid items={[
  { label: "أسرار في المطالبات", description: "مفاتيح API، كلمات مرور، رموز ملصوقة في المطالبات", example: "\"استخدم مفتاح API هذا: sk-abc123...\"", color: "red" },
  { label: "بيانات شخصية", description: "تضمين معلومات تعريف شخصية ترسل لخوادم طرف ثالث", example: "أسماء العملاء، بريدهم الإلكتروني، عناوينهم في المطالبات", exampleType: "text", color: "red" },
  { label: "مدخلات مستخدم غير معقمة", description: "تمرير مدخلات المستخدم مباشرة إلى المطالبات", example: "ثغرات حقن المطالبات", exampleType: "text", color: "red" },
  { label: "معلومات ملكية", description: "أسرار تجارية أو بيانات سرية", example: "استراتيجيات داخلية، تفاصيل منتجات غير معلنة", exampleType: "text", color: "red" }
]} />

**لماذا يحدث هذا**: التركيز على الوظائف على حساب الأمان. لكن تذكر: المطالبات غالباً تذهب لخوادم خارجية، قد تُسجّل، ويمكن استخدامها للتدريب.

<TryIt 
  title="مراجعة أمنية"
  description="افحص مطالبتك بحثاً عن مشاكل أمنية قبل إرسالها."
  prompt={`راجع هذه المطالبة بحثاً عن مخاوف أمنية:

"\${promptToReview}"

تحقق من:

1. **أسرار مكشوفة**: مفاتيح API، كلمات مرور، رموز، بيانات اعتماد
2. **بيانات شخصية**: أسماء، بريد إلكتروني، عناوين، أرقام هواتف، أرقام ضمان اجتماعي
3. **معلومات ملكية**: أسرار تجارية، استراتيجيات داخلية، بيانات سرية
4. **مخاطر الحقن**: مدخلات مستخدم قد تتلاعب بالمطالبة

لكل مشكلة تُوجد:
- اشرح المخاطر
- اقترح كيفية حذف أو حماية المعلومات
- أوصِ ببدائل أكثر أماناً`}
/>

## فخ تجاهل الهلوسة

**النمط**: تطلب اقتباسات أو إحصائيات أو حقائق محددة، وتفترض أنها حقيقية لأن الذكاء الاصطناعي ذكرها بثقة. لكن الذكاء الاصطناعي يختلق بانتظام معلومات تبدو معقولة.

<Compare 
  before={{ label: "ثقة عمياء", content: "أعطني 5 إحصائيات عن إنتاجية العمل عن بُعد مع المصادر." }}
  after={{ label: "الاعتراف بالقيود", content: "ماذا نعرف عن إنتاجية العمل عن بُعد؟ لأي إحصائيات تذكرها، وضّح ما إذا كانت نتائج راسخة أو أكثر عدم يقين. سأتحقق من أي أرقام محددة بشكل مستقل." }}
/>

**لماذا يحدث هذا**: الذكاء الاصطناعي يولّد نصاً يبدو موثوقاً. هو لا "يعرف" متى يختلق الأشياء—إنه يتنبأ بالنص المحتمل، لا يسترجع حقائق موثقة.

<TryIt 
  title="استعلام مقاوم للهلوسة"
  description="هيكل مطالبتك لتقليل خطر الهلوسة والإشارة إلى الشكوك."
  prompt={`أحتاج معلومات عن: \${topic}

من فضلك اتبع هذه الإرشادات لتقليل الأخطاء:

1. **التزم بالحقائق الراسخة**. تجنب الادعاءات الغامضة التي يصعب التحقق منها.

2. **أشر إلى عدم اليقين**. إذا لم تكن واثقاً من شيء، قل "أعتقد..." أو "قد يحتاج هذا للتحقق..."

3. **لا تختلق مصادر**. لا تستشهد بأوراق أو كتب أو روابط محددة إلا إذا كنت متأكداً من وجودها. بدلاً من ذلك، صف أين يمكن إيجاد هذا النوع من المعلومات.

4. **اعترف بحدود المعرفة**. إذا كان سؤالي عن أحداث بعد بيانات تدريبك، قل ذلك.

5. **افصل الحقيقة عن الاستنتاج**. ميّز بوضوح بين "X صحيح" و"بناءً على Y، من المحتمل أن X صحيح."

الآن، مع وضع هذه الإرشادات في الاعتبار: \${actualQuestion}`}
/>

## قائمة فحص ما قبل الإرسال

قبل إرسال أي مطالبة مهمة، راجع هذه القائمة السريعة:

<Checklist 
  title="فحص جودة المطالبة"
  items={[
    { text: "هل هي محددة بما فيه الكفاية؟ (ليست غامضة)" },
    { text: "هل هي مركزة؟ (ليست محمّلة بالمتطلبات)" },
    { text: "هل تتضمن كل السياق الضروري؟" },
    { text: "هل السؤال محايد؟ (ليس موجّهاً)" },
    { text: "هل حددت تنسيق الناتج؟" },
    { text: "هل المدخلات ضمن حدود السياق؟" },
    { text: "هل هناك مخاوف أمنية؟" },
    { text: "هل أنا مستعد للتحقق من الناتج؟" },
    { text: "هل أنا مستعد للتكرار إذا لزم الأمر؟" }
  ]}
/>

<Quiz 
  question="ما أخطر خطأ عند استخدام الذكاء الاصطناعي للقرارات المهمة؟"
  options={[
    "استخدام مطالبات غامضة",
    "الثقة بمخرجات الذكاء الاصطناعي دون تحقق",
    "عدم تحديد تنسيق الناتج",
    "تحميل المطالبات بمتطلبات كثيرة"
  ]}
  correctIndex={1}
  explanation="بينما كل الأخطاء تسبب مشاكل، الثقة بمخرجات الذكاء الاصطناعي دون تحقق هي الأخطر لأنها قد تؤدي إلى نشر معلومات خاطئة، أو نشر كود به أخطاء، أو اتخاذ قرارات بناءً على بيانات مهلوسة. الذكاء الاصطناعي يبدو واثقاً حتى عندما يكون خاطئاً تماماً، مما يجعل التحقق ضرورياً لأي استخدام مهم."
/>

## حلل مطالباتك

استخدم الذكاء الاصطناعي للحصول على تغذية راجعة فورية على جودة مطالبتك. الصق أي مطالبة واحصل على تحليل مفصل:

<PromptAnalyzer 
  title="محلل جودة المطالبات"
  description="احصل على تغذية راجعة مدعومة بالذكاء الاصطناعي حول الوضوح والتحديد واقتراحات للتحسين"
  defaultPrompt="ساعدني مع كودي"
/>

## صحح هذه المطالبة

هل تستطيع اكتشاف ما الخطأ في هذه المطالبة؟

<PromptDebugger
  title="اكتشف الخطأ"
  badPrompt="اكتب مقالة مدونة عن التكنولوجيا محسّنة لمحركات البحث مع كلمات مفتاحية ومضحكة أيضاً لكن احترافية وتتضمن أمثلة برمجية وتستهدف المبتدئين لكن فيها نصائح متقدمة وتذكر منتجنا TechCo وفيها دليل اجتماعي ودعوة للعمل و500 كلمة لكن شاملة."
  badOutput="إليك مسودة مقالة مدونة عن التكنولوجيا...

[محتوى عام غير مركز يحاول فعل كل شيء لكن لا ينجز شيئاً بشكل جيد. النبرة تتغير بشكل محرج بين الودي والتقني. نصف المتطلبات مفقودة.]"
  options={[
    { id: "vague", label: "المطالبة غامضة جداً", isCorrect: false, explanation: "في الواقع، المطالبة تحتوي على العديد من المتطلبات المحددة. المشكلة هي العكس—متطلبات كثيرة جداً، لا قليلة جداً." },
    { id: "overload", label: "المطالبة محمّلة بمتطلبات متنافسة كثيرة", isCorrect: true, explanation: "صحيح! هذه المطالبة تطلب SEO + مضحكة + احترافية + كود + مبتدئين + متقدمة + ذكر المنتج + دليل اجتماعي + CTA + قيد الطول. هذه أكثر من 10 متطلبات متنافسة! الذكاء الاصطناعي لا يستطيع تلبيتها كلها، فيقوم بعمل متواضع في كل شيء. الحل: قسّم هذا إلى مطالبات مركزة متعددة." },
    { id: "format", label: "تنسيق الناتج غير محدد", isCorrect: false, explanation: "بينما تنسيق أكثر تحديداً سيساعد، المشكلة الرئيسية هي التحميل الزائد بالمتطلبات. لا يمكنك حل مشكلة طلب الكثير بتحديد التنسيق." },
    { id: "context", label: "لا يوجد سياق كافٍ", isCorrect: false, explanation: "المطالبة في الواقع تحتوي على الكثير من السياق—ربما أكثر من اللازم! المشكلة هي أنها تحاول تحقيق أهداف كثيرة جداً في وقت واحد." }
  ]}
  hint="احسب كم متطلباً مختلفاً معبأ في هذه المطالبة الواحدة."
/>
