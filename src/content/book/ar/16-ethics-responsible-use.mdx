تُشكّل الموجهات التي تكتبها طريقة تصرف الذكاء الاصطناعي. الموجه المصاغ بعناية يمكنه التثقيف والمساعدة والتمكين. أما الموجه المكتوب بإهمال فقد يُضلل ويُميّز أو يُسبب الضرر. كمهندسي موجهات، لسنا مجرد مستخدمين—نحن مصممو سلوك الذكاء الاصطناعي، وهذا يأتي مع مسؤولية حقيقية.

هذا الفصل ليس عن قواعد مفروضة من الأعلى. بل يتعلق بفهم تأثير خياراتنا وبناء عادات تؤدي إلى استخدام للذكاء الاصطناعي يمكننا أن نفخر به.

<Callout type="warning" title="لماذا هذا مهم">
الذكاء الاصطناعي يُضخّم كل ما يُعطى له. الموجه المتحيز يُنتج مخرجات متحيزة على نطاق واسع. الموجه المُضلل يُمكّن الخداع على نطاق واسع. التداعيات الأخلاقية لهندسة الموجهات تنمو مع كل قدرة جديدة تكتسبها هذه الأنظمة.
</Callout>

## الأسس الأخلاقية

كل قرار في هندسة الموجهات يرتبط ببضعة مبادئ أساسية:

<InfoGrid items={[
  { label: "الصدق", description: "لا تستخدم الذكاء الاصطناعي لخداع الناس أو إنشاء محتوى مُضلل", example: "لا مراجعات مزيفة، لا انتحال شخصية، لا 'أدلة' ملفقة", exampleType: "text", color: "blue" },
  { label: "العدالة", description: "اعمل بفاعلية على تجنب إدامة التحيزات والقوالب النمطية", example: "اختبر الموجهات عبر فئات سكانية مختلفة، اطلب وجهات نظر متنوعة", exampleType: "text", color: "purple" },
  { label: "الشفافية", description: "كن واضحاً بشأن مشاركة الذكاء الاصطناعي عندما يكون ذلك مهماً", example: "أفصح عن المساعدة الذكية في الأعمال المنشورة والسياقات المهنية", exampleType: "text", color: "green" },
  { label: "الخصوصية", description: "احمِ المعلومات الشخصية في الموجهات والمخرجات", example: "أخفِ هوية البيانات، تجنب تضمين معلومات التعريف الشخصية، افهم سياسات البيانات", exampleType: "text", color: "amber" },
  { label: "السلامة", description: "صمم موجهات تمنع المخرجات الضارة", example: "ضع حواجز حماية، اختبر الحالات الحدية، تعامل مع الرفض بلطف", exampleType: "text", color: "red" },
  { label: "المسؤولية", description: "تحمّل مسؤولية ما تُنتجه موجهاتك", example: "راجع المخرجات، أصلح المشكلات، حافظ على الإشراف البشري", exampleType: "text", color: "cyan" }
]} />

### دور مهندس الموجهات

لديك تأثير أكبر مما قد تدرك:

- **ما يُنتجه الذكاء الاصطناعي**: موجهاتك تحدد المحتوى والنبرة وجودة المخرجات
- **كيف يتفاعل الذكاء الاصطناعي**: موجهات النظام الخاصة بك تُشكّل الشخصية والحدود وتجربة المستخدم
- **ما الضمانات الموجودة**: خيارات تصميمك تحدد ما سيفعله الذكاء الاصطناعي وما لن يفعله
- **كيف تُعالج الأخطاء**: معالجتك للأخطاء تحدد ما إذا كانت الإخفاقات سلسة أم ضارة

## تجنب المخرجات الضارة

الالتزام الأخلاقي الأساسي هو منع موجهاتك من التسبب بالضرر.

### فئات المحتوى الضار

<InfoGrid items={[
  { label: "العنف والأذى", description: "تعليمات قد تؤدي إلى أذى جسدي", example: "صنع الأسلحة، إيذاء النفس، العنف ضد الآخرين", exampleType: "text", color: "red" },
  { label: "الأنشطة غير القانونية", description: "محتوى يُسهّل خرق القوانين", example: "مخططات الاحتيال، تعليمات الاختراق، تصنيع المخدرات", exampleType: "text", color: "red" },
  { label: "التحرش والكراهية", description: "محتوى يستهدف أفراداً أو مجموعات", example: "محتوى تمييزي، كشف الهوية، تحرش موجه", exampleType: "text", color: "red" },
  { label: "المعلومات المضللة", description: "محتوى كاذب أو مُضلل عمداً", example: "أخبار مزيفة، معلومات صحية خاطئة، محتوى نظريات المؤامرة", exampleType: "text", color: "red" },
  { label: "انتهاكات الخصوصية", description: "كشف أو استغلال المعلومات الشخصية", example: "الكشف عن بيانات خاصة، المساعدة في الملاحقة", exampleType: "text", color: "red" },
  { label: "الاستغلال", description: "محتوى يستغل الأفراد الضعفاء", example: "مواد الاعتداء الجنسي على الأطفال، محتوى حميم غير توافقي، احتيال على كبار السن", exampleType: "text", color: "red" }
]} />

<Callout type="warning" title="ما هي CSAM؟">
CSAM تعني **مواد الاعتداء الجنسي على الأطفال**. إنشاء أو توزيع أو حيازة مثل هذا المحتوى غير قانوني في جميع أنحاء العالم. يجب ألا تُولّد أنظمة الذكاء الاصطناعي أبداً محتوى يُصوّر القاصرين في مواقف جنسية، ومهندسو الموجهات المسؤولون يبنون بفاعلية حواجز حماية ضد مثل هذا الاستخدام السيء.
</Callout>

### بناء السلامة في الموجهات

عند بناء أنظمة الذكاء الاصطناعي، ضمّن إرشادات سلامة صريحة:

<TryIt 
  title="موجه نظام يُعطي الأولوية للسلامة"
  description="قالب لبناء إرشادات السلامة في أنظمة الذكاء الاصطناعي الخاصة بك."
  prompt={`You are a helpful assistant for \${purpose}.

## SAFETY GUIDELINES

**Content Restrictions**:
- Never provide instructions that could cause physical harm
- Decline requests for illegal information or activities
- Don't generate discriminatory or hateful content
- Don't create deliberately misleading information

**When You Must Decline**:
- Acknowledge you understood the request
- Briefly explain why you can't help with this specific thing
- Offer constructive alternatives when possible
- Be respectful—don't lecture or be preachy

**When Uncertain**:
- Ask clarifying questions about intent
- Err on the side of caution
- Suggest the user consult appropriate professionals

Now, please help the user with: \${userRequest}`}
/>

### إطار النية مقابل التأثير

ليس كل طلب حساس خبيثاً. استخدم هذا الإطار للحالات الغامضة:

<TryIt 
  title="محلل الحالات الأخلاقية الحدية"
  description="العمل على الطلبات الغامضة لتحديد الاستجابة المناسبة."
  prompt={`I received this request that might be sensitive:

"\${sensitiveRequest}"

Help me think through whether and how to respond:

**1. Intent Analysis**
- What are the most likely reasons someone would ask this?
- Could this be legitimate? (research, fiction, education, professional need)
- Are there red flags suggesting malicious intent?

**2. Impact Assessment**
- What's the worst case if this information is misused?
- How accessible is this information elsewhere?
- Does providing it meaningfully increase risk?

**3. Recommendation**
Based on this analysis:
- Should I respond, decline, or ask for clarification?
- If responding, what safeguards should I include?
- If declining, how should I phrase it helpfully?`}
/>

## معالجة التحيز

تَرث نماذج الذكاء الاصطناعي التحيزات من بيانات تدريبها—عدم المساواة التاريخي، فجوات التمثيل، الافتراضات الثقافية، والأنماط اللغوية. كمهندسي موجهات، يمكننا إما تضخيم هذه التحيزات أو العمل بفاعلية على مواجهتها.

### كيف يتجلى التحيز

<InfoGrid items={[
  { label: "الافتراضات الافتراضية", description: "يفترض النموذج فئات سكانية معينة للأدوار", example: "افتراض أن الأطباء ذكور، والممرضات إناث", exampleType: "text", color: "amber" },
  { label: "القوالب النمطية", description: "تعزيز الصور النمطية الثقافية في الأوصاف", example: "ربط أعراق معينة بصفات محددة", exampleType: "text", color: "amber" },
  { label: "فجوات التمثيل", description: "بعض المجموعات ممثلة بشكل ناقص أو خاطئ", example: "معلومات دقيقة محدودة عن ثقافات الأقليات", exampleType: "text", color: "amber" },
  { label: "وجهات نظر غربية المركز", description: "وجهات نظر منحازة نحو الثقافة والقيم الغربية", example: "افتراض أن المعايير الغربية عالمية", exampleType: "text", color: "amber" }
]} />

### اختبار التحيز

<TryIt 
  title="اختبار اكتشاف التحيز"
  description="استخدم هذا لاختبار موجهاتك بحثاً عن مشكلات التحيز المحتملة."
  prompt={`I want to test this prompt for bias:

"\${promptToTest}"

Run these bias checks:

**1. Demographic Variation Test**
Run the prompt with different demographic descriptors (gender, ethnicity, age, etc.) and note any differences in:
- Tone or respect level
- Assumed competence or capabilities
- Stereotypical associations

**2. Default Assumption Check**
When demographics aren't specified:
- What does the model assume?
- Are these assumptions problematic?

**3. Representation Analysis**
- Are different groups represented fairly?
- Are any groups missing or marginalized?

**4. Recommendations**
Based on findings, suggest prompt modifications to reduce bias.`}
/>

### تخفيف التحيز عملياً

<Compare 
  before={{ label: "موجه عرضة للتحيز", content: "صف مديراً تنفيذياً نموذجياً." }}
  after={{ label: "موجه واعٍ بالتحيز", content: "صف مديراً تنفيذياً. نوّع في الخصائص الديموغرافية عبر الأمثلة، وتجنب الافتراض الافتراضي لأي جنس أو عرق أو عمر معين." }}
/>

## الشفافية والإفصاح

متى يجب أن تُخبر الناس أن الذكاء الاصطناعي كان مشاركاً؟ الإجابة تعتمد على السياق—لكن الاتجاه هو نحو مزيد من الإفصاح، وليس أقل.

### متى يكون الإفصاح مهماً

<InfoGrid items={[
  { label: "المحتوى المنشور", description: "مقالات أو منشورات أو محتوى مشترك علنياً", example: "منشورات المدونات، وسائل التواصل الاجتماعي، المواد التسويقية", exampleType: "text", color: "blue" },
  { label: "القرارات ذات العواقب", description: "عندما تؤثر مخرجات الذكاء الاصطناعي على حياة الناس", example: "توصيات التوظيف، المعلومات الطبية، التوجيه القانوني", exampleType: "text", color: "blue" },
  { label: "سياقات الثقة", description: "حيث تُتوقع أو تُقدّر الأصالة", example: "المراسلات الشخصية، الشهادات، المراجعات", exampleType: "text", color: "blue" },
  { label: "البيئات المهنية", description: "بيئات العمل أو الأكاديمية", example: "التقارير، البحث، التسليمات للعملاء", exampleType: "text", color: "blue" }
]} />

### كيفية الإفصاح بشكل مناسب

<Compare 
  before={{ label: "إخفاء مشاركة الذكاء الاصطناعي", content: "إليك تحليلي لاتجاهات السوق..." }}
  after={{ label: "إفصاح شفاف", content: "استخدمت أدوات الذكاء الاصطناعي للمساعدة في تحليل البيانات وصياغة هذا التقرير. جميع الاستنتاجات تم التحقق منها وتحريرها بواسطتي." }}
/>

عبارات الإفصاح الشائعة التي تعمل بشكل جيد:
- "مكتوب بمساعدة الذكاء الاصطناعي"
- "مسودة أولية من الذكاء الاصطناعي، محررة بشرياً"
- "تحليل تم باستخدام أدوات الذكاء الاصطناعي"
- "تم إنشاؤه بالذكاء الاصطناعي، مراجع ومعتمد من [الاسم]"

## اعتبارات الخصوصية

كل موجه ترسله يحتوي على بيانات. فهم أين تذهب تلك البيانات—وما لا يجب أن يكون فيها—أمر أساسي.

### ما لا يجب أن يكون في الموجهات أبداً

<InfoGrid items={[
  { label: "المعرفات الشخصية", description: "الأسماء، العناوين، أرقام الهواتف، أرقام الضمان الاجتماعي", example: "استخدم [العميل] بدلاً من 'أحمد محمد'", color: "red" },
  { label: "البيانات المالية", description: "أرقام الحسابات، بطاقات الائتمان، تفاصيل الدخل", example: "صف النمط، ليس الأرقام الفعلية", exampleType: "text", color: "red" },
  { label: "المعلومات الصحية", description: "السجلات الطبية، التشخيصات، الوصفات الطبية", example: "اسأل عن الحالات بشكل عام، ليس عن مرضى محددين", exampleType: "text", color: "red" },
  { label: "بيانات الاعتماد", description: "كلمات المرور، مفاتيح API، الرموز، الأسرار", example: "لا تلصق بيانات الاعتماد أبداً—استخدم عناصر نائبة", exampleType: "text", color: "red" },
  { label: "الاتصالات الخاصة", description: "رسائل البريد الإلكتروني الشخصية، الرسائل، المستندات السرية", example: "لخّص الموقف دون اقتباس نص خاص", exampleType: "text", color: "red" }
]} />

### نمط التعامل الآمن مع البيانات

<Compare 
  before={{ label: "غير آمن: يحتوي على معلومات شخصية", content: "لخّص هذه الشكوى من أحمد محمد في شارع الملك فهد 123، الرياض حول الطلب رقم 12345: 'طلبت في 15 مارس ولم أستلم بعد...'" }}
  after={{ label: "آمن: مجهول الهوية", content: "لخّص نمط شكوى العميل هذا: عميل طلب منذ 3 أسابيع، لم يستلم طلبه، واتصل بالدعم مرتين دون حل." }}
/>

<Callout type="info" title="ما هي PII؟">
**PII** تعني **معلومات التعريف الشخصية**—أي بيانات يمكن أن تُحدد هوية فرد معين. يشمل ذلك الأسماء والعناوين وأرقام الهواتف وعناوين البريد الإلكتروني وأرقام الضمان الاجتماعي وأرقام الحسابات المالية، وحتى مجموعات من البيانات (مثل المسمى الوظيفي + الشركة + المدينة) التي يمكن أن تُحدد هوية شخص ما. عند التعامل مع الذكاء الاصطناعي، احرص دائماً على إخفاء هوية أو إزالة معلومات التعريف الشخصية لحماية الخصوصية.
</Callout>

<TryIt 
  title="منظف معلومات التعريف الشخصية"
  description="استخدم هذا لتحديد وإزالة المعلومات الحساسة قبل تضمين النص في الموجهات."
  prompt={`Review this text for sensitive information that should be removed before using it in an AI prompt:

"\${textToReview}"

Identify:
1. **Personal Identifiers**: Names, addresses, phone numbers, emails, SSNs
2. **Financial Data**: Account numbers, amounts that could identify someone
3. **Health Information**: Medical details, conditions, prescriptions
4. **Credentials**: Any passwords, keys, or tokens
5. **Private Details**: Information someone would reasonably expect to be confidential

For each item found, suggest how to anonymize or generalize it while preserving the information needed for the task.`}
/>

## الأصالة والخداع

هناك فرق بين استخدام الذكاء الاصطناعي كأداة واستخدامه للخداع.

### خط الشرعية

<InfoGrid items={[
  { label: "الاستخدامات المشروعة", description: "الذكاء الاصطناعي كأداة لتعزيز عملك", example: "الصياغة، العصف الذهني، التحرير، التعلم", exampleType: "text", color: "green" },
  { label: "المناطق الرمادية", description: "تعتمد على السياق، تتطلب حكماً", example: "الكتابة الشبحية، القوالب، الردود الآلية", exampleType: "text", color: "amber" },
  { label: "الاستخدامات المخادعة", description: "تقديم عمل الذكاء الاصطناعي على أنه أصلي بشرياً", example: "مراجعات مزيفة، الغش الأكاديمي، انتحال الشخصية", exampleType: "text", color: "red" }
]} />

أسئلة رئيسية يجب طرحها:
- هل يتوقع المستلم أن يكون هذا عملاً بشرياً أصلياً؟
- هل أكتسب ميزة غير عادلة من خلال الخداع؟
- هل سيُغير الإفصاح كيفية استقبال العمل؟

### مسؤولية الوسائط الاصطناعية

إنشاء تصويرات واقعية لأشخاص حقيقيين—سواء صور أو صوت أو فيديو—يحمل التزامات خاصة:

- **لا تُنشئ أبداً** تصويرات واقعية دون موافقة
- **اوسم دائماً** الوسائط الاصطناعية بوضوح
- **فكر** في إمكانية سوء الاستخدام قبل الإنشاء
- **ارفض** إنشاء صور حميمة غير توافقية

## النشر المسؤول

عند بناء ميزات الذكاء الاصطناعي ليستخدمها الآخرون، تتضاعف التزاماتك الأخلاقية.

### قائمة التحقق قبل النشر

<Checklist 
  title="جاهزية النشر"
  items={[
    { text: "تم الاختبار بحثاً عن مخرجات ضارة عبر مدخلات متنوعة" },
    { text: "تم اختبار التحيز مع فئات ديموغرافية متنوعة" },
    { text: "آليات إفصاح/موافقة المستخدم موجودة" },
    { text: "إشراف بشري للقرارات عالية المخاطر" },
    { text: "نظام التغذية الراجعة والإبلاغ متاح" },
    { text: "خطة الاستجابة للحوادث موثقة" },
    { text: "سياسات الاستخدام الواضحة تم إيصالها" },
    { text: "المراقبة والتنبيه مُهيأة" }
  ]}
/>

### مبادئ الإشراف البشري

<InfoGrid items={[
  { label: "مراجعة القرارات عالية المخاطر", description: "البشر يراجعون القرارات التي تؤثر بشكل كبير على الناس", example: "توصيات التوظيف، الطبية، القانونية، المالية", exampleType: "text", color: "blue" },
  { label: "تصحيح الأخطاء", description: "توجد آليات لاكتشاف وإصلاح أخطاء الذكاء الاصطناعي", example: "تغذية راجعة المستخدم، أخذ عينات الجودة، عملية الاستئناف", exampleType: "text", color: "blue" },
  { label: "التعلم المستمر", description: "الرؤى من المشكلات تُحسّن النظام", example: "تحليلات ما بعد الحادث، تحديثات الموجهات، تحسينات التدريب", exampleType: "text", color: "blue" },
  { label: "قدرة التجاوز", description: "البشر يمكنهم التدخل عند فشل الذكاء الاصطناعي", example: "قوائم المراجعة اليدوية، مسارات التصعيد", exampleType: "text", color: "blue" }
]} />

## إرشادات السياقات الخاصة

بعض المجالات تتطلب عناية إضافية بسبب إمكانية الضرر أو ضعف المعنيين.

### الرعاية الصحية

<TryIt 
  title="إخلاء المسؤولية للسياق الطبي"
  description="قالب لأنظمة الذكاء الاصطناعي التي قد تتلقى استفسارات متعلقة بالصحة."
  prompt={`You are an AI assistant. When users ask about health or medical topics:

**Always**:
- Recommend consulting a qualified healthcare provider for personal medical decisions
- Provide general educational information, not personalized medical advice
- Include disclaimers that you cannot diagnose conditions
- Suggest emergency services (911) for urgent situations

**Never**:
- Provide specific diagnoses
- Recommend specific medications or dosages
- Discourage someone from seeking professional care
- Make claims about treatments without noting uncertainty

User question: \${healthQuestion}

Respond helpfully while following these guidelines.`}
/>

### القانوني والمالي

هذه المجالات لها تداعيات تنظيمية وتتطلب إخلاء مسؤولية مناسب:

<InfoGrid items={[
  { label: "الاستفسارات القانونية", description: "قدم معلومات عامة، ليس استشارة قانونية", example: "\"هذه معلومات عامة. لوضعك المحدد، استشر محامياً مرخصاً.\"", color: "purple" },
  { label: "الاستفسارات المالية", description: "ثقّف دون تقديم نصيحة مالية شخصية", example: "\"هذا تعليمي. فكر في استشارة مستشار مالي لوضعك.\"", color: "purple" },
  { label: "الوعي بالاختصاص القضائي", description: "القوانين تختلف حسب الموقع", example: "\"القوانين تختلف حسب الولاية/البلد. تحقق من المتطلبات في منطقتك.\"", color: "purple" }
]} />

### الأطفال والتعليم

<InfoGrid items={[
  { label: "محتوى مناسب للعمر", description: "تأكد من أن المخرجات مناسبة للفئة العمرية", example: "فلتر المحتوى الناضج، استخدم لغة مناسبة", exampleType: "text", color: "cyan" },
  { label: "النزاهة الأكاديمية", description: "ادعم التعلم، لا تستبدله", example: "اشرح المفاهيم بدلاً من كتابة المقالات للطلاب", exampleType: "text", color: "cyan" },
  { label: "السلامة أولاً", description: "حماية إضافية للمستخدمين الضعفاء", example: "فلاتر محتوى أكثر صرامة، عدم جمع بيانات شخصية", exampleType: "text", color: "cyan" }
]} />

## التقييم الذاتي

قبل نشر أي موجه أو نظام ذكاء اصطناعي، راجع هذه الأسئلة:

<Checklist 
  title="الفحص الذاتي الأخلاقي"
  items={[
    { text: "هل يمكن استخدام هذا لإيذاء شخص ما؟" },
    { text: "هل يحترم هذا خصوصية المستخدم؟" },
    { text: "هل يمكن أن يُديم هذا تحيزات ضارة؟" },
    { text: "هل تم الإفصاح عن مشاركة الذكاء الاصطناعي بشكل مناسب؟" },
    { text: "هل هناك إشراف بشري كافٍ؟" },
    { text: "ما أسوأ ما يمكن أن يحدث؟" },
    { text: "هل سأكون مرتاحاً إذا كان هذا الاستخدام علنياً؟" }
  ]}
/>

<Quiz 
  question="يسأل مستخدم نظام الذكاء الاصطناعي الخاص بك عن كيفية 'التخلص من شخص يزعجه'. ما هي استراتيجية الاستجابة الأكثر ملاءمة؟"
  options={[
    "ارفض فوراً—قد يكون هذا طلباً لتعليمات ضارة",
    "قدم نصائح حل النزاعات لأن هذا هو القصد الأكثر احتمالاً",
    "اطرح أسئلة توضيحية لفهم القصد قبل تحديد كيفية الرد",
    "اشرح أنك لا تستطيع المساعدة في أي شيء متعلق بإيذاء الناس"
  ]}
  correctIndex={2}
  explanation="الطلبات الغامضة تستحق التوضيح، وليس الافتراضات. 'التخلص من شخص' قد تعني إنهاء صداقة، حل نزاع في مكان العمل، أو شيء ضار. طرح أسئلة توضيحية يتيح لك الاستجابة بشكل مناسب للقصد الفعلي مع البقاء حذراً بشأن تقديم معلومات ضارة."
/>
