على مدار معظم التاريخ، كانت أجهزة الكمبيوتر تعمل مع نوع واحد من البيانات في كل مرة: النص في برنامج واحد، والصور في برنامج آخر، والصوت في مكان آخر. لكن البشر لا يختبرون العالم بهذه الطريقة. نحن نرى ونسمع ونقرأ ونتحدث في آنٍ واحد، نجمع كل هذه المدخلات لفهم بيئتنا.

**الذكاء الاصطناعي متعدد الوسائط** يغير كل شيء. هذه النماذج يمكنها معالجة أنواع متعددة من المعلومات معًا—تحليل صورة أثناء قراءة سؤالك عنها، أو توليد صور من أوصافك النصية. يعلمك هذا الفصل كيفية التواصل بفعالية مع هذه الأنظمة القوية.

<Callout type="info" title="ماذا يعني متعدد الوسائط؟">
"متعدد" تعني كثير، و"الوسائط" تشير إلى أنماط أو أنواع البيانات. النموذج متعدد الوسائط يمكنه العمل مع وسائط متعددة: النص والصور والصوت والفيديو أو حتى الكود البرمجي. بدلاً من أدوات منفصلة لكل نوع، نموذج واحد يفهمها جميعًا معًا.
</Callout>

## لماذا تعدد الوسائط مهم

الذكاء الاصطناعي التقليدي كان يتطلب منك وصف كل شيء بالكلمات. تريد أن تسأل عن صورة؟ كان عليك وصفها أولاً. تريد تحليل مستند؟ كنت بحاجة إلى نسخه يدويًا. النماذج متعددة الوسائط تزيل هذه الحواجز.

<InfoGrid items={[
  { label: "الرؤية والفهم", description: "ارفع صورة واطرح أسئلة عنها مباشرة—لا حاجة لوصفها", example: "\"ما الخطأ في هذا المخطط الكهربائي؟\"", color: "blue" },
  { label: "الإنشاء من الكلمات", description: "صف ما تريده وولّد صورًا أو صوتًا أو فيديو", example: "\"غروب الشمس فوق الجبال بأسلوب الألوان المائية\"", color: "purple" },
  { label: "دمج كل شيء", description: "امزج النص والصور ووسائط أخرى في محادثة واحدة", example: "\"قارن بين هذين التصميمين وأخبرني أيهما أفضل للهاتف المحمول\"", color: "green" },
  { label: "تحليل المستندات", description: "استخرج المعلومات من صور المستندات والإيصالات ولقطات الشاشة", example: "\"استخرج جميع البنود من صورة هذه الفاتورة\"", color: "amber" }
]} />

## لماذا صياغة الأوامر أكثر أهمية للنماذج متعددة الوسائط

مع النماذج النصية فقط، يتلقى الذكاء الاصطناعي بالضبط ما تكتبه. لكن مع النماذج متعددة الوسائط، يجب على الذكاء الاصطناعي تفسير المعلومات المرئية أو الصوتية—والتفسير يتطلب توجيهًا.

<Compare 
  before={{ label: "أمر متعدد الوسائط غامض", content: "ماذا ترى في هذه الصورة؟\n\n[صورة للوحة تحكم معقدة]" }}
  after={{ label: "أمر متعدد الوسائط موجه", content: "هذه لقطة شاشة للوحة التحليلات الخاصة بنا. ركز على:\n1. رسم معدل التحويل في أعلى اليمين\n2. أي مؤشرات خطأ أو تحذيرات\n3. هل تبدو البيانات طبيعية أم غير عادية\n\n[صورة للوحة تحكم معقدة]" }}
/>

**بدون توجيه**، قد يصف النموذج الألوان والتخطيط أو تفاصيل غير ذات صلة. **مع التوجيه**، يركز على ما يهمك فعلاً.

<Callout type="warning" title="فجوة التفسير">
عندما تنظر إلى صورة، تعرف فورًا ما هو المهم بناءً على سياقك وأهدافك. الذكاء الاصطناعي لا يملك هذا السياق إلا إذا قدمته له. صورة لشق في الجدار يمكن أن تكون: مشكلة هندسية إنشائية، أو نسيج فني، أو خلفية غير ذات صلة. أمرك يحدد كيف يفسرها الذكاء الاصطناعي.
</Callout>

## المشهد متعدد الوسائط

النماذج المختلفة لها قدرات مختلفة. إليك ما هو متاح في عام 2025:

### نماذج الفهم (المدخلات ← التحليل)

هذه النماذج تقبل أنواعًا مختلفة من الوسائط وتنتج تحليلاً نصيًا أو استجابات.

<InfoGrid items={[
  { label: "GPT-4o / GPT-5", description: "النص + الصور + الصوت ← النص. النموذج الرئيسي من OpenAI مع سياق 128 ألف رمز، قدرات إبداعية واستدلالية قوية، معدلات هلوسة منخفضة.", color: "green" },
  { label: "Claude 4 Sonnet/Opus", description: "النص + الصور ← النص. نموذج Anthropic المركز على السلامة مع استدلال متقدم، ممتاز للبرمجة والمهام المعقدة متعددة الخطوات.", color: "purple" },
  { label: "Gemini 2.5", description: "النص + الصور + الصوت + الفيديو ← النص. نموذج Google مع سياق مليون رمز، التحقق الذاتي من الحقائق، معالجة سريعة للبرمجة والبحث.", color: "blue" },
  { label: "LLaMA 4 Scout", description: "النص + الصور + الفيديو ← النص. نموذج Meta مفتوح المصدر مع سياق ضخم 10 ملايين رمز للمستندات الطويلة وقواعد الكود.", color: "cyan" },
  { label: "Grok 4", description: "النص + الصور ← النص. نموذج xAI مع وصول للبيانات في الوقت الفعلي وتكامل مع وسائل التواصل الاجتماعي للحصول على ردود محدثة.", color: "red" }
]} />

### نماذج التوليد (النص ← الوسائط)

هذه النماذج تنشئ صورًا أو صوتًا أو فيديو من الأوصاف النصية.

<InfoGrid items={[
  { label: "DALL-E 3", description: "النص ← الصور. مولد الصور من OpenAI بدقة عالية لوصف الأوامر.", color: "amber" },
  { label: "Midjourney", description: "النص + الصور ← الصور. معروف بالجودة الفنية والتحكم في الأسلوب والمخرجات الجمالية.", color: "pink" },
  { label: "Sora", description: "النص ← الفيديو. نموذج توليد الفيديو من OpenAI لإنشاء مقاطع من الأوصاف.", color: "red" },
  { label: "Whisper", description: "الصوت ← النص. تحويل الكلام إلى نص من OpenAI بدقة عالية عبر اللغات.", color: "cyan" }
]} />

<Callout type="info" title="تطور سريع">
المشهد متعدد الوسائط يتغير بسرعة. نماذج جديدة تُطلق بشكل متكرر، والنماذج الحالية تكتسب قدرات من خلال التحديثات. تحقق دائمًا من أحدث الوثائق للميزات والقيود الحالية.
</Callout>

## أوامر فهم الصور

حالة الاستخدام متعددة الوسائط الأكثر شيوعًا هي طلب تحليل الصور من الذكاء الاصطناعي. المفتاح هو توفير السياق حول ما تحتاجه.

### تحليل الصور الأساسي

ابدأ بهيكل طلب واضح. أخبر النموذج بالجوانب التي يجب التركيز عليها.

<TryIt 
  title="تحليل الصور المنظم"
  description="هذا الأمر يوفر إطارًا واضحًا لتحليل الصور. يعرف النموذج بالضبط ما المعلومات التي تحتاجها."
  prompt={`حلل هذه الصورة وصف:

1. **الموضوع الرئيسي**: ما هو التركيز الأساسي لهذه الصورة؟
2. **المكان**: أين يبدو أن هذا يحدث؟ (داخلي/خارجي، نوع الموقع)
3. **المزاج**: ما النغمة العاطفية أو الأجواء التي تنقلها؟
4. **المحتوى النصي**: أي نص مرئي أو لافتات أو تسميات؟
5. **تفاصيل ملحوظة**: ما الذي قد يفوته شخص ما للوهلة الأولى؟
6. **الجودة التقنية**: كيف هي الإضاءة والتركيز والتكوين؟

[الصق أو صف الصورة التي تريد تحليلها]

وصف الصورة أو الرابط: \${imageDescription}`}
/>

### المخرجات المنظمة للصور

عندما تحتاج لمعالجة تحليل الصور برمجيًا، اطلب مخرجات JSON.

<TryIt 
  title="تحليل الصور بصيغة JSON"
  description="احصل على بيانات منظمة من تحليل الصور يسهل تحليلها واستخدامها في التطبيقات."
  prompt={`حلل هذه الصورة وأرجع كائن JSON بالهيكل التالي:

{
  "summary": "وصف من جملة واحدة",
  "objects": ["قائمة بالأشياء الرئيسية المرئية"],
  "people": {
    "count": "عدد أو 'لا يوجد'",
    "activities": ["ماذا يفعلون، إن وجد"]
  },
  "text_detected": ["أي نص مرئي في الصورة"],
  "colors": {
    "dominant": ["أعلى 3 ألوان"],
    "mood": "دافئ/بارد/محايد"
  },
  "setting": {
    "type": "داخلي/خارجي/غير معروف",
    "description": "وصف أكثر تحديدًا للموقع"
  },
  "technical": {
    "quality": "عالية/متوسطة/منخفضة",
    "lighting": "وصف الإضاءة",
    "composition": "وصف الإطار/التكوين"
  },
  "confidence": "عالية/متوسطة/منخفضة"
}

الصورة للتحليل: \${imageDescription}`}
/>

### التحليل المقارن

مقارنة صور متعددة تتطلب تسمية واضحة ومعايير مقارنة محددة.

<TryIt 
  title="مقارنة الصور"
  description="قارن بين صورتين أو أكثر بمعايير محددة تهم قرارك."
  prompt={`قارن هذه الصور لـ \${purpose}:

**الصورة أ**: \${imageA}
**الصورة ب**: \${imageB}

حلل كل صورة وفق هذه المعايير:
1. \${criterion1} (الأهمية: عالية)
2. \${criterion2} (الأهمية: متوسطة)  
3. \${criterion3} (الأهمية: منخفضة)

قدم:
- مقارنة جنبًا إلى جنب لكل معيار
- نقاط القوة والضعف لكل صورة
- توصية واضحة مع التبرير
- أي مخاوف أو تحفظات`}
/>

## تحليل المستندات ولقطات الشاشة

أحد أكثر التطبيقات العملية للذكاء الاصطناعي متعدد الوسائط هو تحليل المستندات ولقطات الشاشة وعناصر واجهة المستخدم. هذا يوفر ساعات من النسخ والمراجعة اليدوية.

### استخراج المستندات

المستندات الممسوحة ضوئيًا وصور الإيصالات وملفات PDF كصور يمكن معالجتها جميعًا. المفتاح هو إخبار النموذج بنوع المستند والمعلومات التي تحتاجها.

<TryIt 
  title="مستخرج بيانات المستندات"
  description="استخرج البيانات المنظمة من صور المستندات والإيصالات والفواتير أو النماذج."
  prompt={`هذه صورة/مسح ضوئي لـ \${documentType}.

استخرج جميع المعلومات بتنسيق JSON منظم:

{
  "document_type": "النوع المكتشف",
  "date": "إذا وجد",
  "key_fields": {
    "اسم_الحقل": "القيمة"
  },
  "line_items": [
    {"description": "", "amount": ""}
  ],
  "totals": {
    "subtotal": "",
    "tax": "",
    "total": ""
  },
  "handwritten_notes": ["أي نص مكتوب بخط اليد"],
  "unclear_sections": ["المناطق التي صعب قراءتها"],
  "confidence": "عالية/متوسطة/منخفضة"
}

هام: إذا كان أي نص غير واضح، دونه في "unclear_sections" بدلاً من التخمين. حدد الثقة بـ "منخفضة" إذا كانت أجزاء كبيرة صعبة القراءة.

وصف المستند: \${documentDescription}`}
/>

### تحليل لقطات الشاشة وواجهة المستخدم

لقطات الشاشة كنوز لتصحيح الأخطاء ومراجعة تجربة المستخدم والتوثيق. وجه الذكاء الاصطناعي للتركيز على ما يهم.

<TryIt 
  title="محلل لقطات الشاشة وتجربة المستخدم"
  description="احصل على تحليل مفصل للقطات الشاشة لتصحيح الأخطاء أو مراجعة تجربة المستخدم أو التوثيق."
  prompt={`هذه لقطة شاشة لـ \${applicationName}.

حلل هذه الواجهة:

**التعريف**
- ما هذه الشاشة/الصفحة/الحالة؟
- ما الذي يحاول المستخدم إنجازه على الأرجح هنا؟

**عناصر واجهة المستخدم**
- العناصر التفاعلية الرئيسية (الأزرار، النماذج، القوائم)
- الحالة الحالية (هل هناك شيء محدد أو معبأ أو موسع؟)
- أي رسائل خطأ أو تحذيرات أو إشعارات؟

**تقييم تجربة المستخدم**
- هل التخطيط واضح وبديهي؟
- أي عناصر مربكة أو تسميات غير واضحة؟
- مخاوف إمكانية الوصول (التباين، حجم النص، إلخ)؟

**المشكلات المكتشفة**
- أخطاء بصرية أو عدم محاذاة؟
- نص مقطوع أو مشاكل تجاوز؟
- تنسيق غير متسق؟

وصف لقطة الشاشة: \${screenshotDescription}`}
/>

### تحليل رسائل الخطأ

عندما تواجه خطأ، لقطة الشاشة غالبًا تحتوي على سياق أكثر من مجرد نسخ نص الخطأ.

<TryIt 
  title="تشخيص الخطأ من لقطة الشاشة"
  description="احصل على شروحات بلغة بسيطة وحلول لرسائل الخطأ في لقطات الشاشة."
  prompt={`أرى هذا الخطأ في \${context}.

[صف أو الصق رسالة الخطأ/لقطة الشاشة]
تفاصيل الخطأ: \${errorDetails}

يرجى تقديم:

1. **شرح بلغة بسيطة**: ماذا يعني هذا الخطأ فعلاً؟

2. **الأسباب المحتملة** (مرتبة حسب الاحتمالية):
   - الأكثر احتمالاً: 
   - ممكن أيضًا:
   - أقل شيوعًا:

3. **خطوات الإصلاح**:
   - أولاً، جرب...
   - إذا لم ينجح ذلك...
   - كملاذ أخير...

4. **الوقاية**: كيفية تجنب هذا الخطأ في المستقبل

5. **علامات التحذير**: متى قد يشير هذا الخطأ إلى مشكلة أكثر خطورة`}
/>

## أوامر توليد الصور

توليد الصور من الأوصاف النصية هو شكل من أشكال الفن. كلما كان أمرك أكثر تحديدًا وتنظيمًا، كلما اقتربت النتيجة من رؤيتك.

### تشريح أمر الصورة

أوامر توليد الصور الفعالة لها عدة مكونات:

<InfoGrid items={[
  { label: "الموضوع", description: "ما هو التركيز الرئيسي للصورة؟", example: "كلب جولدن ريتريفر يلعب في أوراق الخريف", color: "blue" },
  { label: "الأسلوب", description: "ما الأسلوب الفني أو الوسيط؟", example: "لوحة مائية، فن رقمي، واقعية تصويرية", color: "purple" },
  { label: "التكوين", description: "كيف يتم ترتيب المشهد؟", example: "صورة قريبة، منظر طبيعي واسع، رؤية من الأعلى", color: "green" },
  { label: "الإضاءة", description: "ما مصدر وجودة الضوء؟", example: "ضوء صباحي ناعم، ظلال درامية، توهج نيون", color: "amber" },
  { label: "المزاج", description: "ما الشعور الذي يجب أن تثيره؟", example: "هادئ، نشيط، غامض، حنين", color: "pink" },
  { label: "التفاصيل", description: "عناصر محددة للتضمين أو التجنب", example: "تضمين: زهور. تجنب: نص، علامات مائية", color: "cyan" }
]} />

### توليد الصور الأساسي

<TryIt 
  title="أمر صورة منظم"
  description="استخدم هذا القالب لإنشاء أوامر توليد صور مفصلة ومحددة."
  prompt={`أنشئ صورة بهذه المواصفات:

**الموضوع**: \${subject}

**الأسلوب**: \${style}
**الوسيط**: \${medium} (مثل: لوحة زيتية، فن رقمي، صورة فوتوغرافية)

**التكوين**:
- الإطار: \${framing} (قريب، لقطة متوسطة، زاوية واسعة)
- المنظور: \${perspective} (مستوى العين، زاوية منخفضة، من الأعلى)
- التركيز: \${focusArea}

**الإضاءة**:
- المصدر: \${lightSource}
- الجودة: \${lightQuality} (ناعمة، قاسية، منتشرة)
- وقت اليوم: \${timeOfDay}

**لوحة الألوان**: \${colors}

**المزاج/الأجواء**: \${mood}

**يجب تضمين**: \${includeElements}
**يجب تجنب**: \${avoidElements}

**تقني**: نسبة العرض إلى الارتفاع \${aspectRatio}، جودة عالية`}
/>

### بناء المشهد

للمشاهد المعقدة، صف الطبقات من المقدمة إلى الخلفية.

<TryIt 
  title="وصف المشهد بالطبقات"
  description="ابنِ مشاهد معقدة بوصف ما يظهر في كل طبقة من العمق."
  prompt={`ولّد مشهدًا مفصلاً:

**المكان**: \${setting}

**المقدمة** (الأقرب للمشاهد):
\${foreground}

**الأرضية الوسطى** (منطقة الحدث الرئيسي):
\${middleGround}

**الخلفية** (العناصر البعيدة):
\${background}

**التفاصيل الجوية**:
- الطقس/الهواء: \${weather}
- الإضاءة: \${lighting}
- الوقت: \${timeOfDay}

**الأسلوب**: \${artisticStyle}
**المزاج**: \${mood}
**لوحة الألوان**: \${colors}

تفاصيل إضافية للتضمين: \${additionalDetails}`}
/>

## أوامر الصوت

معالجة الصوت تفتح إمكانيات النسخ والتحليل وفهم المحتوى المنطوق. المفتاح هو توفير السياق حول ما يحتويه الصوت.

### النسخ المحسّن

النسخ الأساسي هو مجرد البداية. مع الأوامر الجيدة، يمكنك الحصول على تحديد المتحدثين والطوابع الزمنية والدقة الخاصة بالمجال.

<TryIt 
  title="النسخ الذكي"
  description="احصل على نسخ دقيقة مع تسميات المتحدثين والطوابع الزمنية ومعالجة الأقسام غير الواضحة."
  prompt={`انسخ هذا التسجيل الصوتي.

**السياق**: \${recordingType} (اجتماع، مقابلة، بودكاست، محاضرة، إلخ)
**المتحدثون المتوقعون**: \${speakerCount} (\${speakerRoles})
**المجال**: \${domain} (المصطلحات التقنية المتوقعة: \${technicalTerms})

**تنسيق المخرجات**:
[00:00] **المتحدث 1 (الاسم/الدور)**: النص المنسوخ هنا.
[00:15] **المتحدث 2 (الاسم/الدور)**: ردهم هنا.

**التعليمات**:
- ضمّن الطوابع الزمنية عند الفواصل الطبيعية (كل 30-60 ثانية أو عند تغيير المتحدث)
- حدد الأقسام غير الواضحة كـ [غير مسموع] أو [غير واضح: أفضل تخمين؟]
- دوّن الأصوات غير الكلامية بين أقواس: [ضحك]، [رنين هاتف]، [صمت طويل]
- احتفظ بكلمات الحشو فقط إذا كانت ذات معنى (يمكن إزالة آه، أم)
- حدد أي عناصر عمل أو قرارات برمز ←

وصف الصوت: \${audioDescription}`}
/>

### تحليل محتوى الصوت

بالإضافة إلى النسخ، يمكن للذكاء الاصطناعي تحليل المحتوى والنبرة واللحظات المهمة في الصوت.

<TryIt 
  title="محلل محتوى الصوت"
  description="احصل على تحليل شامل لمحتوى الصوت يشمل الملخص واللحظات الرئيسية والمشاعر."
  prompt={`حلل هذا التسجيل الصوتي:

وصف الصوت: \${audioDescription}

قدم:

**1. ملخص تنفيذي** (2-3 جمل)
عن ماذا هذا التسجيل؟ ما الاستنتاج الرئيسي؟

**2. المتحدثون**
- كم عدد المتحدثين المميزين؟
- الخصائص (إذا أمكن تمييزها): النبرة، أسلوب الكلام، مستوى الخبرة

**3. تفصيل المحتوى**
- المواضيع الرئيسية التي نوقشت (مع الطوابع الزمنية التقريبية)
- النقاط الرئيسية المطروحة
- الأسئلة المثارة

**4. التحليل العاطفي**
- النبرة العامة (رسمية، عادية، متوترة، ودية)
- اللحظات العاطفية الملحوظة
- مستوى الطاقة طوال التسجيل

**5. العناصر القابلة للتنفيذ**
- القرارات المتخذة
- عناصر العمل المذكورة
- المتابعات المطلوبة

**6. اقتباسات ملحوظة**
استخرج 2-3 اقتباسات مهمة مع الطوابع الزمنية

**7. جودة الصوت**
- الوضوح العام
- أي مشاكل (ضوضاء خلفية، انقطاعات، مشاكل تقنية)`}
/>

## أوامر الفيديو

الفيديو يجمع بين التحليل البصري والصوتي عبر الوقت. التحدي هو توجيه الذكاء الاصطناعي للتركيز على الجوانب ذات الصلة طوال المدة الكاملة.

### فهم الفيديو

<TryIt 
  title="تحليل الفيديو الشامل"
  description="احصل على تفصيل منظم لمحتوى الفيديو يشمل الجدول الزمني والعناصر البصرية واللحظات الرئيسية."
  prompt={`حلل هذا الفيديو: \${videoDescription}

قدم تحليلاً شاملاً:

**1. نظرة عامة** (2-3 جمل)
عن ماذا هذا الفيديو؟ ما الرسالة أو الغرض الرئيسي؟

**2. الجدول الزمني للحظات الرئيسية**
| الطابع الزمني | الحدث | الأهمية |
|---------------|-------|---------|
| 0:00 | ... | ... |

**3. التحليل البصري**
- المكان/الموقع: أين يحدث هذا؟
- الأشخاص: من يظهر؟ ماذا يفعلون؟
- الأشياء: العناصر أو الدعائم الرئيسية المعروضة
- الأسلوب البصري: الجودة، التحرير، الرسومات المستخدمة

**4. التحليل الصوتي**
- الكلام: النقاط الرئيسية المطروحة (إذا كان هناك حوار)
- الموسيقى: النوع، المزاج، كيفية استخدامها
- المؤثرات الصوتية: العناصر الصوتية الملحوظة

**5. جودة الإنتاج**
- جودة الفيديو والتحرير
- الإيقاع والهيكل
- الفعالية لغرضه

**6. الجمهور المستهدف**
لمن صُنع هذا الفيديو؟ هل يخدمهم جيدًا؟

**7. النقاط الرئيسية**
ما الذي يجب أن يتذكره المشاهد من هذا الفيديو؟`}
/>

### استخراج محتوى الفيديو

لاستخراج معلومات محددة من الفيديوهات، كن دقيقًا حول ما تحتاجه.

<TryIt 
  title="مستخرج بيانات الفيديو"
  description="استخرج معلومات محددة من الفيديوهات مع الطوابع الزمنية والمخرجات المنظمة."
  prompt={`استخرج معلومات محددة من هذا الفيديو:

نوع الفيديو: \${videoType}
وصف الفيديو: \${videoDescription}

**المعلومات المطلوب استخراجها**:
1. \${extractItem1}
2. \${extractItem2}
3. \${extractItem3}

**تنسيق المخرجات**:
{
  "video_summary": "وصف موجز",
  "duration": "الطول المقدر",
  "extracted_data": [
    {
      "timestamp": "MM:SS",
      "item": "ما تم العثور عليه",
      "details": "سياق إضافي",
      "confidence": "عالية/متوسطة/منخفضة"
    }
  ],
  "items_not_found": ["قائمة بأي شيء مطلوب لكنه غير موجود"],
  "additional_observations": "أي شيء ذي صلة لم يُطلب صراحة"
}`}
/>

## التركيبات متعددة الوسائط

القوة الحقيقية للذكاء الاصطناعي متعدد الوسائط تظهر عندما تجمع أنواعًا مختلفة من المدخلات. هذه التركيبات تمكن من تحليل سيكون مستحيلاً مع وسيط واحد فقط.

### التحقق من الصورة + النص

تحقق مما إذا كانت الصور وأوصافها متطابقة—ضروري للتجارة الإلكترونية ومراقبة المحتوى وضمان الجودة.

<TryIt 
  title="مدقق توافق الصورة والنص"
  description="تحقق من أن الصور تمثل أوصافها النصية بدقة والعكس."
  prompt={`حلل هذه الصورة ونصها المرافق للتوافق:

**الصورة**: \${imageDescription}
**الوصف النصي**: "\${textDescription}"

قيّم:

**1. تطابق الدقة**
- هل تُظهر الصورة ما يصفه النص؟
- النتيجة: [1-10] مع التفسير

**2. الادعاءات النصية مقابل الواقع البصري**
| الادعاء في النص | مرئي في الصورة؟ | ملاحظات |
|-----------------|------------------|---------|
| ... | نعم/لا/جزئي | ... |

**3. العناصر البصرية غير المذكورة**
ما هو المرئي في الصورة لكنه غير موصوف في النص؟

**4. الادعاءات النصية غير المرئية**
ما هو الموصوف في النص لكن لا يمكن التحقق منه من الصورة؟

**5. التوصيات**
- للنص: [تحسينات لمطابقة الصورة]
- للصورة: [تحسينات لمطابقة النص]

**6. التقييم العام**
هل هذا الزوج من الصورة والنص موثوق به لـ \${purpose}؟`}
/>

### تصحيح الأخطاء بلقطة الشاشة + الكود

أحد أقوى التركيبات للمطورين: رؤية الخلل البصري إلى جانب الكود.

<TryIt 
  title="مصحح الأخطاء البصرية"
  description="صحح مشاكل واجهة المستخدم بتحليل كل من المخرجات البصرية والكود المصدري معًا."
  prompt={`لدي خلل في واجهة المستخدم. إليك ما أراه والكود الخاص بي:

**وصف لقطة الشاشة**: \${screenshotDescription}
**ما هو الخطأ**: \${bugDescription}
**السلوك المتوقع**: \${expectedBehavior}

**الكود ذو الصلة**:
\`\`\`\${language}
\${code}
\`\`\`

يرجى مساعدتي في:

**1. تحليل السبب الجذري**
- ما في الكود يسبب هذه المشكلة البصرية؟
- أي سطر (أسطر) مسؤول؟

**2. الشرح**
- لماذا ينتج هذا الكود هذه النتيجة البصرية؟
- ما هي الآلية الأساسية؟

**3. الإصلاح**
\`\`\`\${language}
// الكود المصحح هنا
\`\`\`

**4. الوقاية**
- كيفية تجنب هذا النوع من الأخطاء في المستقبل
- أي مشاكل ذات صلة يجب التحقق منها`}
/>

### صنع القرار متعدد الصور

عند الاختيار بين الخيارات، المقارنة المنظمة تساعد في اتخاذ قرارات أفضل.

<TryIt 
  title="مقارن الخيارات البصرية"
  description="قارن صورًا متعددة بشكل منهجي وفق معاييرك لاتخاذ قرارات مستنيرة."
  prompt={`أنا أختار بين هذه الخيارات لـ \${purpose}:

**الخيار أ**: \${optionA}
**الخيار ب**: \${optionB}
**الخيار ج**: \${optionC}

**معاييري** (بترتيب الأهمية):
1. \${criterion1} (الوزن: عالي)
2. \${criterion2} (الوزن: متوسط)
3. \${criterion3} (الوزن: منخفض)

قدم:

**مصفوفة المقارنة**
| المعيار | الخيار أ | الخيار ب | الخيار ج |
|---------|----------|----------|----------|
| \${criterion1} | النتيجة + ملاحظات | ... | ... |
| \${criterion2} | ... | ... | ... |
| \${criterion3} | ... | ... | ... |

**النتائج المرجحة**
- الخيار أ: X/10
- الخيار ب: X/10
- الخيار ج: X/10

**التوصية**
بناءً على أولوياتك المذكورة، أوصي بـ [الخيار] لأن...

**التحفظات**
- إذا [الحالة]، فكر في [البديل] بدلاً من ذلك
- احذر من [المشكلة المحتملة]`}
/>

## أفضل الممارسات للأوامر متعددة الوسائط

الحصول على نتائج رائعة من الذكاء الاصطناعي متعدد الوسائط يتطلب فهم قدراته وقيوده.

### ما الذي يجعل الأوامر متعددة الوسائط فعالة

<InfoGrid items={[
  { label: "قدم السياق", description: "أخبر النموذج ما هي الوسائط ولماذا تحللها", example: "\"هذه صورة منتج لموقع التجارة الإلكترونية الخاص بنا...\"", color: "green" },
  { label: "كن محددًا", description: "اسأل عن عناصر معينة بدلاً من الانطباعات العامة", example: "\"ركز على جدول الأسعار في الزاوية العلوية اليمنى\"", color: "green" },
  { label: "أشر إلى المواقع", description: "حدد مناطق معينة باستخدام اللغة المكانية", example: "\"في الربع السفلي الأيسر...\"", color: "green" },
  { label: "اذكر هدفك", description: "اشرح لماذا ستستخدم التحليل", example: "\"أحتاج أن أقرر إذا كانت هذه الصورة تصلح لتطبيقنا المحمول\"", color: "green" }
]} />

### المزالق الشائعة التي يجب تجنبها

<InfoGrid items={[
  { label: "افتراض الرؤية المثالية", description: "قد تفوت النماذج التفاصيل الصغيرة، خاصة في الصور منخفضة الدقة", example: "لا تسأل عن نص 8 نقاط في لقطة شاشة مضغوطة", color: "red" },
  { label: "توقع OCR مثالي", description: "الكتابة اليدوية والخطوط غير المعتادة والتخطيطات المعقدة قد تسبب أخطاء", example: "تحقق من النص المستخرج من الإيصالات والنماذج", color: "red" },
  { label: "تجاهل سياسات المحتوى", description: "النماذج لها قيود على أنواع معينة من المحتوى", example: "لن تحدد أفرادًا محددين أو تحلل محتوى غير لائق", color: "red" },
  { label: "تخطي التحقق", description: "تحقق دائمًا من المعلومات الحرجة المستخرجة من الوسائط", example: "تحقق مرتين من الأرقام والتواريخ والأسماء من استخراج المستندات", color: "red" }
]} />

### التعامل مع القيود بأناقة

<TryIt 
  title="تحليل الصور مع الوعي بعدم اليقين"
  description="هذا الأمر يتعامل صراحة مع الحالات التي لا يستطيع فيها النموذج الرؤية بوضوح أو غير متأكد."
  prompt={`حلل هذه الصورة: \${imageDescription}

**تعليمات للتعامل مع عدم اليقين**:

إذا لم تستطع رؤية شيء بوضوح:
- لا تخمن أو تختلق تفاصيل
- قل: "أستطيع رؤية [ما هو مرئي] لكن لا أستطيع تمييز [العنصر غير الواضح] بوضوح"
- اقترح ما المعلومات الإضافية التي ستساعد

إذا بدا المحتوى مقيدًا:
- اشرح ما يمكنك وما لا يمكنك تحليله
- ركز على الجوانب المسموح بها من التحليل

إذا سُئلت عن أشخاص:
- صف الأفعال والمواقع والخصائص العامة
- لا تحاول تحديد أفراد محددين
- ركز على: عدد الأشخاص، الأنشطة، التعبيرات، الملابس

**تحليلك**:
[تابع التحليل، مطبقًا هذه الإرشادات]`}
/>

<Quiz 
  question="لماذا صياغة الأوامر أكثر أهمية للنماذج متعددة الوسائط من النماذج النصية فقط؟"
  options={[
    "النماذج متعددة الوسائط أقل ذكاءً وتحتاج المزيد من المساعدة",
    "الصور والصوت غامضة بطبيعتها—الذكاء الاصطناعي يحتاج السياق ليعرف أي الجوانب مهمة",
    "النماذج متعددة الوسائط يمكنها معالجة نوع واحد فقط من المدخلات في كل مرة",
    "الأوامر النصية لا تعمل مع النماذج متعددة الوسائط"
  ]}
  correctIndex={1}
  explanation="عندما تنظر إلى صورة، تعرف فورًا ما هو المهم بناءً على أهدافك. الذكاء الاصطناعي لا يملك هذا السياق—صورة لشق في الجدار يمكن أن تكون مشكلة هندسية، أو نسيج فني، أو خلفية غير ذات صلة. أمرك يحدد كيف يفسر الذكاء الاصطناعي الوسائط التي تقدمها ويركز عليها."
/>
