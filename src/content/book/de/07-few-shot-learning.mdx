Few-Shot-Lernen ist eine der mächtigsten Prompting-Techniken. Indem du Beispiele dessen bereitstellst, was du willst, kannst du dem Modell komplexe Aufgaben beibringen, ohne Fine-Tuning.

<Callout type="info" title="Lernen durch Beispiele">
Genau wie Menschen durch Sehen von Beispielen lernen, können KI-Modelle Muster aus den Beispielen lernen, die du in deinem Prompt bereitstellst.
</Callout>

## Was ist Few-Shot-Lernen?

Few-Shot-Lernen zeigt dem Modell Beispiele von Eingabe-Ausgabe-Paaren, bevor es gebeten wird, dieselbe Aufgabe auszuführen. Das Modell lernt das Muster aus deinen Beispielen und wendet es auf neue Eingaben an.

<Compare 
  before={{ 
    label: "Zero-Shot (Keine Beispiele)", 
    content: `Klassifiziere diese Bewertung als positiv oder negativ:

"Der Akku hält ewig, aber der Bildschirm ist zu dunkel."

→ Modell kann bei Grenzfällen inkonsistent sein` 
  }}
  after={{ 
    label: "Few-Shot (Mit Beispielen)", 
    content: `"Liebe es!" → Positiv
"Schreckliche Qualität" → Negativ  
"Gut aber teuer" → Gemischt

Jetzt klassifiziere:
"Der Akku hält ewig, aber der Bildschirm ist zu dunkel."

→ Modell lernt deine genauen Kategorien` 
  }}
/>

<div className="my-4 grid grid-cols-2 md:grid-cols-4 gap-2">
  <div className="p-3 bg-muted/50 rounded-lg text-center">
    <div className="text-2xl font-bold">0</div>
    <div className="text-xs text-muted-foreground">Zero-shot</div>
  </div>
  <div className="p-3 bg-muted/50 rounded-lg text-center">
    <div className="text-2xl font-bold">1</div>
    <div className="text-xs text-muted-foreground">One-shot</div>
  </div>
  <div className="p-3 bg-primary/10 rounded-lg text-center border-2 border-primary">
    <div className="text-2xl font-bold">2-5</div>
    <div className="text-xs text-muted-foreground">Few-shot</div>
  </div>
  <div className="p-3 bg-muted/50 rounded-lg text-center">
    <div className="text-2xl font-bold">5+</div>
    <div className="text-xs text-muted-foreground">Many-shot</div>
  </div>
</div>

## Warum Beispiele funktionieren

<FewShotDemo />

Beispiele kommunizieren:
- **Format**: Wie die Ausgabe strukturiert sein soll
- **Stil**: Ton, Länge, Vokabular
- **Logik**: Das zu folgende Denkmuster
- **Grenzfälle**: Wie Sondersituationen zu behandeln sind

## Grundlegendes Few-Shot-Muster

Die grundlegende Struktur des Few-Shot-Promptings folgt einem einfachen Muster: zeige Beispiele, dann frage nach der neuen Aufgabe. Konsistenz in der Formatierung zwischen Beispielen ist entscheidend. Das Modell lernt aus dem Muster, das du etablierst.

```
[Beispiel 1]
Eingabe: [eingabe 1]
Ausgabe: [ausgabe 1]

[Beispiel 2]
Eingabe: [eingabe 2]
Ausgabe: [ausgabe 2]

[Beispiel 3]
Eingabe: [eingabe 3]
Ausgabe: [ausgabe 3]

Jetzt mach dieses:
Eingabe: [neue eingabe]
Ausgabe:
```

## Few-Shot für Klassifizierung

Klassifizierung ist einer der stärksten Anwendungsfälle für Few-Shot-Lernen. Indem du Beispiele jeder Kategorie zeigst, definierst du die Grenzen zwischen Klassen präziser, als es Anweisungen allein könnten.

### Sentiment-Analyse

<Callout type="info" title="Was ist Sentiment-Analyse?">
Sentiment-Analyse klassifiziert Text nach emotionalem Ton: positiv, negativ, neutral oder gemischt. Sie wird weit verbreitet für Kundenfeedback, Social-Media-Monitoring und Markenwahrnehmungs-Tracking verwendet.
</Callout>

Sentiment-Klassifizierung profitiert davon, Beispiele jedes Sentiment-Typs zu zeigen, besonders Grenzfälle wie "gemischtes" Sentiment, das mehrdeutig sein könnte.

<TryIt compact prompt={`Klassifiziere das Sentiment dieser Kundenbewertungen.

Bewertung: "Dieses Produkt hat alle meine Erwartungen übertroffen! Werde wieder kaufen."
Sentiment: Positiv

Bewertung: "Kam kaputt an und der Kundenservice war nicht hilfreich."
Sentiment: Negativ

Bewertung: "Funktioniert gut, nichts Besonderes, erfüllt aber seinen Zweck."
Sentiment: Neutral

Bewertung: "Die Qualität ist fantastisch, aber der Versand hat ewig gedauert."
Sentiment: Gemischt

Jetzt klassifiziere:
Bewertung: "Liebe das Design, aber die Akkulaufzeit ist enttäuschend."
Sentiment:`} />

### Themen-Klassifizierung

Für Multi-Klassen-Kategorisierung füge mindestens ein Beispiel pro Kategorie ein. Dies hilft dem Modell, deine spezifische Taxonomie zu verstehen, die von seinem Standardverständnis abweichen kann.

<TryIt compact prompt={`Kategorisiere diese Support-Tickets.

Ticket: "Ich kann mich nicht in mein Konto einloggen, Passwort-Reset funktioniert nicht"
Kategorie: Authentifizierung

Ticket: "Wie kann ich auf den Premium-Plan upgraden?"
Kategorie: Abrechnung

Ticket: "Die App stürzt ab, wenn ich Daten exportieren will"
Kategorie: Bug-Report

Ticket: "Können Sie Dark Mode zur mobilen App hinzufügen?"
Kategorie: Feature-Anfrage

Jetzt kategorisiere:
Ticket: "Meine Zahlung wurde abgelehnt, aber ich sehe die Abbuchung auf meiner Karte"
Kategorie:`} />

## Few-Shot für Transformation

Transformationsaufgaben konvertieren Eingaben von einer Form in eine andere, während die Bedeutung erhalten bleibt. Beispiele sind hier essentiell, weil sie genau definieren, was "Transformation" für deinen Anwendungsfall bedeutet.

### Text-Umschreibung

Stiltransformation erfordert Beispiele, die den genauen Tonwechsel zeigen, den du willst. Abstrakte Anweisungen wie "mach es professioneller" werden unterschiedlich interpretiert. Beispiele machen es konkret.

<TryIt compact prompt={`Schreibe diese Sätze in professionellem Ton um.

Locker: "Hey, wollte nur checken, ob du meine Mail bekommen hast?"
Professionell: "Ich wollte bezüglich meiner vorherigen E-Mail nachfragen."

Locker: "Das ist mega wichtig und muss sofort gemacht werden!"
Professionell: "Diese Angelegenheit erfordert dringende Aufmerksamkeit und schnelles Handeln."

Locker: "Sorry für die späte Antwort, war total im Stress!"
Professionell: "Ich entschuldige mich für die verspätete Antwort. Ich hatte einen besonders anspruchsvollen Zeitplan."

Jetzt schreibe um:
Locker: "Kann nicht zum Meeting kommen, ist was dazwischengekommen."
Professionell:`} />

### Format-Konvertierung

Format-Konvertierungsaufgaben profitieren von Beispielen, die Grenzfälle und mehrdeutige Eingaben zeigen. Das Modell lernt deine spezifischen Konventionen für den Umgang mit kniffligen Fällen.

<TryIt compact prompt={`Konvertiere diese natürlichsprachlichen Daten ins ISO-Format.

Eingabe: "nächsten Dienstag"
Ausgabe: 2024-01-16 (angenommen heute ist 2024-01-11, Donnerstag)

Eingabe: "übermorgen"
Ausgabe: 2024-01-13

Eingabe: "letzter Tag dieses Monats"
Ausgabe: 2024-01-31

Eingabe: "in zwei Wochen"
Ausgabe: 2024-01-25

Jetzt konvertiere:
Eingabe: "der erste Montag nächsten Monats"
Ausgabe:`} />

## Few-Shot für Generierung

Generierungsaufgaben erstellen neue Inhalte nach einem gelernten Muster. Beispiele etablieren Länge, Struktur, Ton und welche Details hervorgehoben werden sollen. Diese sind schwer nur mit Anweisungen zu spezifizieren.

### Produktbeschreibungen

Marketing-Texte profitieren enorm von Beispielen, weil sie Markenstimme, Feature-Betonung und Überzeugungstechniken einfangen, die abstrakt schwer zu beschreiben sind.

<TryIt compact prompt={`Schreibe Produktbeschreibungen in diesem Stil:

Produkt: Kabellose Bluetooth-Kopfhörer
Beschreibung: Tauche ein in kristallklaren Sound mit unseren federleichten kabellosen Kopfhörern. Mit 40 Stunden Akkulaufzeit, aktiver Geräuschunterdrückung und weichen Memory-Foam-Ohrpolstern für ganztägigen Komfort.

Produkt: Edelstahl-Wasserflasche
Beschreibung: Bleib stilvoll hydriert mit unserer doppelwandigen isolierten Flasche. Hält Getränke 24 Stunden kalt oder 12 Stunden heiß. Mit auslaufsicherem Deckel und passt in Standard-Getränkehalter.

Produkt: Ergonomischer Bürostuhl
Beschreibung: Verwandle deinen Arbeitsplatz mit unserem verstellbaren ergonomischen Stuhl. Atmungsaktive Netzrückenlehne, Lendenwirbelstütze und 360°-Drehung kombinieren sich für Komfort bei langen Arbeitssitzungen.

Jetzt schreibe:
Produkt: Tragbares Handyladegerät
Beschreibung:`} />

### Code-Dokumentation

<Callout type="info" title="Warum Code dokumentieren?">
Gute Dokumentation erklärt, was Code macht, seine Parameter, Rückgabewerte und Nutzungsbeispiele. Konsistente Docstrings ermöglichen automatisch generierte API-Docs und helfen IDEs, bessere Code-Vervollständigung bereitzustellen.
</Callout>

Dokumentationsstil variiert stark zwischen Projekten. Beispiele lehren dein spezifisches Format, was einzubeziehen ist (Args, Returns, Beispiele) und den erwarteten Detailgrad.

<TryIt compact prompt={`Schreibe Dokumentationskommentare für diese Funktionen:

Funktion:
def berechne_bmi(gewicht_kg, groesse_m):
    return gewicht_kg / (groesse_m ** 2)

Dokumentation:
"""
Berechnet den Body-Mass-Index (BMI) aus Gewicht und Größe.

Args:
    gewicht_kg (float): Gewicht in Kilogramm
    groesse_m (float): Größe in Metern

Returns:
    float: BMI-Wert (Gewicht/Größe²)

Beispiel:
    >>> berechne_bmi(70, 1.75)
    22.86
"""

Jetzt dokumentiere:
Funktion:
def ist_palindrom(text):
    bereinigt = ''.join(c.lower() for c in text if c.isalnum())
    return bereinigt == bereinigt[::-1]

Dokumentation:`} />

## Few-Shot für Extraktion

Extraktionsaufgaben ziehen strukturierte Informationen aus unstrukturiertem Text. Beispiele definieren, welche Entitäten wichtig sind, wie die Ausgabe formatiert wird und wie Fälle behandelt werden, in denen Informationen fehlen oder mehrdeutig sind.

### Entitäts-Extraktion

<Callout type="info" title="Was ist Named Entity Recognition?">
Named Entity Recognition (NER) identifiziert und klassifiziert benannte Entitäten in Text in Kategorien wie Personen, Organisationen, Orte, Daten und Produkte. Sie ist fundamental für Information Retrieval und Wissensgraphen.
</Callout>

NER profitiert von Beispielen, die deine spezifischen Entitätstypen zeigen und wie mit Entitäten umzugehen ist, die in mehrere Kategorien passen könnten.

<TryIt compact prompt={`Extrahiere benannte Entitäten aus diesen Sätzen.

Text: "Apple-CEO Tim Cook kündigte das iPhone 15 in Cupertino an."
Entitäten:
- UNTERNEHMEN: Apple
- PERSON: Tim Cook
- PRODUKT: iPhone 15
- ORT: Cupertino

Text: "Die Europäische Union verhängte 2018 eine Strafe von 4,34 Milliarden Euro gegen Google."
Entitäten:
- ORGANISATION: Europäische Union
- UNTERNEHMEN: Google
- GELD: 4,34 Milliarden Euro
- DATUM: 2018

Jetzt extrahiere aus:
Text: "Elon Musks SpaceX startete am 3. Dezember 23 Starlink-Satelliten von Cape Canaveral."
Entitäten:`} />

### Strukturierte Datenextraktion

Das Extrahieren strukturierter Daten aus natürlicher Sprache erfordert Beispiele, die zeigen, wie mit fehlenden Feldern, impliziten Informationen und variierenden Eingabeformaten umzugehen ist.

<TryIt compact prompt={`Extrahiere Meeting-Details in strukturiertes Format.

Email: "Lass uns morgen um 15 Uhr im Konferenzraum B treffen, um das Q4-Budget zu besprechen. Bitte bring deinen Laptop mit."

Meeting:
- Datum: [morgen]
- Zeit: 15:00 Uhr
- Ort: Konferenzraum B
- Thema: Q4-Budget-Diskussion
- Anforderungen: Laptop mitbringen

Email: "Team-Sync auf Freitag 10 Uhr verschoben, wir nutzen stattdessen Zoom. Link in der Kalendereinladung. Maximal 30 Minuten."

Meeting:
- Datum: Freitag
- Zeit: 10:00 Uhr
- Ort: Zoom (virtuell)
- Thema: Team-Sync
- Dauer: 30 Minuten

Jetzt extrahiere aus:
Email: "Können wir Montag früh gegen 9:30 kurz telefonieren, um die Kundenpräsentation durchzugehen? Ich schicke einen Teams-Link."

Meeting:`} />

## Fortgeschrittene Few-Shot-Techniken

Über grundlegendes Few-Shot hinaus können mehrere Techniken die Ergebnisse für komplexe Aufgaben verbessern.

### Diverse Beispiele

Vielfalt in Beispielen ist wertvoller als Quantität. Decke verschiedene Szenarien, Grenzfälle und potenzielle Mehrdeutigkeiten ab, anstatt ähnliche Beispiele wiederholt zu zeigen.

<TryIt compact prompt={`Antworte auf Kundenbeschwerden.

Beispiel 1 (Produktproblem):
Kunde: "Meine Bestellung kam beschädigt an."
Antwort: "Ich entschuldige mich aufrichtig für die beschädigte Lieferung. Ich werde sofort einen Ersatz ohne Kosten senden. Sie müssen den beschädigten Artikel nicht zurücksenden. Darf ich Ihre Lieferadresse bestätigen?"

Beispiel 2 (Service-Problem):
Kunde: "Ich bin seit 2 Stunden in der Warteschleife!"
Antwort: "Es tut mir sehr leid für die lange Wartezeit. Das ist inakzeptabel. Ich bin jetzt da und werde persönlich sicherstellen, dass Ihr Problem gelöst wird. Wie kann ich Ihnen heute helfen?"

Beispiel 3 (Abrechnungsproblem):
Kunde: "Sie haben mir zweimal für dieselbe Bestellung berechnet!"
Antwort: "Ich entschuldige mich für diesen Abrechnungsfehler. Ich habe die doppelte Abbuchung verifiziert und eine Rückerstattung von XX€ auf Ihre ursprüngliche Zahlungsmethode eingeleitet. Sie sollten sie innerhalb von 3-5 Werktagen sehen."

Jetzt antworte auf:
Kunde: "Das Produkt entspricht nicht dem, was auf der Website gezeigt wurde."
Antwort:`} />

### Negative Beispiele

<Callout type="tip" title="Kontrastives Lernen">
"Gute" vs "schlechte" Beispiele zu zeigen wird kontrastives Lernen genannt. Es hilft dem Modell zu verstehen, was du nicht nur willst, sondern auch was zu vermeiden ist. Dies ist besonders nützlich für Stil- und Qualitätsurteile.
</Callout>

Manchmal ist das Zeigen, was *nicht* zu tun ist, genauso wertvoll wie das Zeigen korrekter Beispiele. Negative Beispiele helfen dem Modell, Grenzen zu verstehen und häufige Fehler zu vermeiden.

<TryIt compact prompt={`Schreibe prägnante E-Mail-Betreffzeilen.

Gut: "Q3-Bericht zur Überprüfung bereit"
Schlecht: "Hey, ich hab das Berichtsding fertig, über das wir gesprochen haben"

Gut: "Aktion erforderlich: Urlaub bis Freitag genehmigen"
Schlecht: "Ich brauche dass du was für mich machst bitte lies das"

Gut: "Meeting verschoben: Projekt-Sync → Donnerstag 14 Uhr"
Schlecht: "Planänderung!!!!!"

Jetzt schreibe eine Betreffzeile für:
E-Mail über: Feedback zu einem Vorschlagsentwurf anfordern
Betreff:`} />

### Grenzfall-Beispiele

Grenzfälle bestimmen oft, ob eine Lösung in der Produktion funktioniert. Das Einbeziehen ungewöhnlicher Eingaben in deine Beispiele verhindert, dass das Modell bei realen Daten versagt, die nicht dem "glücklichen Pfad" entsprechen.

<TryIt compact prompt={`Parse Namen in strukturiertes Format.

Eingabe: "Hans Müller"
Ausgabe: {"vorname": "Hans", "nachname": "Müller", "zweiter_vorname": null, "suffix": null}

Eingabe: "Maria Anna Schmidt-Weber"
Ausgabe: {"vorname": "Maria", "zweiter_vorname": "Anna", "nachname": "Schmidt-Weber", "suffix": null}

Eingabe: "Dr. Martin Ludwig König Jr."
Ausgabe: {"präfix": "Dr.", "vorname": "Martin", "zweiter_vorname": "Ludwig", "nachname": "König", "suffix": "Jr."}

Eingabe: "Madonna"
Ausgabe: {"vorname": "Madonna", "nachname": null, "zweiter_vorname": null, "suffix": null, "mononym": true}

Jetzt parse:
Eingabe: "Graf Ferdinand von Habsburg III"
Ausgabe:`} />

## Wie viele Beispiele?

<div className="my-4 grid gap-2">
  <div className="flex gap-3 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-40">Einfache Klassifizierung</span>
    <span className="text-primary font-mono">2-3</span>
    <span className="text-muted-foreground">Mindestens eines pro Kategorie</span>
  </div>
  <div className="flex gap-3 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-40">Komplexe Formatierung</span>
    <span className="text-primary font-mono">3-5</span>
    <span className="text-muted-foreground">Zeige Variationen</span>
  </div>
  <div className="flex gap-3 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-40">Nuancierter Stil</span>
    <span className="text-primary font-mono">4-6</span>
    <span className="text-muted-foreground">Erfasse volle Bandbreite</span>
  </div>
  <div className="flex gap-3 p-3 bg-muted/50 rounded-lg">
    <span className="font-semibold min-w-40">Grenzfälle</span>
    <span className="text-primary font-mono">1-2</span>
    <span className="text-muted-foreground">Zusammen mit normalen Beispielen</span>
  </div>
</div>

## Beispielqualität zählt

<Compare 
  before={{ 
    label: "Schlechte Beispiele", 
    content: `"Nettes Produkt" → Gut
"Netter Service" → Gut
"Netter Preis" → Gut

✗ Alle zu ähnlich
✗ Gleiches Wort wiederholt
✗ Keine Grenzfälle gezeigt` 
  }}
  after={{ 
    label: "Gute Beispiele", 
    content: `"Erwartungen übertroffen!" → Positiv
"Bei Ankunft kaputt" → Negativ
"Funktioniert gut, nichts Besonderes" → Neutral
"Tolle Qualität aber überteuert" → Gemischt

✓ Diverse Szenarien
✓ Klare Grenzen
✓ Deckt Grenzfälle ab` 
  }}
/>

## Few-Shot mit anderen Techniken kombinieren

Few-Shot-Lernen kombiniert sich kraftvoll mit anderen Prompting-Techniken. Die Beispiele liefern das "Was", während andere Techniken Kontext, Denken oder Struktur hinzufügen können.

### Few-Shot + Rolle

Das Hinzufügen einer Rolle gibt dem Modell Kontext dafür, *warum* es die Aufgabe ausführt, was Qualität und Konsistenz verbessern kann.

```
Du bist ein juristischer Vertragsprüfer.

[Beispiele für Vertragsklausel-Analyse]

Jetzt analysiere: [neue Klausel]
```

### Few-Shot + CoT

Die Kombination von Few-Shot mit Chain of Thought zeigt nicht nur *welche* Antwort zu geben ist, sondern *wie* man zu dieser Antwort denkt. Dies ist mächtig für Aufgaben, die Urteilsvermögen erfordern.

```
Klassifiziere und erkläre die Begründung.

Bewertung: "Tolle Features aber überteuert"
Denken: Die Bewertung erwähnt positive Aspekte ("tolle Features") 
aber auch ein bedeutendes Negativ ("überteuert"). Das Negative scheint 
das Positive zu überwiegen, basierend auf der "aber"-Konjunktion.
Klassifizierung: Gemischt-Negativ

[weitere Beispiele mit Begründung]

Jetzt klassifiziere mit Begründung:
Bewertung: "Genau was ich brauchte, kam schneller als erwartet an"
```

## Zusammenfassung

<Callout type="tip" title="Wichtige Erkenntnisse">
Few-Shot-Lernen lehrt durch Demonstration und ist oft effektiver als Anweisungen allein. Verwende 2-5 diverse, korrekte Beispiele und kombiniere mit anderen Techniken für beste Ergebnisse.
</Callout>

<Quiz 
  question="Wie viele Beispiele solltest du typischerweise beim Few-Shot-Lernen bereitstellen?"
  options={[
    "So viele wie möglich (10+)",
    "Nur 1 Beispiel reicht immer",
    "2-5 diverse, korrekte Beispiele",
    "Beispiele sind nicht nötig, wenn Anweisungen klar sind"
  ]}
  correctIndex={2}
  explanation="2-5 diverse, korrekte Beispiele funktionieren typischerweise am besten. Zu wenige erfassen möglicherweise nicht das Muster, während zu viele Tokens verschwenden und das Modell verwirren können. Qualität und Vielfalt zählen mehr als Quantität."
/>

Im nächsten Kapitel erkunden wir iteratives Verfeinern: die Kunst, Prompts durch aufeinanderfolgende Versuche zu verbessern.
